{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangChain vs LangGraph (feat. LangGraph ê°œë… ì„¤ëª…)\n",
        "* LangGraphì˜ ê°œë…ê³¼ ì£¼ìš” ê¸°ëŠ¥ì„ ì´í•´í•˜ê³ , ì°¨ì´ì ì„ ë¹„êµí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs\n",
            "WD\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(OPENAI_API_KEY[:2])\n",
        "\n",
        "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
        "print(UPSTAGE_API_KEY[30:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USER\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-CGunLKE6-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client=<openai.resources.chat.completions.completions.Completions object at 0x0000025184FCE050> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000251854EA550> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='**LangGraph**ëŠ” **LangChain**ê³¼ í†µí•©ëœ ê·¸ë˜í”„ ê¸°ë°˜ì˜ ìƒíƒœ ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ë¡œ, ë³µì¡í•œ ëŒ€í™”í˜• AI ì• í”Œë¦¬ì¼€ì´ì…˜(ì˜ˆ: ì±—ë´‡, ì—ì´ì „íŠ¸, ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ)ì„ êµ¬ì¶•í•  ë•Œ **ìƒíƒœ(state)ì™€ íë¦„ì„ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬**í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  \\n\\n### ğŸ” **í•µì‹¬ ê°œë…**\\n1. **ê·¸ë˜í”„ êµ¬ì¡°**  \\n   - ë…¸ë“œ(Node)ì™€ ì—£ì§€(Edge)ë¡œ êµ¬ì„±ëœ ë°©í–¥ì„± ê·¸ë˜í”„ë¡œ, ê° ë…¸ë“œëŠ” ìƒíƒœ ì „ì´(state transition) ë˜ëŠ” ì‘ì—…(ì˜ˆ: LLM í˜¸ì¶œ, ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ)ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.  \\n   - ì˜ˆ: `ëŒ€í™” ì‹œì‘ â†’ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ â†’ ì™¸ë¶€ API í˜¸ì¶œ â†’ ì‘ë‹µ ìƒì„±`ê³¼ ê°™ì€ íë¦„ì„ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„.\\n\\n2. **ìƒíƒœ ê´€ë¦¬**  \\n   - ëŒ€í™” ê¸°ë¡, ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸, ë©”ëª¨ë¦¬ ë³€ìˆ˜ ë“±ì„ ê·¸ë˜í”„ ë‚´ì—ì„œ ì¶”ì í•˜ë©°, ë³µì¡í•œ ì„¸ì…˜ì—ì„œë„ ì¼ê´€ëœ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.  \\n   - LangChainì˜ `ConversationBufferMemory` ë“±ê³¼ ì—°ë™ ê°€ëŠ¥.\\n\\n3. **í™•ì¥ì„±**  \\n   - ì»¤ìŠ¤í…€ ë…¸ë“œ/ì—£ì§€ë¥¼ ì¶”ê°€í•´ ë³µì¡í•œ ë¡œì§(ì˜ˆ: ë¶„ê¸° ì²˜ë¦¬, ì¡°ê±´ë¶€ íë¦„)ì„ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n   - ì˜ˆ: ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ë‹¤ë¥¸ LLM ì²´ì¸ì„ í˜¸ì¶œí•˜ëŠ” ë¶„ê¸° êµ¬ì¡°.\\n\\n4. **LangChainê³¼ì˜ í†µí•©**  \\n   - LangChainì˜ ì²´ì¸(Chain), ë„êµ¬(Tools), ë©”ëª¨ë¦¬(Memory) ë“±ì„ LangGraph ë…¸ë“œì—ì„œ ì§ì ‘ í™œìš© ê°€ëŠ¥.\\n\\n---\\n\\n### ğŸ›  **ì‚¬ìš© ì‚¬ë¡€**\\n- **ë©€í‹°í„´ ì±—ë´‡**: ëŒ€í™” ì´ë ¥ì„ ìœ ì§€í•˜ë©° ë³µì¡í•œ ì‘ë‹µ ìƒì„±.  \\n- **ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**: ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ í›„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  íë¦„ ì œì–´.  \\n- **ì›Œí¬í”Œë¡œìš° ìë™í™”**: ì¡°ê±´ë¶€ ë¶„ê¸°, ë³‘ë ¬ ì²˜ë¦¬, ì—ëŸ¬ í•¸ë“¤ë§ ë“±.  \\n\\n---\\n\\n### ğŸ“¦ **ì˜ˆì‹œ ì½”ë“œ (ê°„ë‹¨í•œ ê·¸ë˜í”„)**\\n```python\\nfrom langgraph import State, Graph\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\n# ìƒíƒœ í´ë˜ìŠ¤ ì •ì˜\\nclass DialogState(State):\\n    message: str = \"\"\\n    response: str = \"\"\\n\\n# ë…¸ë“œ í•¨ìˆ˜ ì •ì˜\\ndef process_input(state: DialogState) -> DialogState:\\n    state.message = \"ì•ˆë…•í•˜ì„¸ìš”!\"  # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\\n    return state\\n\\ndef generate_response(state: DialogState) -> DialogState:\\n    prompt = ChatPromptTemplate.from_template(\"ë‹µë³€ ìƒì„±: {message}\")\\n    llm = ChatOpenAI()\\n    state.response = llm.invoke(prompt.format_messages(message=state.message)).content\\n    return state\\n\\n# ê·¸ë˜í”„ ìƒì„±\\ngraph = Graph(DialogState)\\ngraph.add_node(\"process_input\", process_input)\\ngraph.add_node(\"generate_response\", generate_response)\\ngraph.add_edge(\"process_input\", \"generate_response\")\\n\\n# ì‹¤í–‰\\nfor state in graph.stream({\"message\": \"ì•ˆë…•\"}):\\n    print(state)\\n```\\n\\n---\\n\\n### ğŸ“Œ **LangChain vs. LangGraph**\\n| íŠ¹ì§•                | LangChain                     | LangGraph                     |\\n|---------------------|-------------------------------|-------------------------------|\\n| **ì£¼ìš” ëª©ì **       | ëª¨ë“ˆì‹ ì²´ì¸ êµ¬ì„±              | ê·¸ë˜í”„ ê¸°ë°˜ ìƒíƒœ ê´€ë¦¬         |\\n| **ë³µì¡ë„**          | ë‹¨ìˆœí•œ ì„ í˜•/ë¶„ê¸° íë¦„         | ë³µì¡í•œ ìƒíƒœ ì „ì´ ë° ìˆœí™˜ ì§€ì› |\\n| **ì‚¬ìš© ì‚¬ë¡€**       | ë‹¨ì¼ ì‘ì—… ì²˜ë¦¬                | ëŒ€í™”í˜• ì—ì´ì „íŠ¸, ì›Œí¬í”Œë¡œìš°   |\\n\\nLangGraphëŠ” LangChainì˜ í•œê³„ë¥¼ ë„˜ì–´ **ë™ì  ìƒíƒœ ê´€ë¦¬**ê°€ í•„ìš”í•œ ê³ ê¸‰ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•©ë‹ˆë‹¤. ê³µì‹ ë¬¸ì„œ: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 681, 'prompt_tokens': 19, 'total_tokens': 700, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'ae856fa4-9ece-4718-b873-a99ea693adb7', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a53600d3-1055-484c-866b-7ca6136fe49e-0', usage_metadata={'input_tokens': 19, 'output_tokens': 681, 'total_tokens': 700, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(model='gpt-4o-mini') # í…ŒìŠ¤íŠ¸ì˜ ê²½ìš°ì—ëŠ” ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
        "\n",
        "from langchain_upstage import ChatUpstage\n",
        "llm = ChatUpstage(\n",
        "        model=\"solar-pro\",\n",
        "        base_url=\"https://api.upstage.ai/v1\",\n",
        "        temperature=0.5\n",
        "    )\n",
        "print(llm)\n",
        "\n",
        "query = 'LangGraphëŠ” ë¬´ì—‡ì¸ê°€ìš”?'\n",
        "llm.invoke(query)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangGraphì˜ ê¸°ë³¸ê°œë…\n",
        "* `state`ëŠ” LangGraph ì—ì´ì „íŠ¸ì˜ stateë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° êµ¬ì¡°ì…ë‹ˆë‹¤.\n",
        "* `state`ëŠ” `TypedDict`ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ì˜ë˜ë©°, ì´ëŠ” Pythonì˜ íƒ€ì… íŒíŒ…ì„ í†µí•´ êµ¬ì¡°ë¥¼ ëª…í™•íˆ í•©ë‹ˆë‹¤.\n",
        "    * ê°„ë‹¨í•˜ê²Œ `messages`ë¼ëŠ” í•„ë“œë§Œ ìˆìŠµë‹ˆë‹¤.\n",
        "    * í•„ìš”ì— ë”°ë¼ ë‹¤ì–‘í•œ ê°’ë“¤ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* `state`ëŠ” ì—ì´ì „íŠ¸ì˜ ë™ì‘ì„ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ê° ë…¸ë“œì—ì„œ stateë¥¼ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ì°¸ì¡°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "* `state`ëŠ” LangGraphì˜ ë…¸ë“œ ê°„ì— ì „ë‹¬ë˜ë©°, ì—ì´ì „íŠ¸ì˜ state ì „ì´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated # íƒ€ì… íŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ \n",
        "from typing_extensions import TypedDict # êµ¬ì¡°í™”ëœ ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì„ ì •ì˜í•˜ê¸° ìœ„í•´ \n",
        "\n",
        "from langgraph.graph.message import add_messages \n",
        "from langchain_core.messages import AnyMessage # LangChainì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë“  ì¢…ë¥˜ì˜ ë©”ì‹œì§€(ì˜ˆ: HumanMessage, AIMessage)\n",
        "\n",
        "# AgentStateëŠ” ì—ì´ì „íŠ¸ì˜ í˜„ì¬ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë”•ì…”ë„ˆë¦¬ íƒ€ì…ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "# TypedDictë¥¼ ì‚¬ìš©í•˜ë©´ ë”•ì…”ë„ˆë¦¬ê°€ ì–´ë–¤ í‚¤ì™€ ê°’ íƒ€ì…ì„ ê°€ì ¸ì•¼ í•˜ëŠ”ì§€ ëª…í™•í•˜ê²Œ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "class AgentState(TypedDict):\n",
        "    # 'messages' í‚¤ëŠ” ì—ì´ì „íŠ¸ì˜ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "    # ì´ ëª©ë¡ì—ëŠ” LangChain ë©”ì‹œì§€ ê°ì²´(AnyMessage)ê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤.\n",
        "    # LangGraphê°€ ì´ ìƒíƒœë¥¼ ì²˜ë¦¬í•  ë•Œ, ìƒˆë¡œìš´ ë©”ì‹œì§€ê°€ ì¶”ê°€ë˜ë©´\n",
        "    # ê¸°ì¡´ ë©”ì‹œì§€ ëª©ë¡ì˜ ëì— ìë™ìœ¼ë¡œ ì¶”ê°€ë˜ë„ë¡(append) ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "    messages: list[Annotated[AnyMessage, add_messages]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ìœ„ì— ì„ ì–¸í•œ `AgentState`ë¥¼ í™œìš©í•˜ì—¬ `StateGraph`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "graph_builder = StateGraph(AgentState)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `graph`ì— ì¶”ê°€í•  `node`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
        "-  `node`ëŠ” LangGraphì—ì„œ ì‹¤í–‰ë˜ëŠ” ê°œë³„ì ì¸ ì‘ì—… ë‹¨ìœ„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. \n",
        "    - ê° ë…¸ë“œëŠ” íŠ¹ì • ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ” ë…ë¦½ì ì¸ ì»´í¬ë„ŒíŠ¸ë¡œ, ì˜ˆë¥¼ ë“¤ì–´ í…ìŠ¤íŠ¸ ìƒì„±, ë°ì´í„° ì²˜ë¦¬, ë˜ëŠ” ì˜ì‚¬ ê²°ì •ê³¼ ê°™ì€ ì‘ì—…ì„ ë‹´ë‹¹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    - `node`ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í•¨ìˆ˜(function)ë¡œ ì •ì˜ë˜ê³ , ë’¤ì—ì„œ ë‹¤ë£¨ì§€ë§Œ ë‹¤ë¥¸ ì—ì´ì „íŠ¸(agent)ë¥¼ í™œìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    `generate` ë…¸ë“œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ì„œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë…¸ë“œì…ë‹ˆë‹¤.\n",
        "    \"\"\"\n",
        "    messages = state['messages']\n",
        "    ai_message = llm.invoke(messages)\n",
        "    return {'messages': [ai_message]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`ë¥¼ ìƒì„±í•œ í›„ì— `edge`ë¡œ ì—°ê²°í•©ë‹ˆë‹¤\n",
        "- `edge`ëŠ” ë…¸ë“œë“¤ ì‚¬ì´ì˜ ì—°ê²°ì„ ë‚˜íƒ€ë‚´ë©°, ë°ì´í„°ì™€ ì œì–´ íë¦„ì˜ ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤. \n",
        "    - ì—£ì§€ë¥¼ í†µí•´ í•œ ë…¸ë“œì˜ ì¶œë ¥ì´ ë‹¤ìŒ ë…¸ë“œì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ë˜ì–´, ì „ì²´ì ì¸ ì›Œí¬í”Œë¡œìš°ê°€ í˜•ì„±ë©ë‹ˆë‹¤.\n",
        "    - `node`ì™€ `edge`ì˜ ì¡°í•©ì€ ë°©í–¥ì„± ê·¸ë˜í”„(Directed Graph)ë¥¼ í˜•ì„±í•˜ë©°, ì´ë¥¼ í†µí•´ ë³µì¡í•œ AI ì—ì´ì „íŠ¸ì˜ í–‰ë™ íë¦„ì„ êµ¬ì¡°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x251854f77d0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_builder.add_node('generate', generate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- ëª¨ë“  ê·¸ë˜í”„ëŠ” `START(ì‹œì‘)`ì™€ `END(ì¢…ë£Œ)`ê°€ ìˆìŠµë‹ˆë‹¤\n",
        "    - `END`ë¥¼ explicití•˜ê²Œ ì„ ì–¸í•˜ì§€ ì•ŠëŠ” ê²½ìš°ë„ ì¢…ì¢… ìˆì§€ë§Œ, ê°€ë…ì„±ì„ ìœ„í•´ ì‘ì„±í•´ì£¼ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x251854f77d0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import START, END\n",
        "\n",
        "graph_builder.add_edge(START, 'generate')\n",
        "graph_builder.add_edge('generate', END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`ë¥¼ ìƒì„±í•˜ê³  `edge`ë¡œ ì—°ê²°í•œ í›„ì— `compile` ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ `Graph`ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        }
      ],
      "source": [
        "graph = graph_builder.compile()\n",
        "print(type(graph))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `compile` í›„ì—ëŠ” ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
        "- ì˜ë„í•œëŒ€ë¡œ ê·¸ë˜í”„ê°€ ìƒì„±ëëŠ”ì§€ í™•ì¸í•˜ëŠ” ìŠµê´€ì„ ê¸°ë¥´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤\n",
        "    - `git`ì—ì„œ ì½”ë“œ ì‘ì—…ë¬¼ì„ commití•˜ê¸° ì „ì— `git diff`ë¥¼ í†µí•´ ë³€ê²½ì‚¬í•­ì„ í™•ì¸í•˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from IPython.display import display, Image\n",
        "\n",
        "#display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mermaid Code:\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tgenerate(generate)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> generate;\n",
            "\tgenerate --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ëŒ€ì²´ ë°©ë²•\n",
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(\"Mermaid Code:\")\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* https://mermaid.live/ ì—ì„œ  mermain_code ë¡œ ì§ì ‘ í™•ì¸í•œë‹¤.\n",
        "* [Graph ì´ë¯¸ì§€](https://mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNpVkEFuwjAQRa9iTTcgJWlwSXANYlOO0FXrCplknFhKnMhxpFLE3WsMpMUbz9f89z3jExRdicChsrKvyftuLYxw-_3gpPXX7HPTbye1ee63X3POudJ2cBdjhQatdDi7F_Mrjqac4FBPaCOv5BRK4nhL7vj6f2jo3PjQKDw87FCREpUcG0eUbhr-pKhKlYoabTCuUVe144uEPgBh4GCPu14W2h15-mC4jHWLO6hDrgqI_JfoErizI0bQom3lRcJJGEIEuBpbFMB9eZtGgDBnj_XSfHRdeydtN1Y1cCWbwauxL_1mOy39f_9Z_Ipo37rROOCLVYgAfoJvrzKa5IzmKaUsY9lqmUdwBL6kyas_LH3JM7akjJ4j-AmPpglbZedfLmWdwA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [AIMessage(content='**LangGraph**ëŠ” **ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**ê³¼ **ìƒíƒœ ê´€ë¦¬ë¥¼ ê²°í•©**í•œ **ê·¸ë˜í”„ ê¸°ë°˜ í”„ë ˆì„ì›Œí¬**ë¡œ, ë³µì¡í•œ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¡°í™”í•˜ê³  í™•ì¥ ê°€ëŠ¥í•˜ê²Œ ì„¤ê³„í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. LangChainì˜ í™•ì¥ í”„ë¡œì íŠ¸ë¡œ ê°œë°œë˜ì—ˆìœ¼ë©°, íŠ¹íˆ **ì¥ê¸°ì ì¸ ëŒ€í™” ìƒíƒœ ì¶”ì **, **ë©€í‹°ëª¨ë‹¬ ì‘ì—…**, **ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìë™í™”**ì— ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\\n\\n### ğŸ“Œ **LangGraphì˜ ì£¼ìš” íŠ¹ì§•**\\n1. **ê·¸ë˜í”„ ê¸°ë°˜ ì•„í‚¤í…ì²˜**  \\n   - ë…¸ë“œ(LLM, ë„êµ¬, ë©”ëª¨ë¦¬ ë“±)ì™€ ì—£ì§€(ìƒíƒœ ì „ì´)ë¡œ êµ¬ì„±ëœ **ìœ í•œ ìƒíƒœ ë¨¸ì‹ (FSM)** ë˜ëŠ” **ë‹¤ì´ë‚´ë¯¹ í”Œë¡œìš°**ë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n   - ì˜ˆ: ì‚¬ìš©ì ì…ë ¥ â†’ LLM ì²˜ë¦¬ â†’ ì™¸ë¶€ API í˜¸ì¶œ â†’ ì‘ë‹µ ìƒì„± â†’ ìƒíƒœ ì—…ë°ì´íŠ¸.\\n\\n2. **ìƒíƒœ(State) ê´€ë¦¬**  \\n   - ëŒ€í™” ê¸°ë¡, ë³€ìˆ˜, ì»¨í…ìŠ¤íŠ¸ë¥¼ ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ì— ìœ ì§€í•˜ë©° **ì¥ê¸°ì  ë§¥ë½**ì„ ë³´ì¡´í•©ë‹ˆë‹¤.\\n   - `State` ê°ì²´ë¥¼ í†µí•´ ê° ë…¸ë“œ ê°„ ë°ì´í„°ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\\n\\n3. **LangChainê³¼ì˜ í†µí•©**  \\n   - LangChainì˜ ì²´ì¸(Chains), ë„êµ¬(Tools), ë©”ëª¨ë¦¬(Memory) ì»´í¬ë„ŒíŠ¸ë¥¼ LangGraph ë…¸ë“œë¡œ ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n4. **í™•ì¥ì„±**  \\n   - ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°(ì˜ˆ: ë‹¤ë‹¨ê³„ í¼ ì±„ìš°ê¸°, ì±—ë´‡ ëŒ€í™” ìƒíƒœ ê´€ë¦¬)ë¥¼ ëª¨ë“ˆì‹ìœ¼ë¡œ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n---\\n\\n### ğŸ§© **ì‚¬ìš© ì‚¬ë¡€ ì˜ˆì‹œ**\\n- **ë©€í‹°í„´ ì±—ë´‡**: ì´ì „ ëŒ€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒíƒœë¥¼ ìœ ì§€í•˜ë©° ì‘ë‹µí•©ë‹ˆë‹¤.  \\n- **ì›Œí¬í”Œë¡œìš° ìë™í™”**: LLMì´ ì—¬ëŸ¬ ë„êµ¬ì™€ ìƒí˜¸ì‘ìš©í•˜ë©° ì‘ì—…ì„ ì™„ë£Œí•©ë‹ˆë‹¤(ì˜ˆ: ì˜ˆì•½ ì‹œìŠ¤í…œ).  \\n- **ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ**: ì¡°ê±´ ë¶„ê¸°ì™€ ìƒíƒœ ì „ì´ë¥¼ í†µí•´ ë™ì  ì˜ì‚¬ ê²°ì •ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\\n\\n---\\n\\n### ğŸ›  **ê°„ë‹¨í•œ ì˜ˆì‹œ ì½”ë“œ (Python)**\\n```python\\nfrom langgraph import State, BaseGraph\\n\\nclass SimpleGraph(BaseGraph):\\n    @classmethod\\n    def define_nodes(cls):\\n        return {\\n            \"start\": lambda state: state.update({\"greeting\": \"Hello!\"}),\\n            \"process\": lambda state: state.update({\"response\": f\"{state.greeting} How can I help?\"}),\\n        }\\n\\n    @classmethod\\n    def define_edges(cls):\\n        return {\\n            \"start\": \"process\",\\n            \"process\": \"end\"\\n        }\\n\\n# ì‹¤í–‰\\nstate = State()\\ngraph = SimpleGraph()\\nfor node in graph.steps(state):\\n    print(node)  # start â†’ process â†’ end\\nprint(state.response)  # \"Hello! How can I help?\"\\n```\\n\\n---\\n\\n### ğŸ” **LangChain vs. LangGraph**\\n| **ê¸°ëŠ¥**          | **LangChain**               | **LangGraph**                     |\\n|-------------------|----------------------------|-----------------------------------|\\n| **ì£¼ìš” ëª©ì **     | LLM ì‘ì—… ì²´ì¸ êµ¬ì„±          | ìƒíƒœ ê¸°ë°˜ ê·¸ë˜í”„ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬   |\\n| **ìƒíƒœ ê´€ë¦¬**     | ì œí•œì  (ë©”ëª¨ë¦¬ ëª¨ë“ˆ í•„ìš”)   | ë‚´ì¥ëœ ìƒíƒœ ê°ì²´ ì§€ì›              |\\n| **ë³µì¡ì„±**        | ë‹¨ìˆœí•œ íŒŒì´í”„ë¼ì¸           | ì¡°ê±´ ë¶„ê¸°, ë£¨í”„, ë‹¤ì¤‘ ê²½ë¡œ ê°€ëŠ¥    |\\n\\nLangGraphëŠ” **ìƒíƒœ ì˜ì¡´ì **ì´ê±°ë‚˜ **ë™ì  í”Œë¡œìš°**ê°€ í•„ìš”í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë” ì í•©í•©ë‹ˆë‹¤. ê³µì‹ ë¬¸ì„œ: [https://langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 647, 'prompt_tokens': 19, 'total_tokens': 666, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'fa2b5d8b-9fd8-44e9-8e13-508e5c5a47d2', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--38ff82f2-96df-4919-9408-985dc14bf12a-0', usage_metadata={'input_tokens': 19, 'output_tokens': 647, 'total_tokens': 666, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "initial_state = {'messages': [HumanMessage(query)]}\n",
        "graph.invoke(initial_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mylangchain-app-CGunLKE6-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
