{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_LiNnM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001ED0BD0B690> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001ED0BD38750> root_client=<openai.OpenAI object at 0x000001ED0BD2A250> root_async_client=<openai.AsyncOpenAI object at 0x000001ED0BBF2050> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm))\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ## íŒŒì´ì¬(Python)ì´ë€?\n",
      "\n",
      "íŒŒì´ì¬ì€ **ê³ ìˆ˜ì¤€(highâ€‘level) ì¸í„°í”„ë¦¬í„° ì–¸ì–´**ë¡œ, 1991ë…„ì— ë„¤ëœë€ë“œì˜ í”„ë¡œê·¸ë˜ë¨¸ **ê·€ë„ ë°˜ ë¡œì¸(Guido van Rossum)**ì´ ì²˜ìŒ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” **ì˜¤í”ˆì†ŒìŠ¤**ì´ë©°, ì „ ì„¸ê³„ ìˆ˜ë§ì€ ê°œë°œìì™€ ê¸°ì—…ì´ í™œë°œíˆ ìœ ì§€Â·ë³´ìˆ˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŒŒì´ì¬ì€ **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**, **ë‹¤ì–‘í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬**, ê·¸ë¦¬ê³  **í’ë¶€í•œ ì„œë“œíŒŒí‹° íŒ¨í‚¤ì§€** ë•ë¶„ì— ì›¹ ê°œë°œ, ë°ì´í„° ê³¼í•™, ì¸ê³µì§€ëŠ¥, ì‹œìŠ¤í…œ ê´€ë¦¬, ì„ë² ë””ë“œ ì‹œìŠ¤í…œ ë“± ê±°ì˜ ëª¨ë“  ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§•\n",
      "\n",
      "| íŠ¹ì§• | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•** | ë“¤ì—¬ì“°ê¸°(Indentation)ë¥¼ ì‚¬ìš©í•´ ë¸”ë¡ì„ êµ¬ë¶„í•©ë‹ˆë‹¤. ì¤‘ê´„í˜¸ `{}` ë‚˜ `;` ê°™ì€ êµ¬ë¬¸ì´ ì—†ì–´ ê°€ë…ì„±ì´ ë›°ì–´ë‚©ë‹ˆë‹¤. |\n",
      "| **ë™ì  íƒ€ì´í•‘** | ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ëŸ°íƒ€ì„ì— ê°ì²´ì˜ íƒ€ì…ì´ ê²°ì •ë©ë‹ˆë‹¤. |\n",
      "| **ì¸í„°í”„ë¦¬í„° ì–¸ì–´** | ì½”ë“œë¥¼ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ ê°œë°œÂ·ë””ë²„ê¹…ì´ ë¹ ë¦…ë‹ˆë‹¤. (ì»´íŒŒì¼ ë‹¨ê³„ê°€ ì—†ê±°ë‚˜ ìµœì†Œí™”ë¨) |\n",
      "| **í’ë¶€í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | `os`, `sys`, `json`, `datetime`, `http`, `re` ë“± ìˆ˜ë°± ê°œì˜ ëª¨ë“ˆì´ ê¸°ë³¸ ì œê³µë©ë‹ˆë‹¤. |\n",
      "| **ë©€í‹°íŒ¨ëŸ¬ë‹¤ì„** | ì ˆì°¨ì , ê°ì²´ì§€í–¥, í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤. |\n",
      "| **í”Œë«í¼ ë…ë¦½ì„±** | Windows, macOS, Linux, BSD, ê·¸ë¦¬ê³  ì¼ë¶€ ëª¨ë°”ì¼/ì„ë² ë””ë“œ OSì—ì„œë„ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤. |\n",
      "| **í™•ì¥ì„±** | C/C++ ë¡œ ì‘ì„±ëœ ëª¨ë“ˆì„ ì†ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆì–´ ì„±ëŠ¥ì´ ì¤‘ìš”í•œ ë¶€ë¶„ì€ ë„¤ì´í‹°ë¸Œ ì½”ë“œë¡œ ë³´ê°•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. |\n",
      "| **ëŒ€ê·œëª¨ ì»¤ë®¤ë‹ˆí‹°** | PyPI(Python Package Index)ì—ëŠ” 30ë§Œ ê°œê°€ ë„˜ëŠ” íŒ¨í‚¤ì§€ê°€ ì¡´ì¬í•˜ë©°, Stack Overflow, GitHub, Reddit ë“±ì—ì„œ í™œë°œíˆ ì§ˆë¬¸Â·ë‹µë³€ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤. |\n",
      "| **ë²„ì „ ê´€ë¦¬** | í˜„ì¬ ì£¼ ë²„ì „ì€ **Python 3.x**ì´ë©°, 2.xëŠ” 2020ë…„ 1ì›”ì— ê³µì‹ ì§€ì›ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. íŒŒì´ì¬ì˜ ì—­ì‚¬\n",
      "\n",
      "| ì—°ë„ | ì£¼ìš” ì‚¬ê±´ |\n",
      "|------|-----------|\n",
      "| **1989** | ê·€ë„ ë°˜ ë¡œì¸ì´ â€œì•„ëª°í”„(ABC) ì–¸ì–´â€ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ íŒŒì´ì¬ ì„¤ê³„ ì°©ìˆ˜ |\n",
      "| **1991** | íŒŒì´ì¬ 0.9.0 ê³µê°œ (ì˜ˆì™¸ ì²˜ë¦¬, ëª¨ë“ˆ, í•¨ìˆ˜ ë“± ê¸°ë³¸ ê¸°ëŠ¥ í¬í•¨) |\n",
      "| **1994** | íŒŒì´ì¬ 1.0 ë¦´ë¦¬ìŠ¤ |\n",
      "| **2000** | íŒŒì´ì¬ 2.0 ë¦´ë¦¬ìŠ¤ (ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë“±) |\n",
      "| **2008** | íŒŒì´ì¬ 3.0 ë¦´ë¦¬ìŠ¤ (ë¬¸ìì—´ì´ Unicode ê¸°ë°˜, `print`ê°€ í•¨ìˆ˜í™” ë“±) |\n",
      "| **2010~2020** | ë°ì´í„° ê³¼í•™Â·ë¨¸ì‹ ëŸ¬ë‹ ë¶ê³¼ í•¨ê»˜ íŒŒì´ì¬ ì‚¬ìš© ê¸‰ì¦ (NumPy, pandas, TensorFlow, PyTorch ë“±) |\n",
      "| **2023** | íŒŒì´ì¬ 3.12 ë¦´ë¦¬ìŠ¤ (íŒ¨í„´ ë§¤ì¹­ ê°œì„ , ì„±ëŠ¥ ìµœì í™”) |\n",
      "| **2025** | í˜„ì¬ ìµœì‹  LTS ë²„ì „ì€ 3.13 (ì˜ˆì •) |\n",
      "\n",
      "> **í•µì‹¬ í¬ì¸íŠ¸**: íŒŒì´ì¬ 2ì™€ 3ëŠ” ë¬¸ë²•Â·í‘œí˜„ì‹ì´ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì´ ìˆì–´, 2020ë…„ ì´í›„ ì‹ ê·œ í”„ë¡œì íŠ¸ëŠ” ë°˜ë“œì‹œ 3.x ë²„ì „ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²• ì˜ˆì‹œ\n",
      "\n",
      "### 3-1. â€œHello, World!â€ ì¶œë ¥\n",
      "```python\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "### 3-2. ë³€ìˆ˜ì™€ ìë£Œí˜•\n",
      "```python\n",
      "# ì •ìˆ˜\n",
      "age = 30\n",
      "\n",
      "# ì‹¤ìˆ˜\n",
      "height = 1.78\n",
      "\n",
      "# ë¬¸ìì—´\n",
      "name = \"í™ê¸¸ë™\"\n",
      "\n",
      "# ë¦¬ìŠ¤íŠ¸\n",
      "fruits = [\"ì‚¬ê³¼\", \"ë°”ë‚˜ë‚˜\", \"ì²´ë¦¬\"]\n",
      "\n",
      "# ë”•ì…”ë„ˆë¦¬\n",
      "person = {\"ì´ë¦„\": \"í™ê¸¸ë™\", \"ë‚˜ì´\": 30}\n",
      "```\n",
      "\n",
      "### 3-3. ì œì–´ë¬¸\n",
      "```python\n",
      "# if-elif-else\n",
      "if age < 20:\n",
      "    print(\"ì²­ì†Œë…„\")\n",
      "elif age < 60:\n",
      "    print(\"ì„±ì¸\")\n",
      "else:\n",
      "    print(\"ë…¸ì¸\")\n",
      "\n",
      "# for ë£¨í”„ (ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ)\n",
      "for fruit in fruits:\n",
      "    print(fruit)\n",
      "\n",
      "# while ë£¨í”„\n",
      "i = 0\n",
      "while i < 5:\n",
      "    print(i)\n",
      "    i += 1\n",
      "```\n",
      "\n",
      "### 3-4. í•¨ìˆ˜ ì •ì˜ì™€ í˜¸ì¶œ\n",
      "```python\n",
      "def greet(name: str, times: int = 1) -> None:\n",
      "    \"\"\"ì¸ì‚¬ë§ì„ ì—¬ëŸ¬ ë²ˆ ì¶œë ¥í•©ë‹ˆë‹¤.\"\"\"\n",
      "    for _ in range(times):\n",
      "        print(f\"ì•ˆë…•í•˜ì„¸ìš”, {name}ë‹˜!\")\n",
      "\n",
      "greet(\"í™ê¸¸ë™\", 3)\n",
      "```\n",
      "\n",
      "### 3-5. í´ë˜ìŠ¤ì™€ ê°ì²´ì§€í–¥\n",
      "```python\n",
      "class Animal:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError(\"subclass must implement speak()\")\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"ë©ë©!\"\n",
      "\n",
      "class Cat(Animal):\n",
      "    def speak(self):\n",
      "        return \"ì•¼ì˜¹!\"\n",
      "\n",
      "dog = Dog(\"ë°”ë‘‘ì´\")\n",
      "cat = Cat(\"ë‚˜ë¹„\")\n",
      "print(dog.speak())   # ë©ë©!\n",
      "print(cat.speak())   # ì•¼ì˜¹!\n",
      "```\n",
      "\n",
      "### 3-6. íŒŒì¼ ì…ì¶œë ¥\n",
      "```python\n",
      "# íŒŒì¼ ì“°ê¸°\n",
      "with open(\"sample.txt\", \"w\", encoding=\"utf-8\") as f:\n",
      "    f.write(\"íŒŒì´ì¬ì€ ì¬ë¯¸ìˆì–´ìš”!\\n\")\n",
      "\n",
      "# íŒŒì¼ ì½ê¸°\n",
      "with open(\"sample.txt\", \"r\", encoding=\"utf-8\") as f:\n",
      "    content = f.read()\n",
      "    print(content)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 4. íŒŒì´ì¬ì´ ë§ì´ ì“°ì´ëŠ” ë¶„ì•¼\n",
      "\n",
      "| ë¶„ì•¼ | í™œìš© ì˜ˆì‹œ | ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬/í”„ë ˆì„ì›Œí¬ |\n",
      "|------|-----------|------------------------------|\n",
      "| **ì›¹ ê°œë°œ** | ë°±ì—”ë“œ API, ì„œë²„ ì‚¬ì´ë“œ ë Œë”ë§ | Django, Flask, FastAPI, Tornado |\n",
      "| **ë°ì´í„° ê³¼í•™** | ë°ì´í„° ì „ì²˜ë¦¬Â·ì‹œê°í™”Â·í†µê³„ ë¶„ì„ | NumPy, pandas, Matplotlib, Seaborn |\n",
      "| **ë¨¸ì‹ ëŸ¬ë‹Â·ë”¥ëŸ¬ë‹** | ëª¨ë¸ ì„¤ê³„Â·í•™ìŠµÂ·ë°°í¬ | scikitâ€‘learn, TensorFlow, PyTorch, Keras |\n",
      "| **ìë™í™”Â·ìŠ¤í¬ë¦½íŠ¸** | ì‹œìŠ¤í…œ ê´€ë¦¬, í…ŒìŠ¤íŠ¸ ìë™í™”, ETL | `subprocess`, `os`, `shutil`, `click` |\n",
      "| **ê³¼í•™Â·ê³µí•™** | ì‹œë®¬ë ˆì´ì…˜, ìˆ˜ì¹˜í•´ì„ | SciPy, SymPy, PyTorch (ë¬¼ë¦¬ ì‹œë®¬), Jupyter |\n",
      "| **ê²Œì„ ê°œë°œ** | 2D/3D ê²Œì„ ì—”ì§„ | Pygame, Panda3D, Godot (Python ìŠ¤í¬ë¦½íŒ…) |\n",
      "| **ë„¤íŠ¸ì›Œí‚¹Â·ë³´ì•ˆ** | íŒ¨í‚· ë¶„ì„, ì¹¨íˆ¬ í…ŒìŠ¤íŠ¸, ìë™í™” | Scapy, paramiko, requests, Twisted |\n",
      "| **ì„ë² ë””ë“œÂ·IoT** | ë¼ì¦ˆë² ë¦¬ íŒŒì´, ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ | MicroPython, CircuitPython |\n",
      "| **êµìœ¡** | í”„ë¡œê·¸ë˜ë° ì…ë¬¸, ì•Œê³ ë¦¬ì¦˜ êµìœ¡ | êµì¬Â·ì˜¨ë¼ì¸ ì½”ìŠ¤ (Codecademy, Coursera ë“±) |\n",
      "\n",
      "> **íŠ¹íˆ ë°ì´í„° ê³¼í•™Â·ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì•¼**ì—ì„œ íŒŒì´ì¬ì€ â€œí‘œì¤€ ì–¸ì–´â€ë¡œ ìë¦¬ ì¡ì•˜ìœ¼ë©°, ê¸°ì—…Â·í•™ê³„ ëª¨ë‘ì—ì„œ ê°€ì¥ ë§ì´ ì±„íƒë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. íŒŒì´ì¬ ê°œë°œ í™˜ê²½ ì„¤ì •\n",
      "\n",
      "1. **Python ì„¤ì¹˜**  \n",
      "   - ê³µì‹ ì›¹ì‚¬ì´íŠ¸ <https://www.python.org/downloads/> ì—ì„œ ìµœì‹  3.x ë²„ì „ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.  \n",
      "   - Windowsì—ì„œëŠ” `Add Python to PATH` ì˜µì…˜ì„ ë°˜ë“œì‹œ ì²´í¬í•˜ì„¸ìš”.  \n",
      "\n",
      "2. **ê°€ìƒ í™˜ê²½(Virtual Environment) ì‚¬ìš©**  \n",
      "   ```bash\n",
      "   # í”„ë¡œì íŠ¸ í´ë” ìƒì„±\n",
      "   mkdir my_project && cd my_project\n",
      "\n",
      "   # ê°€ìƒ í™˜ê²½ ìƒì„± (Python 3.8+)\n",
      "   python -m venv venv\n",
      "\n",
      "   # í™œì„±í™”\n",
      "   # Windows\n",
      "   venv\\Scripts\\activate\n",
      "   # macOS/Linux\n",
      "   source venv/bin/activate\n",
      "   ```\n",
      "\n",
      "3. **íŒ¨í‚¤ì§€ ê´€ë¦¬**  \n",
      "   - ê¸°ë³¸ íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €: `pip`  \n",
      "   ```bash\n",
      "   pip install numpy pandas matplotlib\n",
      "   ```\n",
      "   - ì˜ì¡´ì„± íŒŒì¼: `requirements.txt`  \n",
      "   ```bash\n",
      "   pip freeze > requirements.txt   # í˜„ì¬ í™˜ê²½ ì €ì¥\n",
      "   pip install -r requirements.txt # ë‹¤ë¥¸ í™˜ê²½ì— ì¬ì„¤ì¹˜\n",
      "   ```\n",
      "\n",
      "4. **IDE/ì—ë””í„°**  \n",
      "   - **VS Code** + Python í™•ì¥ (IntelliSense, ë””ë²„ê±°)  \n",
      "   - **PyCharm** (Professional: ì›¹Â·ë°ì´í„° ê³¼í•™ ì§€ì›)  \n",
      "   - **Jupyter Notebook / JupyterLab** (ì¸í„°ë™í‹°ë¸Œ ë°ì´í„° ë¶„ì„)  \n",
      "\n",
      "5. **ì½”ë“œ ìŠ¤íƒ€ì¼**  \n",
      "   - PEPâ€¯8: íŒŒì´ì¬ ê³µì‹ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ (ë“¤ì—¬ì“°ê¸° 4 ìŠ¤í˜ì´ìŠ¤, ë¼ì¸ ê¸¸ì´ 79ì ë“±)  \n",
      "   - ìë™ í¬ë§·í„°: `black`, `isort`  \n",
      "   - ë¦°í„°: `flake8`, `pylint`\n",
      "\n",
      "---\n",
      "\n",
      "## 6. íŒŒì´ì¬ ì„±ëŠ¥ ìµœì í™” íŒ\n",
      "\n",
      "| ìƒí™© | ìµœì í™” ë°©ë²• |\n",
      "|------|-------------|\n",
      "| **CPU ë°”ìš´ë“œ ì—°ì‚°** | NumPy/Numba ì‚¬ìš© â†’ C ë ˆë²¨ ì—°ì‚°ìœ¼ë¡œ ê°€ì† |\n",
      "| **I/O ë°”ìš´ë“œ** | `asyncio`, `aiohttp` ê°™ì€ ë¹„ë™ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš© |\n",
      "| **ë°˜ë³µë¬¸ ìµœì í™”** | ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜, ì œë„¤ë ˆì´í„° ì‚¬ìš© â†’ ë©”ëª¨ë¦¬ íš¨ìœ¨ â†‘ |\n",
      "| **í•¨ìˆ˜ í˜¸ì¶œ ë¹„ìš©** | `functools.lru_cache` ë¡œ ê²°ê³¼ ìºì‹œ |\n",
      "| **ë‹¤ì¤‘ ì½”ì–´ í™œìš©** | `multiprocessing` ëª¨ë“ˆ ë˜ëŠ” `concurrent.futures` |\n",
      "| **í”„ë¡œíŒŒì¼ë§** | `cProfile`, `line_profiler` ë¡œ ë³‘ëª© íŒŒì•… |\n",
      "| **C í™•ì¥** | Cython, Pybind11, SWIG ë¡œ í•µì‹¬ ë¡œì§ì„ C/C++ ë¡œ êµ¬í˜„ |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. íŒŒì´ì¬ í•™ìŠµ ë¡œë“œë§µ (ì´ˆê¸‰ â†’ ê³ ê¸‰)\n",
      "\n",
      "1. **ê¸°ì´ˆ**  \n",
      "   - ë³€ìˆ˜Â·ìë£Œí˜•Â·ì—°ì‚°ìÂ·ì œì–´ë¬¸Â·í•¨ìˆ˜Â·ëª¨ë“ˆÂ·íŒ¨í‚¤ì§€  \n",
      "   - ê¸°ë³¸ ì…ì¶œë ¥Â·ì˜ˆì™¸ ì²˜ë¦¬Â·íŒŒì¼ I/O  \n",
      "\n",
      "2. **ì¤‘ê¸‰**  \n",
      "   - ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° (í´ë˜ìŠ¤Â·ìƒì†Â·ë‹¤í˜•ì„±)  \n",
      "   - í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš© (`collections`, `itertools`, `datetime` ë“±)  \n",
      "   - ê°€ìƒ í™˜ê²½Â·íŒ¨í‚¤ì§€ ê´€ë¦¬Â·í…ŒìŠ¤íŠ¸ (`unittest`, `pytest`)  \n",
      "\n",
      "3. **ì „ë¬¸ ë¶„ì•¼ ì„ íƒ**  \n",
      "   - **ì›¹** â†’ Django/Flask/FastAPI, REST API ì„¤ê³„, ë°°í¬(Docker, Gunicorn)  \n",
      "   - **ë°ì´í„° ê³¼í•™** â†’ pandas, matplotlib, seaborn, Jupyter, ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸  \n",
      "   - **ë¨¸ì‹ ëŸ¬ë‹** â†’ scikitâ€‘learn, TensorFlow, PyTorch, ëª¨ë¸ ì„œë¹™(ONNX, FastAPI)  \n",
      "   - **ìë™í™”** â†’ Selenium, PyAutoGUI, `subprocess`, CI/CD íŒŒì´í”„ë¼ì¸  \n",
      "\n",
      "4. **ê³ ê¸‰**  \n",
      "   - ë©”íƒ€í”„ë¡œê·¸ë˜ë° (ë°ì½”ë ˆì´í„°Â·í´ë˜ìŠ¤ ë°ì½”ë ˆì´í„°Â·ë™ì  ì½”ë“œ ìƒì„±)  \n",
      "   - íƒ€ì… íŒíŠ¸ì™€ ì •ì  ë¶„ì„ (`mypy`, `pyright`)  \n",
      "   - ì„±ëŠ¥ ìµœì í™” (Cython, Numba, ë©€í‹°í”„ë¡œì„¸ì‹±)  \n",
      "   - ë°°í¬Â·ì»¨í…Œì´ë„ˆí™” (Docker, Kubernetes, Serverless)  \n",
      "\n",
      "---\n",
      "\n",
      "## 8. íŒŒì´ì¬ì„ ë°°ìš°ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ìë£Œ\n",
      "\n",
      "| ì¢…ë¥˜ | ì¶”ì²œ ìë£Œ |\n",
      "|------|-----------|\n",
      "| **ê³µì‹ ë¬¸ì„œ** | <https://docs.python.org/3/> (íŠœí† ë¦¬ì–¼, ë¼ì´ë¸ŒëŸ¬ë¦¬ ë ˆí¼ëŸ°ìŠ¤) |\n",
      "| **ì˜¨ë¼ì¸ ê°•ì˜** | Coursera â€œPython for Everybodyâ€, Udemy â€œComplete Python Bootcampâ€, Fast.ai â€œPractical Deep Learning for Codersâ€ |\n",
      "| **ì±…** | ã€ŠíŒŒì´ì¬ ì½”ë”© ë„ì¥ã€‹, ã€ŠFluent Pythonã€‹, ã€ŠEffective Pythonã€‹, ã€ŠPython Data Science Handbookã€‹ |\n",
      "| **ì¸í„°ë™í‹°ë¸Œ** | Codecademy, LeetCode (Python), HackerRank (Python) |\n",
      "| **ì»¤ë®¤ë‹ˆí‹°** | Stack Overflow (python tag), Reddit r/Python, í•œêµ­ì–´ ì¹´ì¹´ì˜¤í†¡Â·ë””ìŠ¤ì½”ë“œ íŒŒì´ì¬ ìŠ¤í„°ë”” ì±„ë„ |\n",
      "| **ë¸”ë¡œê·¸Â·íŠœí† ë¦¬ì–¼** | Real Python, Towards Data Science, íŒŒì´ì¬ì½”ë“œ (í•œêµ­ì–´ ë¸”ë¡œê·¸) |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. ê²°ë¡ \n",
      "\n",
      "- **íŒŒì´ì¬ì€** ë°°ìš°ê¸° ì‰½ê³ , **ë‹¤ì–‘í•œ ë¶„ì•¼**ì— ì ìš© ê°€ëŠ¥í•œ ë²”ìš© í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.  \n",
      "- **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**ê³¼ **í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬** ë•ë¶„ì— í”„ë¡œí† íƒ€ì…ë¶€í„° ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ê¹Œì§€ í­ë„“ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.  \n",
      "- **ì»¤ë®¤ë‹ˆí‹°ì™€ ìƒíƒœê³„**ê°€ í™œë°œí•´ ìµœì‹  ê¸°ìˆ (ì¸ê³µì§€ëŠ¥Â·ë°ì´í„° ê³¼í•™Â·í´ë¼ìš°ë“œ)ê³¼ë„ ë¹ ë¥´ê²Œ ì—°ê³„ë©ë‹ˆë‹¤.  \n",
      "\n",
      "íŒŒì´ì¬ì„ **í•µì‹¬ ì–¸ì–´**ë¡œ ì‚¼ê³ , **í”„ë¡œì íŠ¸ì™€ ì‹¤ì „ ê²½í—˜**ì„ í†µí•´ ë‹¨ê³„ì ìœ¼ë¡œ í•™ìŠµí•œë‹¤ë©´, í˜„ëŒ€ ì†Œí”„íŠ¸ì›¨ì–´Â·ë°ì´í„° ë¶„ì•¼ì—ì„œ í° ê²½ìŸë ¥ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•œ ì‹¬í™” ì„¤ëª…ì´ í•„ìš”í•˜ë©´ ì–¸ì œë“  ì•Œë ¤ ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001ED0BD0B690>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001ED0BD38750>, root_client=<openai.OpenAI object at 0x000001ED0BD2A250>, root_async_client=<openai.AsyncOpenAI object at 0x000001ED0BBF2050>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"ì§€êµ¬ì˜ ìì „ì£¼ê¸°ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ì§€êµ¬ëŠ” **ìì „**ì„ í•œ ë²ˆ í•˜ëŠ” ë° ì•½ **23ì‹œê°„â€¯56ë¶„â€¯4ì´ˆ**(â‰ˆâ€¯23.934â€¯ì‹œê°„) ì •ë„ê°€ ê±¸ë¦½ë‹ˆë‹¤. ì´ëŠ” **í•­ì„±ì¼(sidereal day)**ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê°’ìœ¼ë¡œ, ë³„ì„ ê¸°ì¤€ìœ¼ë¡œ ë³´ì•˜ì„ ë•Œ ì§€êµ¬ê°€ í•œ ë°”í€´ ë„ëŠ” ì‹œê°„ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ì¼ë°˜ì ìœ¼ë¡œ ìš°ë¦¬ê°€ ì¼ìƒì—ì„œ ì‚¬ìš©í•˜ëŠ” **íƒœì–‘ì¼(solar day)**ì€ íƒœì–‘ì´ ê°™ì€ ìœ„ì¹˜ì— ë‹¤ì‹œ ì˜¤ë¥´ëŠ” ì‹œê°„ì„ ì˜ë¯¸í•˜ëŠ”ë°, ì´ê²ƒì€ ì•½ **24ì‹œê°„**(ì •í™•íˆëŠ” 24â€¯ì‹œê°„â€¯0â€¯ë¶„â€¯0â€¯ì´ˆ)ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ë”°ë¼ì„œ:\n",
      "\n",
      "- **í•­ì„±ì¼** â‰ˆ 23â€¯hâ€¯56â€¯mâ€¯4â€¯s (ìì „ ìì²´ì— ëŒ€í•œ ìˆœìˆ˜í•œ íšŒì „ ì‹œê°„)  \n",
      "- **íƒœì–‘ì¼** â‰ˆ 24â€¯h (ìš°ë¦¬ ìƒí™œì—ì„œ ê²½í—˜í•˜ëŠ” í•˜ë£¨)  \n",
      "\n",
      "ë‘ ê°’ì˜ ì°¨ì´ëŠ” ì§€êµ¬ê°€ íƒœì–‘ ì£¼ìœ„ë¥¼ ê³µì „í•˜ë©´ì„œ ë™ì‹œì— ìì „í•˜ê¸° ë•Œë¬¸ì— ë°œìƒí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-CGunLKE6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
