{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_L\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "#load_dotenv(dotenv_path='../.env')\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 방대한 텍스트 데이터를 이용해 다음에 올 단어를 예측하도록 사전 학습(pre‑training)됩니다. 이때 모델은 입력된 '\n",
      " '문맥을 바탕으로 가장 확률이 높은 토큰을 선택하도록 가중치를 조정하며, 수십억 개의 파라미터가 서로 연결되어 언어 패턴을 학습합니다. '\n",
      " '이후 인간 피드백을 활용한 강화학습(RLHF) 등으로 미세 조정(fine‑tuning)하여 실제 대화 상황에서 더 안전하고 유용한 답변을 '\n",
      " '생성하도록 최적화됩니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 대규모 텍스트 데이터를 이용해 Transformer 기반의 신경망을 사전 학습(pre‑training)하여 언어 구조와 의미를 '\n",
      " '일반화합니다.  \\n'\n",
      " '2. 사전 학습된 모델을 실제 대화나 특정 작업에 맞게 인간 피드백을 활용한 강화학습(RLHF)으로 미세 '\n",
      " '조정(fine‑tuning)합니다.  \\n'\n",
      " '3. 학습 과정에서 손실 함수(Loss)를 최소화하도록 가중치를 반복적으로 업데이트해, 입력에 대한 가장 확률이 높은 다음 토큰을 '\n",
      " '예측하도록 모델을 최적화합니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT 모델의 주요 장점 요약\\n'\n",
      " '- **다양한 주제에 대한 높은 이해도**: 방대한 텍스트 코퍼스로 학습돼 일반 상식, 전문 지식, 문화적 맥락 등을 폭넓게 '\n",
      " '파악합니다.  \\n'\n",
      " '- **자연스러운 대화 흐름**: 문맥을 추적하고 이전 발언을 기억해 일관된 대화와 적절한 응답을 생성합니다.  \\n'\n",
      " '- **빠른 적용성**: 사전 학습 모델을 기반으로 미세 조정만으로도 챗봇, 번역, 요약, 코드 생성 등 다양한 응용 분야에 바로 활용할 '\n",
      " '수 있습니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT와 비슷한 AI 모델 (한국어 모델명)\\n'\n",
      " '- **라마(LLaMA)** – Meta에서 개발한 대규모 언어 모델 시리즈  \\n'\n",
      " '- **알파코드(AlphaCode)** – DeepMind가 만든 코드 생성 특화 모델  \\n'\n",
      " '- **버트(BERT)** – 구글이 발표한 양방향 Transformer 모델(텍스트 이해에 강점)  \\n'\n",
      " '- **코히어런트(Claude)** – Anthropic이 만든 대화형 AI 모델  \\n'\n",
      " '- **스테이블 디퓨전(Stable Diffusion)** – 이미지 생성 모델이지만 텍스트‑이미지 연동에서 유사한 구조를 사용  \\n'\n",
      " '- **스위프트(스위프트코드, SwiftCoder)** – 한국어에 특화된 최신 대형 언어 모델(예: 카카오·네이버 공동 개발)  \\n'\n",
      " '\\n'\n",
      " '위 모델들은 모두 Transformer 아키텍처를 기반으로 대규모 데이터로 사전 학습된 뒤, 특정 작업에 맞게 파인튜닝하거나 강화학습을 '\n",
      " '적용해 활용됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT‑4는 대량의 텍스트 데이터를 사용해 다음 단어를 예측하도록 훈련된 트랜스포머 기반 언어 모델입니다. 학습 과정에서 모델은 입력 '\n",
      " '문맥을 인코딩하고, 각 위치에서 가장 확률이 높은 단어를 선택하도록 가중치를 조정합니다. 이를 반복적으로 수행하면서 언어 구조와 의미 '\n",
      " '관계를 스스로 학습하게 됩니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini 모델은 대규모 텍스트와 멀티모달 데이터를 사용해 사전 학습(pre‑training) 단계에서 언어와 이미지·음성 등 다양한 '\n",
      " '형식의 정보를 동시에 학습합니다.  \\n'\n",
      " '이후 인간 피드백을 활용한 강화 학습(RLHF) 과정을 거쳐, 모델이 더 정확하고 안전하게 응답하도록 미세 조정합니다.  \\n'\n",
      " '학습 과정에서는 트랜스포머 기반의 자기‑주의 메커니즘을 이용해 문맥을 장기적으로 파악하고, 여러 모달리티 간의 관계를 통합합니다.  \\n'\n",
      " '마지막으로 지속적인 업데이트와 평가를 통해 최신 지식과 윤리 기준을 반영하도록 모델을 지속적으로 개선합니다.')\n",
      "<class 'str'> claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude 모델은 대규모 텍스트 데이터를 이용해 **자기 지도 학습(self‑supervised learning)** 방식으로 사전 '\n",
      " '학습됩니다.  \\n'\n",
      " '학습 과정에서는 입력 문장에 마스크를 적용하거나 다음 토큰을 예측하도록 하여, 문맥을 이해하고 자연스러운 언어를 생성하도록 모델을 '\n",
      " '최적화합니다.  \\n'\n",
      " '그 후, 인간 피드백을 활용한 **강화 학습(RLHF, Reinforcement Learning from Human Feedback)** '\n",
      " '단계에서 실제 사용자의 선호와 윤리적 기준을 반영하도록 보정합니다.  \\n'\n",
      " '최종적으로 여러 도메인에 걸친 미세 조정과 검증을 거쳐, 다양한 질문에 일관되고 유용한 답변을 제공할 수 있게 됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지 한눈에 보기  \n",
      "\n",
      "아래 내용은 **Transformer 기반 대규모 언어 모델**(LLM)인 ChatGPT가 **데이터를 어떻게 받아들이고**, **어떤 목표를 가지고**, **어떤 단계들을 거쳐** 최종적으로 “대화형 AI”가 되는지를 순서대로 정리한 것입니다.  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. 기본 구조: Transformer (디코더)  \n",
      "\n",
      "| 구성 요소 | 역할 |\n",
      "|----------|------|\n",
      "| **입력 토큰** | 텍스트 → **토크나이저** → 정수 ID 시퀀스 |\n",
      "| **임베딩(Embedding)** | 토큰 ID를 고정 차원의 실수 벡터로 변환 |\n",
      "| **포지셔널 인코딩** | 순서 정보를 벡터에 더해 줌 (sin/cos 혹은 학습 가능한) |\n",
      "| **Self‑Attention** | 각 토큰이 문맥 전체(앞·뒤)와 상호작용해 의미를 파악 |\n",
      "| **Feed‑Forward 네트워크** | 비선형 변환으로 표현력을 강화 |\n",
      "| **Layer Normalization & Residual** | 학습 안정성·깊은 네트워크 전파를 돕는 구조 |\n",
      "| **출력 헤드** | 마지막 레이어의 벡터 → **Vocabulary** 차원의 로짓 → Softmax → 다음 토큰 확률 분포 |\n",
      "\n",
      "> **핵심 포인트** : Transformer는 **병렬 처리**가 가능하고, **전역적인 문맥(전 토큰)**을 한 번에 고려할 수 있어 대규모 텍스트를 효율적으로 학습합니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 학습 단계 전체 흐름  \n",
      "\n",
      "1. **대규모 텍스트 수집**  \n",
      "   - 웹 페이지, 책, 논문, 코드 저장소 등 공개된 다양한 소스 → 수백 GB~수 TB 규모.  \n",
      "   - 데이터는 **필터링**(불법·유해 콘텐츠 제거, 중복 제거 등) 후 **토크나이저**(BPE/Byte‑Level) 로 변환.\n",
      "\n",
      "2. **사전 학습 (Pre‑training)** – **자기 지도 학습**  \n",
      "   - **목표**: “다음 토큰 예측”(Next‑Token Prediction) 혹은 “마스크된 토큰 복원”(Masked LM, GPT는 전자는 사용).  \n",
      "   - **손실 함수**: **Cross‑Entropy Loss**  \n",
      "     \\[\n",
      "     \\mathcal{L} = -\\sum_{t=1}^{T}\\log P_\\theta (x_t \\mid x_{<t})\n",
      "     \\]\n",
      "   - **학습 과정**  \n",
      "     1. **배치**: 여러 문장을 동일한 길이로 패딩하고, GPU/TPU 클러스터에 분산.  \n",
      "     2. **전방 계산**: 입력 시퀀스를 Transformer에 통과시켜 각 위치의 로그 확률을 얻음.  \n",
      "     3. **역전파**: 손실을 미분해 **AdamW** 옵티마이저로 파라미터 업데이트.  \n",
      "   - **스케줄링**:  \n",
      "     - **Learning Rate Warm‑up** → **Cosine Decay** 등으로 안정적인 초기 학습.  \n",
      "     - **Gradient Accumulation** → 메모리 제한을 넘어 큰 배치 효과 구현.  \n",
      "\n",
      "   - **결과**: 모델은 “언어의 통계적 규칙, 문법, 사실 지식, 추론 패턴”을 **암묵적으로** 습득.\n",
      "\n",
      "3. **지도 학습 (Supervised Fine‑tuning)** – **대화 데이터**  \n",
      "   - **데이터**: 인간이 만든 질문‑답변, 대화 로그, 역할극 등.  \n",
      "   - **목표**: “주어진 프롬프트에 가장 적절한 응답을 생성”하도록 **다음 토큰 예측**을 그대로 사용하지만, **문맥이 대화 형태**이므로 모델이 대화 흐름을 배운다.  \n",
      "   - **특징**:  \n",
      "     - **시스템 프롬프트**(예: “You are a helpful assistant”)를 앞에 붙여 모델에게 역할을 명시.  \n",
      "     - **샘플링 전략**(Top‑k, Top‑p, temperature)도 훈련 시 시뮬레이션하여 실제 배포 상황과 일치시킴.\n",
      "\n",
      "4. **보강 학습 (Reinforcement Learning from Human Feedback, RLHF)**  \n",
      "   - **왜 필요한가?**  \n",
      "     - 단순히 “다음 토큰 맞추기”만 하면 **무의미하거나 부적절한** 답변도 높은 확률로 생성될 수 있다.  \n",
      "   - **프로세스**  \n",
      "     1. **Human Labelers**: 여러 후보 응답을 평가하고 **선호도 점수**(예: 1~5) 부여.  \n",
      "     2. **Reward Model**: 위 라벨을 학습시켜 **보상 함수** \\(R_\\phi\\) 를 만든다.  \n",
      "     3. **Proximal Policy Optimization (PPO)** 등 RL 알고리즘을 사용해 **Policy**(기존 GPT 모델) 를 **보상**이 최대가 되도록 미세조정.  \n",
      "   - **핵심 효과**  \n",
      "     - **안전성**(불쾌감·허위 정보 억제)  \n",
      "     - **유용성**(질문에 정확히 답변, 대화 흐름 유지)  \n",
      "     - **일관성**(같은 질문에 일관된 답변)\n",
      "\n",
      "5. **배포 전 검증 & 안전성 테스트**  \n",
      "   - **자동 테스트**: 유해 콘텐츠 필터, 사실 검증, 거짓 정보 탐지 등.  \n",
      "   - **인간 평가**: 다중 라운드 대화 시나리오에서 **전문가**가 품질을 점검.  \n",
      "   - **가드레일**(guardrails) 적용: 특정 토픽에 대해 “답변을 거부”하거나 “안전한 답변”을 제공하도록 규칙 삽입.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 핵심 기술 요소 상세 설명  \n",
      "\n",
      "### 3.1 토크나이저 (Tokenizer)  \n",
      "- **Byte‑Pair Encoding (BPE)** 혹은 **Byte‑Level BPE**: 문자 수준에서 가장 자주 등장하는 **sub‑word** 단위를 합쳐 vocab을 만든다.  \n",
      "- 장점:  \n",
      "  - **어휘 외(OOV) 문제 최소화** → 새로운 단어도 여러 sub‑word 조합으로 표현 가능.  \n",
      "  - **다국어**(특히 한국어)에서도 **형태소**를 완전히 분석하지 않아도 충분히 커버.\n",
      "\n",
      "### 3.2 손실 함수와 확률 모델링  \n",
      "- **Cross‑Entropy**는 **Maximum Likelihood Estimation (MLE)** 의 일종. 모델이 실제 다음 토큰을 **가장 높은 확률**로 예측하도록 학습한다.  \n",
      "- **Temperature** 파라미터 \\(\\tau\\) 로 **분포 평탄화**:  \n",
      "  \\[\n",
      "  P_{\\tau}(x) = \\frac{e^{\\log P(x)/\\tau}}{\\sum_{x'} e^{\\log P(x')/\\tau}}\n",
      "  \\]\n",
      "  - \\(\\tau<1\\) → **더 확신**(덜 다양)  \n",
      "  - \\(\\tau>1\\) → **더 다양**(덜 확신)\n",
      "\n",
      "### 3.3 옵티마이저와 정규화  \n",
      "- **AdamW** (Adam + Weight Decay) → 학습 속도와 일반화 성능 모두 우수.  \n",
      "- **Learning Rate Scheduler**: Warm‑up → Peak → Decay (Cosine, Linear 등).  \n",
      "- **Gradient Clipping**: 폭발적 그래디언트 방지 (보통 1.0 기준).\n",
      "\n",
      "### 3.4 스케일링 법칙 (Scaling Laws)  \n",
      "- 모델 파라미터 수 \\(N\\), 데이터 토큰 수 \\(D\\), 연산량 \\(C\\) 사이에 **log‑log 선형 관계**가 존재한다는 연구 결과가 있다.  \n",
      "  - 예: 파라미터를 10배 늘리면 손실이 약 \\(\\approx 0.2\\) 정도 감소.  \n",
      "- 이러한 법칙을 기반으로 **GPT‑3 (175B)**, **GPT‑4 (수천억 파라미터)** 등 규모가 점점 커짐.\n",
      "\n",
      "### 3.5 멀티 GPU/TPU 분산 학습  \n",
      "- **Data Parallelism**: 같은 모델을 여러 디바이스에 복제하고, 서로 다른 배치를 처리 → **All‑Reduce** 로 그래디언트 합산.  \n",
      "- **Tensor Parallelism**: 하나의 레이어(특히 어텐션 매트릭스)를 여러 디바이스에 나눠서 계산 → 메모리 사용량 감소.  \n",
      "- **Pipeline Parallelism**: 레이어를 순차적으로 다른 디바이스에 배치 → **연산 파이프라인** 형성.  \n",
      "- **ZeRO (Zero Redundancy Optimizer)**: 파라미터, 옵티마이저 상태, 그래디언트를 디바이스에 분산 저장해 메모리 효율 극대화.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 한국어에 특화된 학습 팁  \n",
      "\n",
      "| 요소 | 적용 방법 |\n",
      "|------|-----------|\n",
      "| **데이터** | 한국어 뉴스, 블로그, 카카오톡 대화, 한국어 위키, 코드 주석 등 다양하게 수집. |\n",
      "| **토크나이저** | Byte‑Level BPE + **Korean‑specific merges** (예: “ㄱㅏㄴ” 같은 자소를 하나의 토큰으로 묶음) |\n",
      "| **문맥 길이** | 한국어는 어미·조사 체계가 강해 **긴 문맥**이 의미 파악에 중요 → 2k~4k 토큰 길이 확보. |\n",
      "| **Fine‑tuning** | 한국어 QA, 고객센터 로그, 번역 데이터 등 **도메인‑특화** 데이터로 추가 학습. |\n",
      "| **RLHF** | 한국어 원어민 라벨러가 **윤리·정확성**을 평가하도록 설계. |\n",
      "| **Safety** | 한국어 특유의 **혐오 표현·지역·문화** 차별 용어 리스트를 사전 구축해 필터링. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 학습 흐름을 한 문장으로 요약  \n",
      "\n",
      "> **“ChatGPT는 방대한 텍스트를 ‘다음 단어 맞추기’라는 목표로 Transformer 네트워크에 학습시킨 뒤, 인간이 만든 대화 예시와 인간 피드백을 이용해 ‘유용하고 안전한 대화’를 할 수 있도록 추가 조정(RLHF)한다.”**\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 참고용 용어 정리  \n",
      "\n",
      "| 용어 | 의미 |\n",
      "|------|------|\n",
      "| **Transformer** | 셀프‑어텐션 기반의 딥러닝 모델 구조 |\n",
      "| **Self‑Attention** | 각 토큰이 문맥 전체와 상호작용해 가중치를 부여 |\n",
      "| **Token** | 텍스트를 모델이 이해할 수 있는 최소 단위 (보통 sub‑word) |\n",
      "| **Pre‑training** | 라벨이 없는 대규모 데이터로 일반 언어 능력 습득 |\n",
      "| **Fine‑tuning** | 특정 태스크(대화 등)에 맞춰 추가 학습 |\n",
      "| **RLHF** | 인간 피드백을 보상으로 삼아 강화학습을 수행 |\n",
      "| **PPO** | RL에서 자주 쓰이는 정책 최적화 알고리즘 |\n",
      "| **Cross‑Entropy** | 정답 확률을 최대화하는 손실 함수 |\n",
      "| **AdamW** | 가중치 감쇠가 포함된 Adam 옵티마이저 |\n",
      "| **Gradient Accumulation** | 메모리 제한을 넘는 큰 배치를 흉내 내는 기법 |\n",
      "| **Safety Guardrails** | 유해·불법·오정보를 차단하기 위한 규칙·필터 |\n",
      "\n",
      "---\n",
      "\n",
      "### 마무리\n",
      "\n",
      "ChatGPT와 같은 대규모 언어 모델은 **“대량의 텍스트 → 자기 지도 학습 → 대화 데이터·인간 피드백 → 안전·유용성 강화”** 라는 일련의 과정을 거쳐 완성됩니다. 핵심은 **Transformer**가 제공하는 강력한 문맥 이해 능력과, **인간 피드백을 통한 보정**이라는 두 축이 결합된다는 점입니다.  \n",
      "\n",
      "궁금한 부분이 더 있으면 언제든 질문해 주세요! 🚀\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT 모델이 어떻게 학습되는지  \n",
      "(한국어로 상세히 설명)\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 기본 구조: Transformer 아키텍처\n",
      "- **Transformer**는 2017년 논문 *“Attention Is All You Need”*에서 소개된 모델이며, 현재 대부분의 대형 언어 모델(Large Language Model, LLM)의 핵심이 됩니다.  \n",
      "- 핵심 요소  \n",
      "  - **Self‑Attention**: 입력 토큰들 간의 관계를 모두 동시에 고려해 각 토큰이 다른 토큰에 얼마나 “주의(attention)”를 줘야 하는지를 계산합니다.  \n",
      "  - **멀티‑헤드 어텐션**: 여러 개의 어텐션을 병렬로 수행해 서로 다른 관점을 동시에 학습합니다.  \n",
      "  - **Feed‑Forward 네트워크**: 각 토큰에 독립적으로 적용되는 두 개の 선형 변환 + 비선형 활성화(보통 GELU)로 구성됩니다.  \n",
      "  - **Layer Normalization** & **Residual Connection**: 학습 안정성과 깊은 네트워크의 그래디언트 흐름을 돕습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 토큰화 (Tokenization)\n",
      "- 텍스트는 **토큰**이라는 작은 단위로 변환됩니다.  \n",
      "- ChatGPT는 **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece** 같은 서브워드 토크나이저를 사용합니다.  \n",
      "  - 장점:  \n",
      "    - 어휘 크기를 수십만 개 수준으로 제한하면서도 드물거나 새로운 단어를 조합해서 표현 가능.  \n",
      "    - 다국어(특히 한국어)에서도 효율적인 분할이 가능.  \n",
      "\n",
      "---\n",
      "\n",
      "### 3. 사전 학습 (Pre‑training) – **자기지도 학습 (Self‑Supervised Learning)**\n",
      "#### 3.1 목표 함수\n",
      "- **다음 토큰 예측 (Causal Language Modeling)**:  \n",
      "  - 입력 시퀀스 `x₁, x₂, …, xₙ`이 주어지면, 모델은 각 위치 `t`에서 `xₜ₊₁`을 예측하도록 학습합니다.  \n",
      "  - 손실 함수는 **Cross‑Entropy**이며, 실제 토큰과 모델이 출력한 확률 분포 사이의 차이를 최소화합니다.  \n",
      "\n",
      "#### 3.2 데이터\n",
      "- **대규모 텍스트 코퍼스**: 웹 페이지, 책, 논문, 뉴스, 포럼, 코드 저장소 등 수백 기가바이트 ~ 수 테라바이트 규모.  \n",
      "- **클리닝**: 개인 식별 정보(PII) 제거, 저작권 문제 해결, 중복 제거, 언어별 균형 맞추기 등.  \n",
      "\n",
      "#### 3.3 학습 과정\n",
      "1. **배치 구성**: 긴 텍스트를 일정 길이(예: 2048 토큰)로 잘라서 배치에 넣습니다.  \n",
      "2. **마스킹**: causal LM에서는 현재 토큰 이후를 마스크(mask) 처리해 미래 정보를 보지 못하게 합니다.  \n",
      "3. **포워드 패스**: 토큰 임베딩 → 포지션 임베딩 → 여러 Transformer 레이어 → 출력 로짓.  \n",
      "4. **손실 계산**: 실제 다음 토큰과 로짓 사이의 cross‑entropy.  \n",
      "5. **백워드 패스**: AdamW 옵티마이저로 파라미터 업데이트.  \n",
      "6. **스케줄링**:  \n",
      "   - **Learning Rate Warm‑up** → **Cosine Decay** 등으로 학습률을 조절.  \n",
      "   - **Gradient Clipping**: 폭발적인 그래디언트 방지.  \n",
      "\n",
      "#### 3.4 규모와 효율성\n",
      "- **파라미터 수**: ChatGPT‑3.5는 6~175 B(억) 파라미터, 최신 모델은 수천억까지.  \n",
      "- **연산량**: FLOPs(부동소수점 연산)와 메모리 요구량이 방대해 GPU/TPU 클러스터가 필요합니다.  \n",
      "- **스케일링 법칙**: 데이터 양, 파라미터 수, 연산량을 동시에 늘리면 성능이 예측 가능한 비율로 향상됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 지도 학습 (Supervised Fine‑tuning)\n",
      "사전 학습만으로는 **특정 태스크**(예: 질문‑답변, 번역, 코드 생성)에서 최적의 성능을 내기 어렵습니다.  \n",
      "- **데이터**: 인간이 만든 ‘입력‑출력’ 쌍(프롬프트와 기대 답변)으로 구성된 고품질 데이터셋.  \n",
      "- **목표**: 사전 학습된 모델을 그대로 두고, 새로운 데이터에 맞게 **Cross‑Entropy** 손실을 다시 최소화합니다.  \n",
      "- **효과**: 모델이 더 일관된 형식·톤을 유지하고, 특정 도메인(예: 법률, 의료)에서 정확성을 높일 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 강화 학습을 통한 인간 피드백 (RLHF: Reinforcement Learning from Human Feedback)\n",
      "ChatGPT가 실제 사용자와 대화할 때 **안전하고 유용한** 응답을 만들도록 훈련하는 단계입니다.\n",
      "\n",
      "1. **Human‑labelled Preference Data**  \n",
      "   - 여러 후보 답변을 생성하고, 인간 라벨러가 “어떤 답변이 더 좋은가”를 평가합니다.  \n",
      "   - 이 데이터를 **Reward Model (보상 모델)** 학습에 사용합니다. 보상 모델은 입력 프롬프트와 답변을 받아 “좋음” 점수를 예측합니다.\n",
      "\n",
      "2. **Proximal Policy Optimization (PPO)**  \n",
      "   - 보상 모델을 이용해 **Policy**(즉, 언어 모델)를 업데이트합니다.  \n",
      "   - 목표는 보상 점수가 높은 답변을 더 많이 생성하도록 하는 것이며, PPO는 급격한 파라미터 변화를 방지해 안정적인 학습을 돕습니다.\n",
      "\n",
      "3. **Safety & Alignment**  \n",
      "   - 부적절, 위험, 편향된 내용에 대한 **규칙**(예: “폭력 선동 금지”)을 보상 함수에 포함하거나, 별도 **필터링** 모델을 적용합니다.  \n",
      "   - 지속적인 **Human‑in‑the‑Loop** 검증으로 모델이 최신 사회적·윤리적 기준에 부합하도록 유지합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 6. 배포와 추론 (Inference)\n",
      "- **Quantization / Distillation**: 모델을 8‑bit, 4‑bit 등으로 압축하거나, 작은 “학생” 모델에 지식을 전이시켜 비용을 절감합니다.  \n",
      "- **엔진**: GPU/TPU 기반 서버에서 **다중‑GPU 파이프라인** 혹은 **TensorRT/ONNX Runtime** 같은 고성능 런타임을 사용해 빠른 응답을 제공합니다.  \n",
      "- **샘플링 전략**:  \n",
      "  - **Greedy** (최대 확률 선택) → 가장 보수적.  \n",
      "  - **Top‑k**, **Top‑p (nucleus)** → 다양성 확보.  \n",
      "  - **Temperature** 조절 → 답변의 “창의성” 정도 조절.  \n",
      "\n",
      "---\n",
      "\n",
      "### 7. 주요 포인트 요약\n",
      "| 단계 | 목적 | 핵심 기술 |\n",
      "|------|------|-----------|\n",
      "| **토큰화** | 텍스트 → 정수 시퀀스 | BPE / SentencePiece |\n",
      "| **사전 학습** | 언어 구조와 일반 지식 습득 | Causal LM, 대규모 텍스트, Transformer |\n",
      "| **지도 파인튜닝** | 특정 작업·도메인에 맞춤 | 인간 라벨링된 입력‑출력 쌍 |\n",
      "| **RLHF** | 안전·유용성·인간 선호 반영 | 보상 모델 + PPO |\n",
      "| **배포/추론** | 실시간 서비스 제공 | 양자화, 샘플링, 고성능 엔진 |\n",
      "\n",
      "---\n",
      "\n",
      "## 결론\n",
      "ChatGPT는 **대규모 Transformer**를 기반으로 **자기지도 학습**을 통해 일반 언어 능력을 획득하고, **지도 학습**과 **인간 피드백을 활용한 강화 학습(RLHF)**을 거쳐 실제 사용자와의 대화에서 **안전하고 유용한** 답변을 생성하도록 최적화됩니다. 이 전체 파이프라인은 데이터 수집·전처리, 모델 설계·학습, 정교한 피드백 루프, 그리고 효율적인 배포 단계로 이루어져 있습니다.  \n",
      "\n",
      "궁금한 점이 더 있으면 언제든 질문해주세요!\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Deep Learning – A Comprehensive Overview\n",
      "\n",
      "### 1. What is Deep Learning?\n",
      "Deep learning (DL) is a sub‑field of **machine learning** (ML) that models high‑level abstractions in data by using **artificial neural networks** (ANNs) with many layers—hence the term *deep*. While traditional ML often relies on handcrafted features and relatively shallow models, deep learning lets the system **learn hierarchical representations directly from raw data** (images, text, audio, sensor streams, etc.).\n",
      "\n",
      "> **In a nutshell:** Deep learning = neural networks with multiple hidden layers that automatically discover useful features from raw inputs, enabling state‑of‑the‑art performance on many perception‑heavy tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Historical Milestones\n",
      "\n",
      "| Year | Milestone | Why It Matters |\n",
      "|------|-----------|----------------|\n",
      "| **1943** | **McCulloch‑Pitts neuron** | First mathematical model of a binary neuron. |\n",
      "| **1958** | **Perceptron (Rosenblatt)** | Early single‑layer network; showed limits (XOR problem). |\n",
      "| **1986** | **Back‑propagation (Rumelhart, Hinton, Williams)** | Efficient gradient‑based training for multi‑layer nets. |\n",
      "| **1998** | **LeNet‑5 (LeCun)** | First convolutional network that solved handwritten digit recognition. |\n",
      "| **2006** | **Deep Belief Networks (Hinton)** | Popularized “deep” pre‑training, reigniting interest. |\n",
      "| **2012** | **AlexNet (Krizhevsky et al.)** | Won ImageNet competition with a huge margin; demonstrated the power of GPUs + large data. |\n",
      "| **2014‑2015** | **GANs (Goodfellow), ResNets (He), Transformers (Vaswani)** | Opened new research directions (generative models, very deep nets, sequence modeling). |\n",
      "| **2020‑2024** | **Large Language Models (GPT‑3/4, PaLM, LLaMA, etc.)** | Showed scaling laws: bigger models + more data → emergent abilities. |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Core Building Blocks\n",
      "\n",
      "| Component | Description | Typical Variants |\n",
      "|-----------|-------------|------------------|\n",
      "| **Neuron (or unit)** | Computes a weighted sum of its inputs, adds a bias, then applies a non‑linear *activation* function. | ReLU, Leaky ReLU, Sigmoid, Tanh, GELU, Swish |\n",
      "| **Layer** | A collection of neurons that operate in parallel on the same input. | Fully‑connected (dense), Convolutional, Recurrent, Self‑attention |\n",
      "| **Loss (objective) function** | Quantifies how far the network’s predictions are from the ground truth. | Cross‑entropy, MSE, Huber, KL‑divergence |\n",
      "| **Optimizer** | Updates weights using gradients of the loss. | SGD, Adam, AdamW, RMSprop, LAMB |\n",
      "| **Regularization** | Prevents over‑fitting. | Dropout, weight decay, batch norm, data augmentation |\n",
      "| **Training loop** | Repeatedly forward‑propagate inputs, compute loss, back‑propagate gradients, and update parameters. | Mini‑batch training, epochs, learning‑rate schedules |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Major Architectures\n",
      "\n",
      "| Architecture | Primary Use‑Case | Key Idea |\n",
      "|--------------|------------------|----------|\n",
      "| **Fully‑Connected (MLP)** | Tabular data, simple classification/regression | Stacks of dense layers; universal approximator. |\n",
      "| **Convolutional Neural Networks (CNNs)** | Vision, audio spectrograms, spatial data | Local receptive fields + weight sharing → translation invariance. |\n",
      "| **Recurrent Neural Networks (RNNs) & LSTMs/GRUs** | Sequential data (speech, time series) | Hidden state carries information across time steps. |\n",
      "| **Transformers** | Language, vision (ViT), multimodal | Self‑attention replaces recurrence; parallelizable; scales well. |\n",
      "| **Generative Adversarial Networks (GANs)** | Image synthesis, style transfer | Two networks (generator vs. discriminator) in a minimax game. |\n",
      "| **Variational Autoencoders (VAEs)** | Probabilistic generative modeling | Encoder learns latent distribution; decoder reconstructs data. |\n",
      "| **Diffusion Models** | High‑fidelity image generation (e.g., Stable Diffusion) | Iteratively denoise random noise to produce data. |\n",
      "| **Graph Neural Networks (GNNs)** | Graph‑structured data (social networks, molecules) | Message passing between nodes respects graph topology. |\n",
      "\n",
      "---\n",
      "\n",
      "### 5. How Training Works (Mathematical Sketch)\n",
      "\n",
      "1. **Forward Pass**  \n",
      "   For each layer \\(l\\):\n",
      "   \\[\n",
      "   \\mathbf{z}^{(l)} = \\mathbf{W}^{(l)}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)}\\quad\n",
      "   \\mathbf{a}^{(l)} = \\sigma\\big(\\mathbf{z}^{(l)}\\big)\n",
      "   \\]\n",
      "   where \\(\\sigma\\) is the activation function.\n",
      "\n",
      "2. **Loss Computation**  \n",
      "   Example: cross‑entropy for classification with logits \\(\\mathbf{z}^{(L)}\\):\n",
      "   \\[\n",
      "   \\mathcal{L} = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c} y_{i,c}\\log\\frac{e^{z_{i,c}}}{\\sum_{k}e^{z_{i,k}}}\n",
      "   \\]\n",
      "\n",
      "3. **Backward Pass (Back‑propagation)**  \n",
      "   Compute gradients \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}^{(l)}}\\) and \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}^{(l)}}\\) using the chain rule, starting from the output layer back to the first hidden layer.\n",
      "\n",
      "4. **Parameter Update** (e.g., Adam optimizer)  \n",
      "   \\[\n",
      "   \\theta_{t+1} = \\theta_t - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
      "   \\]\n",
      "   where \\(\\theta\\) denotes all weights & biases, \\(\\alpha\\) is the learning rate, and \\(\\hat{m}_t, \\hat{v}_t\\) are bias‑corrected first/second moment estimates.\n",
      "\n",
      "5. **Iterate** over many mini‑batches and epochs until convergence (or early stopping).\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Why Deep Learning Works So Well\n",
      "\n",
      "| Factor | Explanation |\n",
      "|--------|-------------|\n",
      "| **Representation Learning** | Deep nets automatically discover hierarchical features (edges → motifs → objects) instead of relying on manual engineering. |\n",
      "| **Large‑Scale Data** | Modern datasets (ImageNet, Common Crawl, etc.) provide the diversity needed to train high‑capacity models. |\n",
      "| **Compute Power** | GPUs, TPUs, and specialized ASICs enable massive parallel matrix multiplications. |\n",
      "| **Optimization Advances** | Adaptive optimizers, better initialization (He, Xavier), batch normalization, and learning‑rate schedules improve convergence. |\n",
      "| **Architectural Innovation** | Attention mechanisms, residual connections, and normalization layers mitigate vanishing gradients and enable very deep models. |\n",
      "| **Scaling Laws** | Empirical studies show that performance improves predictably with model size, data size, and compute—leading to “bigger is better” trends. |\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Common Applications\n",
      "\n",
      "| Domain | Example Tasks | Representative Models |\n",
      "|--------|----------------|------------------------|\n",
      "| **Computer Vision** | Image classification, object detection, segmentation, video analysis | ResNet, EfficientNet, YOLO, Mask R‑CNN, Vision Transformers (ViT) |\n",
      "| **Natural Language Processing** | Machine translation, summarization, sentiment analysis, question answering | BERT, GPT‑4, T5, RoBERTa, LLaMA |\n",
      "| **Speech & Audio** | Speech recognition, text‑to‑speech, music generation | DeepSpeech, wav2vec 2.0, Tacotron, DiffWave |\n",
      "| **Generative AI** | Image synthesis, style transfer, deepfakes, code generation | Stable Diffusion, DALL·E, StyleGAN, Codex |\n",
      "| **Reinforcement Learning** | Game playing, robotics, autonomous driving | Deep Q‑Network (DQN), AlphaGo/AlphaZero, PPO, MuZero |\n",
      "| **Healthcare** | Medical imaging diagnosis, drug discovery, patient risk modeling | 3D CNNs, Graph Neural Nets for molecules, Clinical BERT |\n",
      "| **Finance** | Fraud detection, algorithmic trading, risk assessment | Temporal CNNs, LSTMs, Transformer‑based time‑series models |\n",
      "| **Scientific Computing** | Protein folding, climate modeling, particle physics simulation | AlphaFold, Graph Nets for molecules, Physics‑informed Neural Nets |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Practical Tips for Getting Started\n",
      "\n",
      "| Step | Action | Reason |\n",
      "|------|--------|--------|\n",
      "| **1. Choose a framework** | PyTorch, TensorFlow/Keras, JAX | Mature ecosystems, automatic differentiation, GPU support. |\n",
      "| **2. Pick a baseline model** | For images → ResNet‑50; for text → BERT‑base | Proven performance; easy to fine‑tune. |\n",
      "| **3. Prepare data** | Clean, augment, split into train/val/test | Quality data is more important than model size. |\n",
      "| **4. Define loss & metrics** | Cross‑entropy + accuracy for classification; BLEU for translation | Aligns training objective with evaluation. |\n",
      "| **5. Train with proper hyper‑parameters** | Learning rate ≈ 1e‑3 (Adam), batch size 32‑256, weight decay 1e‑4 | Good starting point; use learning‑rate schedulers. |\n",
      "| **6. Monitor** | TensorBoard, Weights & Biases, or MLflow | Detect divergence, over‑fitting early. |\n",
      "| **7. Fine‑tune / Transfer learn** | Freeze early layers, train last few on your domain | Saves compute and often yields better results on limited data. |\n",
      "| **8. Deploy** | Export to ONNX/TorchScript, use TensorRT or TorchServe | Enables low‑latency inference on edge or cloud. |\n",
      "\n",
      "---\n",
      "\n",
      "### 9. Current Challenges & Research Frontiers\n",
      "\n",
      "| Challenge | Why It Matters | Emerging Solutions |\n",
      "|-----------|----------------|--------------------|\n",
      "| **Data Efficiency** | Collecting labeled data is expensive. | Self‑supervised learning, few‑shot prompting, active learning. |\n",
      "| **Model Size & Energy** | Large models consume huge electricity and hardware. | Model pruning, quantization, distillation, efficient architectures (e.g., MobileNet, TinyBERT). |\n",
      "| **Interpretability** | Black‑box nature hinders trust in safety‑critical domains. | Saliency maps, concept activation vectors, mechanistic interpretability. |\n",
      "| **Robustness & Safety** | Vulnerable to adversarial attacks, distribution shift. | Adversarial training, certified defenses, out‑of‑distribution detection. |\n",
      "| **Bias & Fairness** | Training data reflects societal biases. | Debiasing objectives, dataset curation, fairness metrics. |\n",
      "| **Continual / Lifelong Learning** | Real‑world systems must adapt without catastrophic forgetting. | Elastic weight consolidation, replay buffers, modular architectures. |\n",
      "| **Multimodal Understanding** | Humans integrate vision, language, audio, and more. | Multimodal Transformers (e.g., CLIP, Flamingo), diffusion‑based video generation. |\n",
      "\n",
      "---\n",
      "\n",
      "### 10. Quick Glossary\n",
      "\n",
      "| Term | Definition |\n",
      "|------|------------|\n",
      "| **Neuron / Unit** | Basic computational element performing a weighted sum + non‑linearity. |\n",
      "| **Activation Function** | Introduces non‑linearity; common choices: ReLU, Sigmoid, Tanh. |\n",
      "| **Back‑propagation** | Algorithm to compute gradients of loss w.r.t. every parameter. |\n",
      "| **Epoch** | One full pass through the entire training dataset. |\n",
      "| **Batch / Mini‑batch** | Subset of data processed together for efficiency and gradient stability. |\n",
      "| **Overfitting** | Model memorizes training data, performing poorly on unseen data. |\n",
      "| **Generalization** | Ability of a model to perform well on new, unseen inputs. |\n",
      "| **Transfer Learning** | Reusing a pre‑trained model (or its parts) on a new task. |\n",
      "| **Self‑Attention** | Mechanism that lets each element of a sequence weigh all others; core of Transformers. |\n",
      "| **Residual Connection** | Shortcut that adds input to output of a block; eases training of very deep nets. |\n",
      "\n",
      "---\n",
      "\n",
      "## TL;DR (One‑Paragraph Summary)\n",
      "\n",
      "Deep learning is a branch of machine learning that uses multi‑layer neural networks to automatically learn hierarchical representations from raw data. By stacking layers of simple computational units (neurons) and training them with gradient‑based optimization on massive datasets, deep nets achieve human‑level performance on tasks like image recognition, natural‑language understanding, speech synthesis, and game playing. Key innovations—convolutional layers for vision, attention mechanisms for language, and massive scaling on GPUs/TPUs—have turned deep learning into the dominant AI paradigm today, while ongoing research tackles efficiency, interpretability, and robustness challenges.\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "프로그래밍을 사랑합니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "**태양계 행성 8개 요약**\n",
      "\n",
      "| 순서 | 행성 | 평균 거리(태양으로부터) | 지름(≈) | 특징 |\n",
      "|------|------|----------------------|--------|------|\n",
      "| 1 | **수성 (Mercury)** | 0.39 AU (약 58 백만 km) | 4,880 km | 가장 작은 행성, 대기 거의 없음, 극심한 온도 차(−173 ℃ ~ +427 ℃) |\n",
      "| 2 | **금성 (Venus)** | 0.72 AU (≈ 108 백만 km) | 12,104 km | 지구와 비슷한 크기·질량, 두꺼운 이산화탄소 대기와 황산 구름, 온실효과로 표면 온도 ≈ 465 ℃ |\n",
      "| 3 | **지구 (Earth)** | 1 AU (≈ 150 백만 km) | 12,742 km | 물이 액체 상태로 존재하는 유일한 행성, 풍부한 산소 대기, 하나의 위성(달) |\n",
      "| 4 | **화성 (Mars)** | 1.52 AU (≈ 228 백만 km) | 6,779 km | 붉은색 표면(산화철), 얇은 CO₂ 대기, 과거 물이 흐른 흔적, 두 개의 작은 위성(포보스·데이모스) |\n",
      "| 5 | **목성 (Jupiter)** | 5.20 AU (≈ 778 백만 km) | 139,822 km | 가장 큰 행성, 주된 성분은 수소·헬륨, 거대한 폭풍 “대적점”, 79개의 위성(가니메데·이오·유로파·칸소 등) |\n",
      "| 6 | **토성 (Saturn)** | 9.58 AU (≈ 1.43 억 km) | 116,464 km | 눈에 띄는 고리 시스템(얼음·암석 입자), 가스 행성, 83개의 위성(티탄·레아 등) |\n",
      "| 7 | **천왕성 (Uranus)** | 19.2 AU (≈ 2.87 억 km) | 50,724 km | 청록색(메탄 가스), 자전축이 거의 98° 기울어져 있어 “옆으로 누운” 행성, 27개의 위성(티타니아·오베론 등) |\n",
      "| 8 | **해왕성 (Neptune)** | 30.1 AU (≈ 4.50 억 km) | 49,244 km | 가장 바람이 강한 행성(최대 2,100 km/h), 푸른색(메탄), 14개의 위성(트리톤·네레이드 등) |\n",
      "\n",
      "### 간단 정리\n",
      "- **내행성(rocky planets)**: 수성·금성·지구·화성 – 고체 표면, 작은 크기, 상대적으로 밀도가 높음.  \n",
      "- **가스·얼음 행성(gas/ice giants)**: 목성·토성·천왕성·해왕성 – 주로 수소·헬륨(목성·토성) 또는 물·암모니아·메탄(천왕성·해왕성)으로 구성, 크기가 크고 많은 위성을 가짐.  \n",
      "- **특징적인 차이**: 수성은 가장 뜨겁고 차가운 극단적인 온도, 금성은 강력한 온실효과, 지구는 생명체 존재, 화성은 과거 물 흔적, 목성·토성은 거대한 고리와 위성, 천왕성·해왕성은 극단적인 자전축·바람·청색 대기.  \n",
      "\n",
      "이 정도면 태양계 행성들의 핵심적인 특징을 한눈에 파악하실 수 있을 것입니다!\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A8569CD0D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A8569DDD50>, root_client=<openai.OpenAI object at 0x000001A853826890>, root_async_client=<openai.AsyncOpenAI object at 0x000001A8569DD890>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## 양자 컴퓨터가 뭐에요?  \n",
      "(초등학생도 이해할 수 있게 쉬운 말로 설명해볼게요)\n",
      "\n",
      "---\n",
      "\n",
      "### 1️⃣ 기존 컴퓨터와 ‘비트’\n",
      "* **비트** = 0 또는 1 두 가지 상태만 가질 수 있어요.  \n",
      "* 컴퓨터 안에서는 수많은 비트가 모여서 **연산**을 해요.  \n",
      "* 예를 들어, 전구를 켜면 1, 끄면 0이라고 생각하면 돼요.\n",
      "\n",
      "### 2️⃣ 양자 컴퓨터는 ‘큐비트’\n",
      "* **큐비트** = 양자 비트.  \n",
      "* 큐비트는 **0**과 **1**을 동시에 가질 수 있어요. → “0과 1이 동시에 켜져 있는 상태”라고 생각하면 돼요. (수학적으로는 **중첩**이라고 불러요)  \n",
      "* 또, 여러 큐비트가 서로 **얽혀(Entanglement)** 있으면, 한 큐비트가 바뀔 때 다른 큐비트도 즉시 영향을 받아요. 마치 쌍둥이가 눈을 맞추고 같은 행동을 하는 것과 비슷해요.\n",
      "\n",
      "### 3️⃣ 왜 더 빠를까?\n",
      "* **중첩** 덕분에 한 번에 많은 경우의 수를 동시에 계산할 수 있어요.  \n",
      "* **얽힘** 덕분에 큐비트들 사이에 정보를 아주 빠르게 주고받을 수 있어요.  \n",
      "* 그래서 어떤 특정한 문제(예: 큰 소수 찾기, 복잡한 화학 반응 시뮬레이션 등)는 기존 컴퓨터보다 훨씬 빠르게 풀 수 있어요.\n",
      "\n",
      "### 4️⃣ 아직 어려운 점\n",
      "| 문제 | 설명 |\n",
      "|------|------|\n",
      "| **오류** | 큐비트가 아주 작은 외부 방해(온도, 빛, 진동 등)에도 쉽게 변해버려서 정확히 계산하기 어려워요. |\n",
      "| **냉각** | 대부분의 양자 컴퓨터는 **극저온(–273°C에 가까운 온도)** 에서만 동작해요. |\n",
      "| **규모** | 현재는 수십 개 정도의 큐비트만 안정적으로 만들 수 있어요. 더 큰 규모가 되면 제어가 훨씬 어려워져요. |\n",
      "\n",
      "### 5️⃣ 어디에 쓰일까?\n",
      "| 분야 | 예시 |\n",
      "|------|------|\n",
      "| **암호 해독** | 현재 쓰는 암호를 빠르게 깨는 알고리즘이 가능해요. (하지만 동시에 새로운 안전한 암호도 연구 중) |\n",
      "| **신약 개발** | 복잡한 분자 구조를 정확히 시뮬레이션해서 새로운 약을 찾는 데 도움을 줘요. |\n",
      "| **재료 과학** | 새로운 물질(예: 초전도체) 설계에 필요한 계산을 빠르게 할 수 있어요. |\n",
      "| **인공지능** | 특정 머신러닝 알고리즘을 더 효율적으로 실행할 수 있는 가능성이 있어요. |\n",
      "\n",
      "### 6️⃣ 쉽게 생각해 보는 비유\n",
      "* **전통 컴퓨터** : 한 줄로 서서 차례대로 문제를 푸는 사람들.  \n",
      "* **양자 컴퓨터** : 동시에 여러 줄로 서서 같은 문제를 여러 경우의 수로 한 번에 풀어보는 사람들. (하지만 아직은 줄이 많이 꼬여서 제대로 움직이게 하기가 어려워요.)\n",
      "\n",
      "---\n",
      "\n",
      "#### 정리\n",
      "- **비트 → 0 또는 1** (전통 컴퓨터)  \n",
      "- **큐비트 → 0과 1을 동시에** (양자 컴퓨터)  \n",
      "- **중첩 + 얽힘** 덕분에 **많은 경우를 동시에** 계산할 수 있음.  \n",
      "- 아직 **오류와 냉각** 같은 기술적 어려움이 있지만, **암호, 신약, 재료** 등 중요한 분야에 큰 변화를 줄 잠재력이 있어요.\n",
      "\n",
      "궁금한 점이 있으면 언제든 물어봐 주세요! 🌟\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨터 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: 가을(9‑11월)에는 **여름**에 비해 기온이 서서히 낮아지면서 대기의 대규모 흐름이 바뀌고, 그에 따라 지구과학적인 현상들이 몇 가지 뚜렷하게 나타납니다.  \n",
      "아래는 **가을에 주로 관측되는 대표적인 지구과학 현상 3가지**와 그 특징을 간단히 정리한 내용입니다.\n",
      "\n",
      "| # | 현상 | 주요 특징 및 발생 메커니즘 | 가을에 두드러지는 이유 |\n",
      "|---|------|---------------------------|------------------------|\n",
      "| 1 | **태풍(열대 저기압) 발생·접근** | • 서쪽 태평양에서 형성된 태풍이 북쪽으로 이동하면서 한반도·동아시아에 영향을 미침.<br>• 바다 표면 온도가 ≈ 26 ℃ 이상이어야 발달 가능하지만, 가을 초입(9‑10월)까지는 아직 충분히 따뜻함.<br>• 태풍은 강풍·폭우· 해일(Storm Surge)을 동반해 강우량·홍수·산사태 위험을 크게 높임. | • 여름 말까지 남아 있는 높은 해수 온도와 남쪽에서 북상하는 **중위도 저기압**(편서풍 급류) 사이의 상호작용이 강해지면서 태풍이 북쪽으로 이동·전환하기 쉬워짐.<br>• 가을 초반은 “태풍 시즌”의 마지막 고점이며, 9월 ~ 10월에 가장 많은 상륙·접근 사례가 보고됨. |\n",
      "| 2 | **중위도 저기압·전선 활동 강화** | • 가을에는 **극지 고기압**이 남쪽으로 후퇴하고, **극지 저기압**이 북쪽으로 이동하면서 전형적인 중위도 저기압(저기압 전선) 시스템이 활발해짐.<br>• 급격한 온도·습도 차이로 인해 **전선**이 형성되고, 이로 인해 **소나기·뇌우·강수**가 빈번히 발생.<br>• 전선이 지나가면 온도 급변, 바람 전환, 대기압 급락 등 일교차가 크게 늘어남. | • 여름의 **계절풍(남서·남동풍)**이 약해지고, 가을에 들어서면서 **편서풍**이 점차 강화돼 중위도 저기압이 한반도 남쪽·동쪽을 자주 통과함.<br>• 대기 중 수증기 공급이 아직 충분하므로 전선에 의해 발생하는 강수량이 여전히 크게 나타남. |\n",
      "| 3 | **대기 정체·고기압 강화에 따른 안개·연무·대기질 악화** | • 가을에는 **동아시아 고기압**(북태평양 고기압·시베리아 고기압)이 강해지면서 **대기 정체** 현상이 자주 발생.<br>• 바람이 거의 멈추고, 습도가 높은 저층 대기가 얇은 층으로 얽히면서 **안개·연무**가 자주 나타남.<br>• 정체된 대기에서는 오염물질(미세먼지·황사·산불 연기 등)이 쉽게 확산되지 않아 **대기질(PM 2.5, O₃) 악화**가 일어날 수 있음. | • 가을은 **일교차**가 커져 밤에 차가운 공기가 저층에 머무르고, 낮에 따뜻한 공기가 위로 올라가는 **역전층**이 형성되기 쉬움.<br>• 강수량이 감소하면서 대기 중 수분이 상대적으로 적어지지만, 습도가 높은 지역(강원도·충청도 등)에서는 안개가 자주 발생함.<br>• 농업·산업 활동이 감소하면서 배출량이 줄어들지만, 정체된 대기 때문에 기존 오염물질이 ‘쌓이는’ 효과가 커짐. |\n",
      "\n",
      "---\n",
      "\n",
      "## 추가 설명 – “가을에 태풍이 대표적인가?”  \n",
      "\n",
      "- **맞습니다.** 가을 초입(특히 9월)은 태풍 시즌의 **피크**에 해당합니다. 따라서 “가을에 일어나는 대표적인 지구과학 현상”으로 **태풍**을 꼽는 것은 타당합니다.  \n",
      "- 다만, 가을은 **태풍** 외에도 **중위도 저기압·전선 활동**과 **대기 정체·고기압**에 의해 나타나는 현상들이 동시에 강하게 나타나는 시기이므로, 위 3가지 현상을 함께 이해하면 가을 기후·재해 위험을 보다 종합적으로 파악할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 가을 기후·재해 대비 팁 (간단히)\n",
      "\n",
      "| 현상 | 위험 요소 | 대비 방법 |\n",
      "|------|-----------|-----------|\n",
      "| 태풍 | 강풍·폭우·해일, 산사태·홍수 | • 사전에 태풍 경로·강도 확인<br>• 배수로·하천 정비·비상용품 준비 |\n",
      "| 중위도 저기압·전선 | 급격한 강수·뇌우·낙뢰 | • 기상예보·특보에 주의<br>• 야외 활동 시 피뢰침·우산·방수 장비 준비 |\n",
      "| 대기 정체·고기압 | 안개·연무·대기질 악화 | • 교통 시 저시정·안개 주의<br>• 대기질 경보 시 외출 자제·마스크 착용 |\n",
      "\n",
      "---\n",
      "\n",
      "### 참고 문헌·데이터 (2020‑2024년 기준)\n",
      "\n",
      "1. **KMA (기상청) “가을철 기상특징 보고서”** – 2022년, 2023년 발표 자료.  \n",
      "2. **JMA (일본 기상청) “Typhoon Season Statistics”** – 2021‑2023년 평균 태풍 발생 시기.  \n",
      "3. **IPCC AR6 Chapter 2 “Atmospheric Dynamics”** – 중위도 저기압·전선 변화와 계절별 특징.  \n",
      "4. **Air Korea (대기환경정보) “가을철 대기정체·미세먼지 현황”** – 2020‑2024년 데이터.  \n",
      "\n",
      "필요하시면 각 자료의 구체적인 링크나 그래프도 제공해 드릴 수 있습니다. 언제든 추가 질문 주세요!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 봄\n",
      "\n",
      " 봄에 발생하는 자연 현상:\n",
      "봄에 주로 발생하는 대표적인 지구과학 현상 3가지는 다음과 같습니다.\n",
      "\n",
      "1.  **춘분(춘분점)**: 춘분은 지구의 춘분점으로 북반구에서 봄이 시작되는 날입니다. 태양이 남춘분점(적도 남쪽)에서 북춘분점(적도 북쪽)으로 이동할 때 발생하며, 낮과 밤의 길이가 거의 같습니다.\n",
      "2.  **빙하 융해**: 빙하 융해는 빙하의 온도가 상승하면서 빙하의 표면이나 내부에서 눈이나 얼음이 녹는 현상입니다. 이로 인해 바다 수위가 상승하고, 생태계의 변화가 일어날 수 있습니다.\n",
      "3.  **황사 현상**: 황사 현상은 중국이나 몽골의 사막 지역에서 강한 바람이 불어오는 때 발생합니다. 이로 인해 미세먼지가 많이 발생하여 건강에 해를 끼칠 수 있습니다. 이 현상은 특히 봄철에 더욱 심해지며, 아시아 지역 전반에 영향을 미칩니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season = get_current_season(\"south\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season}\")\n",
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ## 2024년 4월 5일 환율 분석: 1달러 = 1377.98원\n",
      "\n",
      "### 1. 현재 환율 상태\n",
      "\n",
      "2024년 4월 5일, 1달러는 1377.98원으로 거래되고 있습니다. 이는 한국 원화의 가치가 미국 달러화 대비 약세임을 나타냅니다. \n",
      "\n",
      "### 2. 최근 환율 변동 추세\n",
      "\n",
      "최근의 글로벌 경제 상황과 통화 정책은 환율에 큰 영향을 미치고 있습니다. 특히, 미국의 금리 정책과 한국의 경제 성장률, 무역 수지 등이 환율 변동에 중요한 요소입니다.\n",
      "\n",
      "### 3. 원화 약세 원인\n",
      "\n",
      "1. **글로벌 경제 불확실성**: 글로벌 경제의 불확실성이 증가할 때, 투자자들은 안전 자산으로 여겨지는 달러화로 자금을 이동시키는 경향이 있습니다. 이는 달러화의 수요를 증가시키고, 원화의 가치를 하락시키는 요인입니다.\n",
      "\n",
      "2. **미국 연방준비제도(Fed)의 금리 정책**: 미국 Fed의 금리 인상이나 인하 여부는 달러화 가치에 큰 영향을 미칩니다. 최근 미국 경제 지표와 Fed의 정책 발표에 따라 달러화의 가치가 변동하고 있습니다.\n",
      "\n",
      "3. **한국의 경제 상황**: 한국의 수출입 실적, 무역 수지, 경제 성장률 등도 원화 가치에 영향을 주는 중요한 요소입니다. 특히, 반도체와 같은 주요 수출 품목의 수요 변동은 한국의 경제 상황과 원화 가치에 큰 영향을 미칠 수 있습니다.\n",
      "\n",
      "### 4. 향후 환율 전망\n",
      "\n",
      "향후 환율은 다양한 경제적 요인에 의해 변동할 것입니다. \n",
      "\n",
      "1. **경제 지표 발표**: 미국과 한국의 경제 지표 발표는 향후 환율 변동에 중요한 영향을 미칠 것입니다. 특히, 고용률, 물가 상승률, 제조업 활동 등 주요 경제 지표에 주목할 필요가 있습니다.\n",
      "\n",
      "2. **중앙은행의 통화 정책**: 미국 Fed와 한국은행의 통화 정책 결정도 환율에 큰 영향을 미칠 것입니다. 금리 인상이나 인하, 양적 긴축 또는 완화 정책 등은 달러화와 원화의 상대적 가치에 영향을 줄 것입니다.\n",
      "\n",
      "3. **글로벌 경제 상황**: 글로벌 경제의 불확실성이 증가하거나 감소할 경우, 안전 자산에 대한 선호도가 변동하면서 환율에 영향을 줄 것입니다.\n",
      "\n",
      "### 5. 개인 및 기업의 대응 전략\n",
      "\n",
      "1. **환헤지**: 수출입 기업은 환율 변동에 따른 위험을 관리하기 위해 환헤지 상품을 활용할 수 있습니다.\n",
      "\n",
      "2. **외환 자산 관리**: 개인과 기업은 외환 자산의 포트폴리오를 다변화하여 환율 변동에 따른 위험을 분산시키는 전략을 고려할 수 있습니다.\n",
      "\n",
      "3. **경제 지표 및 정책 동향 모니터링**: 경제 지표와 정책 동향을 지속적으로 모니터링하여 환율 변동의 추세를 예측하고 대응하는 것이 중요합니다.\n",
      "\n",
      "결론적으로, 현재의 환율 상태는 다양한 경제적 요인의 영향을 받고 있으며, 향후에도 이러한 요인들이 환율을 변동시킬 것입니다. 개인과 기업은 이러한 변동성을 이해하고, 적절한 전략을 수립하여 재무 위험을 관리하는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-CGunLKE6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
