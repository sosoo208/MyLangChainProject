{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_L\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "#load_dotenv(dotenv_path='../.env')\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate ì˜ from_template() í•¨ìˆ˜ ì‚¬ìš©\n",
    "* ì£¼ë¡œ LLM(í…ìŠ¤íŠ¸ ì™„ì„±í˜• ëª¨ë¸, ex. Ollama, GPT-3.5)ê³¼ í•¨ê»˜ ì‚¬ìš©\n",
    "* í•˜ë‚˜ì˜ ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPTëŠ” ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ì‚¬ì „ í•™ìŠµ(preâ€‘training)ë©ë‹ˆë‹¤. ì´ë•Œ ëª¨ë¸ì€ ì…ë ¥ëœ '\n",
      " 'ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ í† í°ì„ ì„ íƒí•˜ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ë©°, ìˆ˜ì‹­ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ì„œë¡œ ì—°ê²°ë˜ì–´ ì–¸ì–´ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤. '\n",
      " 'ì´í›„ ì¸ê°„ í”¼ë“œë°±ì„ í™œìš©í•œ ê°•í™”í•™ìŠµ(RLHF) ë“±ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •(fineâ€‘tuning)í•˜ì—¬ ì‹¤ì œ ëŒ€í™” ìƒí™©ì—ì„œ ë” ì•ˆì „í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ '\n",
      " 'ìƒì„±í•˜ë„ë¡ ìµœì í™”ë©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate ê²°í•©í•˜ê¸°\n",
    "* ë™ì¼í•œ Prompt íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì„ ì‘ì„±í•´ì„œ LLMì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.'\n",
      "('**ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ (3ë¬¸ì¥)**  \\n'\n",
      " '1. ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ Transformer ê¸°ë°˜ì˜ ì‹ ê²½ë§ì„ ì‚¬ì „ í•™ìŠµ(preâ€‘training)í•˜ì—¬ ì–¸ì–´ êµ¬ì¡°ì™€ ì˜ë¯¸ë¥¼ '\n",
      " 'ì¼ë°˜í™”í•©ë‹ˆë‹¤.  \\n'\n",
      " '2. ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‹¤ì œ ëŒ€í™”ë‚˜ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¸ê°„ í”¼ë“œë°±ì„ í™œìš©í•œ ê°•í™”í•™ìŠµ(RLHF)ìœ¼ë¡œ ë¯¸ì„¸ '\n",
      " 'ì¡°ì •(fineâ€‘tuning)í•©ë‹ˆë‹¤.  \\n'\n",
      " '3. í•™ìŠµ ê³¼ì •ì—ì„œ ì†ì‹¤ í•¨ìˆ˜(Loss)ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•´, ì…ë ¥ì— ëŒ€í•œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¤ìŒ í† í°ì„ '\n",
      " 'ì˜ˆì¸¡í•˜ë„ë¡ ëª¨ë¸ì„ ìµœì í™”í•©ë‹ˆë‹¤.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT ëª¨ë¸ì˜ ì£¼ìš” ì¥ì  ìš”ì•½\\n'\n",
      " '- **ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ë†’ì€ ì´í•´ë„**: ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤ë¡œ í•™ìŠµë¼ ì¼ë°˜ ìƒì‹, ì „ë¬¸ ì§€ì‹, ë¬¸í™”ì  ë§¥ë½ ë“±ì„ í­ë„“ê²Œ '\n",
      " 'íŒŒì•…í•©ë‹ˆë‹¤.  \\n'\n",
      " '- **ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„**: ë¬¸ë§¥ì„ ì¶”ì í•˜ê³  ì´ì „ ë°œì–¸ì„ ê¸°ì–µí•´ ì¼ê´€ëœ ëŒ€í™”ì™€ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.  \\n'\n",
      " '- **ë¹ ë¥¸ ì ìš©ì„±**: ì‚¬ì „ í•™ìŠµ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •ë§Œìœ¼ë¡œë„ ì±—ë´‡, ë²ˆì—­, ìš”ì•½, ì½”ë“œ ìƒì„± ë“± ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì— ë°”ë¡œ í™œìš©í•  '\n",
      " 'ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPTì™€ ë¹„ìŠ·í•œ AI ëª¨ë¸ (í•œêµ­ì–´ ëª¨ë¸ëª…)\\n'\n",
      " '- **ë¼ë§ˆ(LLaMA)** â€“ Metaì—ì„œ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ ì‹œë¦¬ì¦ˆ  \\n'\n",
      " '- **ì•ŒíŒŒì½”ë“œ(AlphaCode)** â€“ DeepMindê°€ ë§Œë“  ì½”ë“œ ìƒì„± íŠ¹í™” ëª¨ë¸  \\n'\n",
      " '- **ë²„íŠ¸(BERT)** â€“ êµ¬ê¸€ì´ ë°œí‘œí•œ ì–‘ë°©í–¥ Transformer ëª¨ë¸(í…ìŠ¤íŠ¸ ì´í•´ì— ê°•ì )  \\n'\n",
      " '- **ì½”íˆì–´ëŸ°íŠ¸(Claude)** â€“ Anthropicì´ ë§Œë“  ëŒ€í™”í˜• AI ëª¨ë¸  \\n'\n",
      " '- **ìŠ¤í…Œì´ë¸” ë””í“¨ì „(Stable Diffusion)** â€“ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì´ì§€ë§Œ í…ìŠ¤íŠ¸â€‘ì´ë¯¸ì§€ ì—°ë™ì—ì„œ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ì‚¬ìš©  \\n'\n",
      " '- **ìŠ¤ìœ„í”„íŠ¸(ìŠ¤ìœ„í”„íŠ¸ì½”ë“œ, SwiftCoder)** â€“ í•œêµ­ì–´ì— íŠ¹í™”ëœ ìµœì‹  ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(ì˜ˆ: ì¹´ì¹´ì˜¤Â·ë„¤ì´ë²„ ê³µë™ ê°œë°œ)  \\n'\n",
      " '\\n'\n",
      " 'ìœ„ ëª¨ë¸ë“¤ì€ ëª¨ë‘ Transformer ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ì‚¬ì „ í•™ìŠµëœ ë’¤, íŠ¹ì • ì‘ì—…ì— ë§ê²Œ íŒŒì¸íŠœë‹í•˜ê±°ë‚˜ ê°•í™”í•™ìŠµì„ '\n",
      " 'ì ìš©í•´ í™œìš©ë©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"í•œêµ­ì–´\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"í•œêµ­ì–´\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ í•˜ì—¬ ì—¬ëŸ¬ê°œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemini ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'claude ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n",
      "<class 'str'> GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('GPTâ€‘4ëŠ” ëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ëœ íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ì…ë ¥ '\n",
      " 'ë¬¸ë§¥ì„ ì¸ì½”ë”©í•˜ê³ , ê° ìœ„ì¹˜ì—ì„œ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ ë‹¨ì–´ë¥¼ ì„ íƒí•˜ë„ë¡ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©´ì„œ ì–¸ì–´ êµ¬ì¡°ì™€ ì˜ë¯¸ '\n",
      " 'ê´€ê³„ë¥¼ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤.')\n",
      "<class 'str'> Gemini ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('Gemini ëª¨ë¸ì€ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ì™€ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ì‚¬ì „ í•™ìŠµ(preâ€‘training) ë‹¨ê³„ì—ì„œ ì–¸ì–´ì™€ ì´ë¯¸ì§€Â·ìŒì„± ë“± ë‹¤ì–‘í•œ '\n",
      " 'í˜•ì‹ì˜ ì •ë³´ë¥¼ ë™ì‹œì— í•™ìŠµí•©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´í›„ ì¸ê°„ í”¼ë“œë°±ì„ í™œìš©í•œ ê°•í™” í•™ìŠµ(RLHF) ê³¼ì •ì„ ê±°ì³, ëª¨ë¸ì´ ë” ì •í™•í•˜ê³  ì•ˆì „í•˜ê²Œ ì‘ë‹µí•˜ë„ë¡ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ ìê¸°â€‘ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì´ìš©í•´ ë¬¸ë§¥ì„ ì¥ê¸°ì ìœ¼ë¡œ íŒŒì•…í•˜ê³ , ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹° ê°„ì˜ ê´€ê³„ë¥¼ í†µí•©í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ë§ˆì§€ë§‰ìœ¼ë¡œ ì§€ì†ì ì¸ ì—…ë°ì´íŠ¸ì™€ í‰ê°€ë¥¼ í†µí•´ ìµœì‹  ì§€ì‹ê³¼ ìœ¤ë¦¬ ê¸°ì¤€ì„ ë°˜ì˜í•˜ë„ë¡ ëª¨ë¸ì„ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•©ë‹ˆë‹¤.')\n",
      "<class 'str'> claude ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('Claude ëª¨ë¸ì€ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì´ìš©í•´ **ìê¸° ì§€ë„ í•™ìŠµ(selfâ€‘supervised learning)** ë°©ì‹ìœ¼ë¡œ ì‚¬ì „ '\n",
      " 'í•™ìŠµë©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œëŠ” ì…ë ¥ ë¬¸ì¥ì— ë§ˆìŠ¤í¬ë¥¼ ì ìš©í•˜ê±°ë‚˜ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•˜ì—¬, ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì–¸ì–´ë¥¼ ìƒì„±í•˜ë„ë¡ ëª¨ë¸ì„ '\n",
      " 'ìµœì í™”í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ê·¸ í›„, ì¸ê°„ í”¼ë“œë°±ì„ í™œìš©í•œ **ê°•í™” í•™ìŠµ(RLHF, Reinforcement Learning from Human Feedback)** '\n",
      " 'ë‹¨ê³„ì—ì„œ ì‹¤ì œ ì‚¬ìš©ìì˜ ì„ í˜¸ì™€ ìœ¤ë¦¬ì  ê¸°ì¤€ì„ ë°˜ì˜í•˜ë„ë¡ ë³´ì •í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ìµœì¢…ì ìœ¼ë¡œ ì—¬ëŸ¬ ë„ë©”ì¸ì— ê±¸ì¹œ ë¯¸ì„¸ ì¡°ì •ê³¼ ê²€ì¦ì„ ê±°ì³, ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ì¼ê´€ë˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple í˜•íƒœì˜ system, user, assistant ë©”ì‹œì§€ ì§€ì›\n",
    "* ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë¥¼ ì¡°í•©í•˜ì—¬ LLMì—ê²Œ ì „ë‹¬ ê°€ëŠ¥\n",
    "* ê°„ê²°ì„±ê³¼ ê°€ë…ì„±ì´ ë†’ê³  ë‹¨ìˆœí•œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT ëª¨ë¸ì´ ì–´ë–»ê²Œ í•™ìŠµë˜ëŠ”ì§€ í•œëˆˆì— ë³´ê¸°  \n",
      "\n",
      "ì•„ë˜ ë‚´ìš©ì€ **Transformer ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸**(LLM)ì¸ ChatGPTê°€ **ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ë°›ì•„ë“¤ì´ê³ **, **ì–´ë–¤ ëª©í‘œë¥¼ ê°€ì§€ê³ **, **ì–´ë–¤ ë‹¨ê³„ë“¤ì„ ê±°ì³** ìµœì¢…ì ìœ¼ë¡œ â€œëŒ€í™”í˜• AIâ€ê°€ ë˜ëŠ”ì§€ë¥¼ ìˆœì„œëŒ€ë¡œ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. ê¸°ë³¸ êµ¬ì¡°: Transformer (ë””ì½”ë”)  \n",
      "\n",
      "| êµ¬ì„± ìš”ì†Œ | ì—­í•  |\n",
      "|----------|------|\n",
      "| **ì…ë ¥ í† í°** | í…ìŠ¤íŠ¸ â†’ **í† í¬ë‚˜ì´ì €** â†’ ì •ìˆ˜ ID ì‹œí€€ìŠ¤ |\n",
      "| **ì„ë² ë”©(Embedding)** | í† í° IDë¥¼ ê³ ì • ì°¨ì›ì˜ ì‹¤ìˆ˜ ë²¡í„°ë¡œ ë³€í™˜ |\n",
      "| **í¬ì§€ì…”ë„ ì¸ì½”ë”©** | ìˆœì„œ ì •ë³´ë¥¼ ë²¡í„°ì— ë”í•´ ì¤Œ (sin/cos í˜¹ì€ í•™ìŠµ ê°€ëŠ¥í•œ) |\n",
      "| **Selfâ€‘Attention** | ê° í† í°ì´ ë¬¸ë§¥ ì „ì²´(ì•Â·ë’¤)ì™€ ìƒí˜¸ì‘ìš©í•´ ì˜ë¯¸ë¥¼ íŒŒì•… |\n",
      "| **Feedâ€‘Forward ë„¤íŠ¸ì›Œí¬** | ë¹„ì„ í˜• ë³€í™˜ìœ¼ë¡œ í‘œí˜„ë ¥ì„ ê°•í™” |\n",
      "| **Layer Normalization & Residual** | í•™ìŠµ ì•ˆì •ì„±Â·ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ì „íŒŒë¥¼ ë•ëŠ” êµ¬ì¡° |\n",
      "| **ì¶œë ¥ í—¤ë“œ** | ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ë²¡í„° â†’ **Vocabulary** ì°¨ì›ì˜ ë¡œì§“ â†’ Softmax â†’ ë‹¤ìŒ í† í° í™•ë¥  ë¶„í¬ |\n",
      "\n",
      "> **í•µì‹¬ í¬ì¸íŠ¸** : TransformerëŠ” **ë³‘ë ¬ ì²˜ë¦¬**ê°€ ê°€ëŠ¥í•˜ê³ , **ì „ì—­ì ì¸ ë¬¸ë§¥(ì „ í† í°)**ì„ í•œ ë²ˆì— ê³ ë ¤í•  ìˆ˜ ìˆì–´ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. í•™ìŠµ ë‹¨ê³„ ì „ì²´ íë¦„  \n",
      "\n",
      "1. **ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ìˆ˜ì§‘**  \n",
      "   - ì›¹ í˜ì´ì§€, ì±…, ë…¼ë¬¸, ì½”ë“œ ì €ì¥ì†Œ ë“± ê³µê°œëœ ë‹¤ì–‘í•œ ì†ŒìŠ¤ â†’ ìˆ˜ë°± GB~ìˆ˜ TB ê·œëª¨.  \n",
      "   - ë°ì´í„°ëŠ” **í•„í„°ë§**(ë¶ˆë²•Â·ìœ í•´ ì½˜í…ì¸  ì œê±°, ì¤‘ë³µ ì œê±° ë“±) í›„ **í† í¬ë‚˜ì´ì €**(BPE/Byteâ€‘Level) ë¡œ ë³€í™˜.\n",
      "\n",
      "2. **ì‚¬ì „ í•™ìŠµ (Preâ€‘training)** â€“ **ìê¸° ì§€ë„ í•™ìŠµ**  \n",
      "   - **ëª©í‘œ**: â€œë‹¤ìŒ í† í° ì˜ˆì¸¡â€(Nextâ€‘Token Prediction) í˜¹ì€ â€œë§ˆìŠ¤í¬ëœ í† í° ë³µì›â€(Masked LM, GPTëŠ” ì „ìëŠ” ì‚¬ìš©).  \n",
      "   - **ì†ì‹¤ í•¨ìˆ˜**: **Crossâ€‘Entropy Loss**  \n",
      "     \\[\n",
      "     \\mathcal{L} = -\\sum_{t=1}^{T}\\log P_\\theta (x_t \\mid x_{<t})\n",
      "     \\]\n",
      "   - **í•™ìŠµ ê³¼ì •**  \n",
      "     1. **ë°°ì¹˜**: ì—¬ëŸ¬ ë¬¸ì¥ì„ ë™ì¼í•œ ê¸¸ì´ë¡œ íŒ¨ë”©í•˜ê³ , GPU/TPU í´ëŸ¬ìŠ¤í„°ì— ë¶„ì‚°.  \n",
      "     2. **ì „ë°© ê³„ì‚°**: ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ Transformerì— í†µê³¼ì‹œì¼œ ê° ìœ„ì¹˜ì˜ ë¡œê·¸ í™•ë¥ ì„ ì–»ìŒ.  \n",
      "     3. **ì—­ì „íŒŒ**: ì†ì‹¤ì„ ë¯¸ë¶„í•´ **AdamW** ì˜µí‹°ë§ˆì´ì €ë¡œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸.  \n",
      "   - **ìŠ¤ì¼€ì¤„ë§**:  \n",
      "     - **Learning Rate Warmâ€‘up** â†’ **Cosine Decay** ë“±ìœ¼ë¡œ ì•ˆì •ì ì¸ ì´ˆê¸° í•™ìŠµ.  \n",
      "     - **Gradient Accumulation** â†’ ë©”ëª¨ë¦¬ ì œí•œì„ ë„˜ì–´ í° ë°°ì¹˜ íš¨ê³¼ êµ¬í˜„.  \n",
      "\n",
      "   - **ê²°ê³¼**: ëª¨ë¸ì€ â€œì–¸ì–´ì˜ í†µê³„ì  ê·œì¹™, ë¬¸ë²•, ì‚¬ì‹¤ ì§€ì‹, ì¶”ë¡  íŒ¨í„´â€ì„ **ì•”ë¬µì ìœ¼ë¡œ** ìŠµë“.\n",
      "\n",
      "3. **ì§€ë„ í•™ìŠµ (Supervised Fineâ€‘tuning)** â€“ **ëŒ€í™” ë°ì´í„°**  \n",
      "   - **ë°ì´í„°**: ì¸ê°„ì´ ë§Œë“  ì§ˆë¬¸â€‘ë‹µë³€, ëŒ€í™” ë¡œê·¸, ì—­í• ê·¹ ë“±.  \n",
      "   - **ëª©í‘œ**: â€œì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±â€í•˜ë„ë¡ **ë‹¤ìŒ í† í° ì˜ˆì¸¡**ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, **ë¬¸ë§¥ì´ ëŒ€í™” í˜•íƒœ**ì´ë¯€ë¡œ ëª¨ë¸ì´ ëŒ€í™” íë¦„ì„ ë°°ìš´ë‹¤.  \n",
      "   - **íŠ¹ì§•**:  \n",
      "     - **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸**(ì˜ˆ: â€œYou are a helpful assistantâ€)ë¥¼ ì•ì— ë¶™ì—¬ ëª¨ë¸ì—ê²Œ ì—­í• ì„ ëª…ì‹œ.  \n",
      "     - **ìƒ˜í”Œë§ ì „ëµ**(Topâ€‘k, Topâ€‘p, temperature)ë„ í›ˆë ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ì‹¤ì œ ë°°í¬ ìƒí™©ê³¼ ì¼ì¹˜ì‹œí‚´.\n",
      "\n",
      "4. **ë³´ê°• í•™ìŠµ (Reinforcement Learning from Human Feedback, RLHF)**  \n",
      "   - **ì™œ í•„ìš”í•œê°€?**  \n",
      "     - ë‹¨ìˆœíˆ â€œë‹¤ìŒ í† í° ë§ì¶”ê¸°â€ë§Œ í•˜ë©´ **ë¬´ì˜ë¯¸í•˜ê±°ë‚˜ ë¶€ì ì ˆí•œ** ë‹µë³€ë„ ë†’ì€ í™•ë¥ ë¡œ ìƒì„±ë  ìˆ˜ ìˆë‹¤.  \n",
      "   - **í”„ë¡œì„¸ìŠ¤**  \n",
      "     1. **Human Labelers**: ì—¬ëŸ¬ í›„ë³´ ì‘ë‹µì„ í‰ê°€í•˜ê³  **ì„ í˜¸ë„ ì ìˆ˜**(ì˜ˆ: 1~5) ë¶€ì—¬.  \n",
      "     2. **Reward Model**: ìœ„ ë¼ë²¨ì„ í•™ìŠµì‹œì¼œ **ë³´ìƒ í•¨ìˆ˜** \\(R_\\phi\\) ë¥¼ ë§Œë“ ë‹¤.  \n",
      "     3. **Proximal Policy Optimization (PPO)** ë“± RL ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•´ **Policy**(ê¸°ì¡´ GPT ëª¨ë¸) ë¥¼ **ë³´ìƒ**ì´ ìµœëŒ€ê°€ ë˜ë„ë¡ ë¯¸ì„¸ì¡°ì •.  \n",
      "   - **í•µì‹¬ íš¨ê³¼**  \n",
      "     - **ì•ˆì „ì„±**(ë¶ˆì¾Œê°Â·í—ˆìœ„ ì •ë³´ ì–µì œ)  \n",
      "     - **ìœ ìš©ì„±**(ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€, ëŒ€í™” íë¦„ ìœ ì§€)  \n",
      "     - **ì¼ê´€ì„±**(ê°™ì€ ì§ˆë¬¸ì— ì¼ê´€ëœ ë‹µë³€)\n",
      "\n",
      "5. **ë°°í¬ ì „ ê²€ì¦ & ì•ˆì „ì„± í…ŒìŠ¤íŠ¸**  \n",
      "   - **ìë™ í…ŒìŠ¤íŠ¸**: ìœ í•´ ì½˜í…ì¸  í•„í„°, ì‚¬ì‹¤ ê²€ì¦, ê±°ì§“ ì •ë³´ íƒì§€ ë“±.  \n",
      "   - **ì¸ê°„ í‰ê°€**: ë‹¤ì¤‘ ë¼ìš´ë“œ ëŒ€í™” ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ **ì „ë¬¸ê°€**ê°€ í’ˆì§ˆì„ ì ê²€.  \n",
      "   - **ê°€ë“œë ˆì¼**(guardrails) ì ìš©: íŠ¹ì • í† í”½ì— ëŒ€í•´ â€œë‹µë³€ì„ ê±°ë¶€â€í•˜ê±°ë‚˜ â€œì•ˆì „í•œ ë‹µë³€â€ì„ ì œê³µí•˜ë„ë¡ ê·œì¹™ ì‚½ì….\n",
      "\n",
      "---\n",
      "\n",
      "## 3. í•µì‹¬ ê¸°ìˆ  ìš”ì†Œ ìƒì„¸ ì„¤ëª…  \n",
      "\n",
      "### 3.1 í† í¬ë‚˜ì´ì € (Tokenizer)  \n",
      "- **Byteâ€‘Pair Encoding (BPE)** í˜¹ì€ **Byteâ€‘Level BPE**: ë¬¸ì ìˆ˜ì¤€ì—ì„œ ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” **subâ€‘word** ë‹¨ìœ„ë¥¼ í•©ì³ vocabì„ ë§Œë“ ë‹¤.  \n",
      "- ì¥ì :  \n",
      "  - **ì–´íœ˜ ì™¸(OOV) ë¬¸ì œ ìµœì†Œí™”** â†’ ìƒˆë¡œìš´ ë‹¨ì–´ë„ ì—¬ëŸ¬ subâ€‘word ì¡°í•©ìœ¼ë¡œ í‘œí˜„ ê°€ëŠ¥.  \n",
      "  - **ë‹¤êµ­ì–´**(íŠ¹íˆ í•œêµ­ì–´)ì—ì„œë„ **í˜•íƒœì†Œ**ë¥¼ ì™„ì „íˆ ë¶„ì„í•˜ì§€ ì•Šì•„ë„ ì¶©ë¶„íˆ ì»¤ë²„.\n",
      "\n",
      "### 3.2 ì†ì‹¤ í•¨ìˆ˜ì™€ í™•ë¥  ëª¨ë¸ë§  \n",
      "- **Crossâ€‘Entropy**ëŠ” **Maximum Likelihood Estimation (MLE)** ì˜ ì¼ì¢…. ëª¨ë¸ì´ ì‹¤ì œ ë‹¤ìŒ í† í°ì„ **ê°€ì¥ ë†’ì€ í™•ë¥ **ë¡œ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•œë‹¤.  \n",
      "- **Temperature** íŒŒë¼ë¯¸í„° \\(\\tau\\) ë¡œ **ë¶„í¬ í‰íƒ„í™”**:  \n",
      "  \\[\n",
      "  P_{\\tau}(x) = \\frac{e^{\\log P(x)/\\tau}}{\\sum_{x'} e^{\\log P(x')/\\tau}}\n",
      "  \\]\n",
      "  - \\(\\tau<1\\) â†’ **ë” í™•ì‹ **(ëœ ë‹¤ì–‘)  \n",
      "  - \\(\\tau>1\\) â†’ **ë” ë‹¤ì–‘**(ëœ í™•ì‹ )\n",
      "\n",
      "### 3.3 ì˜µí‹°ë§ˆì´ì €ì™€ ì •ê·œí™”  \n",
      "- **AdamW** (Adam + Weight Decay) â†’ í•™ìŠµ ì†ë„ì™€ ì¼ë°˜í™” ì„±ëŠ¥ ëª¨ë‘ ìš°ìˆ˜.  \n",
      "- **Learning Rate Scheduler**: Warmâ€‘up â†’ Peak â†’ Decay (Cosine, Linear ë“±).  \n",
      "- **Gradient Clipping**: í­ë°œì  ê·¸ë˜ë””ì–¸íŠ¸ ë°©ì§€ (ë³´í†µ 1.0 ê¸°ì¤€).\n",
      "\n",
      "### 3.4 ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ (Scaling Laws)  \n",
      "- ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ \\(N\\), ë°ì´í„° í† í° ìˆ˜ \\(D\\), ì—°ì‚°ëŸ‰ \\(C\\) ì‚¬ì´ì— **logâ€‘log ì„ í˜• ê´€ê³„**ê°€ ì¡´ì¬í•œë‹¤ëŠ” ì—°êµ¬ ê²°ê³¼ê°€ ìˆë‹¤.  \n",
      "  - ì˜ˆ: íŒŒë¼ë¯¸í„°ë¥¼ 10ë°° ëŠ˜ë¦¬ë©´ ì†ì‹¤ì´ ì•½ \\(\\approx 0.2\\) ì •ë„ ê°ì†Œ.  \n",
      "- ì´ëŸ¬í•œ ë²•ì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ **GPTâ€‘3 (175B)**, **GPTâ€‘4 (ìˆ˜ì²œì–µ íŒŒë¼ë¯¸í„°)** ë“± ê·œëª¨ê°€ ì ì  ì»¤ì§.\n",
      "\n",
      "### 3.5 ë©€í‹° GPU/TPU ë¶„ì‚° í•™ìŠµ  \n",
      "- **Data Parallelism**: ê°™ì€ ëª¨ë¸ì„ ì—¬ëŸ¬ ë””ë°”ì´ìŠ¤ì— ë³µì œí•˜ê³ , ì„œë¡œ ë‹¤ë¥¸ ë°°ì¹˜ë¥¼ ì²˜ë¦¬ â†’ **Allâ€‘Reduce** ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ í•©ì‚°.  \n",
      "- **Tensor Parallelism**: í•˜ë‚˜ì˜ ë ˆì´ì–´(íŠ¹íˆ ì–´í…ì…˜ ë§¤íŠ¸ë¦­ìŠ¤)ë¥¼ ì—¬ëŸ¬ ë””ë°”ì´ìŠ¤ì— ë‚˜ëˆ ì„œ ê³„ì‚° â†’ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ.  \n",
      "- **Pipeline Parallelism**: ë ˆì´ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë‹¤ë¥¸ ë””ë°”ì´ìŠ¤ì— ë°°ì¹˜ â†’ **ì—°ì‚° íŒŒì´í”„ë¼ì¸** í˜•ì„±.  \n",
      "- **ZeRO (Zero Redundancy Optimizer)**: íŒŒë¼ë¯¸í„°, ì˜µí‹°ë§ˆì´ì € ìƒíƒœ, ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë””ë°”ì´ìŠ¤ì— ë¶„ì‚° ì €ì¥í•´ ë©”ëª¨ë¦¬ íš¨ìœ¨ ê·¹ëŒ€í™”.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. í•œêµ­ì–´ì— íŠ¹í™”ëœ í•™ìŠµ íŒ  \n",
      "\n",
      "| ìš”ì†Œ | ì ìš© ë°©ë²• |\n",
      "|------|-----------|\n",
      "| **ë°ì´í„°** | í•œêµ­ì–´ ë‰´ìŠ¤, ë¸”ë¡œê·¸, ì¹´ì¹´ì˜¤í†¡ ëŒ€í™”, í•œêµ­ì–´ ìœ„í‚¤, ì½”ë“œ ì£¼ì„ ë“± ë‹¤ì–‘í•˜ê²Œ ìˆ˜ì§‘. |\n",
      "| **í† í¬ë‚˜ì´ì €** | Byteâ€‘Level BPE + **Koreanâ€‘specific merges** (ì˜ˆ: â€œã„±ã…ã„´â€ ê°™ì€ ìì†Œë¥¼ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ë¬¶ìŒ) |\n",
      "| **ë¬¸ë§¥ ê¸¸ì´** | í•œêµ­ì–´ëŠ” ì–´ë¯¸Â·ì¡°ì‚¬ ì²´ê³„ê°€ ê°•í•´ **ê¸´ ë¬¸ë§¥**ì´ ì˜ë¯¸ íŒŒì•…ì— ì¤‘ìš” â†’ 2k~4k í† í° ê¸¸ì´ í™•ë³´. |\n",
      "| **Fineâ€‘tuning** | í•œêµ­ì–´ QA, ê³ ê°ì„¼í„° ë¡œê·¸, ë²ˆì—­ ë°ì´í„° ë“± **ë„ë©”ì¸â€‘íŠ¹í™”** ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµ. |\n",
      "| **RLHF** | í•œêµ­ì–´ ì›ì–´ë¯¼ ë¼ë²¨ëŸ¬ê°€ **ìœ¤ë¦¬Â·ì •í™•ì„±**ì„ í‰ê°€í•˜ë„ë¡ ì„¤ê³„. |\n",
      "| **Safety** | í•œêµ­ì–´ íŠ¹ìœ ì˜ **í˜ì˜¤ í‘œí˜„Â·ì§€ì—­Â·ë¬¸í™”** ì°¨ë³„ ìš©ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ì „ êµ¬ì¶•í•´ í•„í„°ë§. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. í•™ìŠµ íë¦„ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½  \n",
      "\n",
      "> **â€œChatGPTëŠ” ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ â€˜ë‹¤ìŒ ë‹¨ì–´ ë§ì¶”ê¸°â€™ë¼ëŠ” ëª©í‘œë¡œ Transformer ë„¤íŠ¸ì›Œí¬ì— í•™ìŠµì‹œí‚¨ ë’¤, ì¸ê°„ì´ ë§Œë“  ëŒ€í™” ì˜ˆì‹œì™€ ì¸ê°„ í”¼ë“œë°±ì„ ì´ìš©í•´ â€˜ìœ ìš©í•˜ê³  ì•ˆì „í•œ ëŒ€í™”â€™ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ì¶”ê°€ ì¡°ì •(RLHF)í•œë‹¤.â€**\n",
      "\n",
      "---\n",
      "\n",
      "## 6. ì°¸ê³ ìš© ìš©ì–´ ì •ë¦¬  \n",
      "\n",
      "| ìš©ì–´ | ì˜ë¯¸ |\n",
      "|------|------|\n",
      "| **Transformer** | ì…€í”„â€‘ì–´í…ì…˜ ê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¡° |\n",
      "| **Selfâ€‘Attention** | ê° í† í°ì´ ë¬¸ë§¥ ì „ì²´ì™€ ìƒí˜¸ì‘ìš©í•´ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬ |\n",
      "| **Token** | í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìµœì†Œ ë‹¨ìœ„ (ë³´í†µ subâ€‘word) |\n",
      "| **Preâ€‘training** | ë¼ë²¨ì´ ì—†ëŠ” ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ì¼ë°˜ ì–¸ì–´ ëŠ¥ë ¥ ìŠµë“ |\n",
      "| **Fineâ€‘tuning** | íŠ¹ì • íƒœìŠ¤í¬(ëŒ€í™” ë“±)ì— ë§ì¶° ì¶”ê°€ í•™ìŠµ |\n",
      "| **RLHF** | ì¸ê°„ í”¼ë“œë°±ì„ ë³´ìƒìœ¼ë¡œ ì‚¼ì•„ ê°•í™”í•™ìŠµì„ ìˆ˜í–‰ |\n",
      "| **PPO** | RLì—ì„œ ìì£¼ ì“°ì´ëŠ” ì •ì±… ìµœì í™” ì•Œê³ ë¦¬ì¦˜ |\n",
      "| **Crossâ€‘Entropy** | ì •ë‹µ í™•ë¥ ì„ ìµœëŒ€í™”í•˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ |\n",
      "| **AdamW** | ê°€ì¤‘ì¹˜ ê°ì‡ ê°€ í¬í•¨ëœ Adam ì˜µí‹°ë§ˆì´ì € |\n",
      "| **Gradient Accumulation** | ë©”ëª¨ë¦¬ ì œí•œì„ ë„˜ëŠ” í° ë°°ì¹˜ë¥¼ í‰ë‚´ ë‚´ëŠ” ê¸°ë²• |\n",
      "| **Safety Guardrails** | ìœ í•´Â·ë¶ˆë²•Â·ì˜¤ì •ë³´ë¥¼ ì°¨ë‹¨í•˜ê¸° ìœ„í•œ ê·œì¹™Â·í•„í„° |\n",
      "\n",
      "---\n",
      "\n",
      "### ë§ˆë¬´ë¦¬\n",
      "\n",
      "ChatGPTì™€ ê°™ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì€ **â€œëŒ€ëŸ‰ì˜ í…ìŠ¤íŠ¸ â†’ ìê¸° ì§€ë„ í•™ìŠµ â†’ ëŒ€í™” ë°ì´í„°Â·ì¸ê°„ í”¼ë“œë°± â†’ ì•ˆì „Â·ìœ ìš©ì„± ê°•í™”â€** ë¼ëŠ” ì¼ë ¨ì˜ ê³¼ì •ì„ ê±°ì³ ì™„ì„±ë©ë‹ˆë‹¤. í•µì‹¬ì€ **Transformer**ê°€ ì œê³µí•˜ëŠ” ê°•ë ¥í•œ ë¬¸ë§¥ ì´í•´ ëŠ¥ë ¥ê³¼, **ì¸ê°„ í”¼ë“œë°±ì„ í†µí•œ ë³´ì •**ì´ë¼ëŠ” ë‘ ì¶•ì´ ê²°í•©ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤.  \n",
      "\n",
      "ê¶ê¸ˆí•œ ë¶€ë¶„ì´ ë” ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# 2-íŠœí”Œ í˜•íƒœì˜ ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# ìƒì„±í•œ ë©”ì‹œì§€ë¥¼ ë°”ë¡œ ì£¼ì…í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT ëª¨ë¸ì´ ì–´ë–»ê²Œ í•™ìŠµë˜ëŠ”ì§€  \n",
      "(í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ì„¤ëª…)\n",
      "\n",
      "---\n",
      "\n",
      "### 1. ê¸°ë³¸ êµ¬ì¡°: Transformer ì•„í‚¤í…ì²˜\n",
      "- **Transformer**ëŠ” 2017ë…„ ë…¼ë¬¸ *â€œAttention Is All You Needâ€*ì—ì„œ ì†Œê°œëœ ëª¨ë¸ì´ë©°, í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(Large Language Model, LLM)ì˜ í•µì‹¬ì´ ë©ë‹ˆë‹¤.  \n",
      "- í•µì‹¬ ìš”ì†Œ  \n",
      "  - **Selfâ€‘Attention**: ì…ë ¥ í† í°ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ëª¨ë‘ ë™ì‹œì— ê³ ë ¤í•´ ê° í† í°ì´ ë‹¤ë¥¸ í† í°ì— ì–¼ë§ˆë‚˜ â€œì£¼ì˜(attention)â€ë¥¼ ì¤˜ì•¼ í•˜ëŠ”ì§€ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.  \n",
      "  - **ë©€í‹°â€‘í—¤ë“œ ì–´í…ì…˜**: ì—¬ëŸ¬ ê°œì˜ ì–´í…ì…˜ì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•´ ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì„ ë™ì‹œì— í•™ìŠµí•©ë‹ˆë‹¤.  \n",
      "  - **Feedâ€‘Forward ë„¤íŠ¸ì›Œí¬**: ê° í† í°ì— ë…ë¦½ì ìœ¼ë¡œ ì ìš©ë˜ëŠ” ë‘ ê°œã® ì„ í˜• ë³€í™˜ + ë¹„ì„ í˜• í™œì„±í™”(ë³´í†µ GELU)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.  \n",
      "  - **Layer Normalization** & **Residual Connection**: í•™ìŠµ ì•ˆì •ì„±ê³¼ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì˜ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì„ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. í† í°í™” (Tokenization)\n",
      "- í…ìŠ¤íŠ¸ëŠ” **í† í°**ì´ë¼ëŠ” ì‘ì€ ë‹¨ìœ„ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.  \n",
      "- ChatGPTëŠ” **Byteâ€‘Pair Encoding (BPE)** í˜¹ì€ **SentencePiece** ê°™ì€ ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
      "  - ì¥ì :  \n",
      "    - ì–´íœ˜ í¬ê¸°ë¥¼ ìˆ˜ì‹­ë§Œ ê°œ ìˆ˜ì¤€ìœ¼ë¡œ ì œí•œí•˜ë©´ì„œë„ ë“œë¬¼ê±°ë‚˜ ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ì¡°í•©í•´ì„œ í‘œí˜„ ê°€ëŠ¥.  \n",
      "    - ë‹¤êµ­ì–´(íŠ¹íˆ í•œêµ­ì–´)ì—ì„œë„ íš¨ìœ¨ì ì¸ ë¶„í• ì´ ê°€ëŠ¥.  \n",
      "\n",
      "---\n",
      "\n",
      "### 3. ì‚¬ì „ í•™ìŠµ (Preâ€‘training) â€“ **ìê¸°ì§€ë„ í•™ìŠµ (Selfâ€‘Supervised Learning)**\n",
      "#### 3.1 ëª©í‘œ í•¨ìˆ˜\n",
      "- **ë‹¤ìŒ í† í° ì˜ˆì¸¡ (Causal Language Modeling)**:  \n",
      "  - ì…ë ¥ ì‹œí€€ìŠ¤ `xâ‚, xâ‚‚, â€¦, xâ‚™`ì´ ì£¼ì–´ì§€ë©´, ëª¨ë¸ì€ ê° ìœ„ì¹˜ `t`ì—ì„œ `xâ‚œâ‚Šâ‚`ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤.  \n",
      "  - ì†ì‹¤ í•¨ìˆ˜ëŠ” **Crossâ€‘Entropy**ì´ë©°, ì‹¤ì œ í† í°ê³¼ ëª¨ë¸ì´ ì¶œë ¥í•œ í™•ë¥  ë¶„í¬ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.  \n",
      "\n",
      "#### 3.2 ë°ì´í„°\n",
      "- **ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ì½”í¼ìŠ¤**: ì›¹ í˜ì´ì§€, ì±…, ë…¼ë¬¸, ë‰´ìŠ¤, í¬ëŸ¼, ì½”ë“œ ì €ì¥ì†Œ ë“± ìˆ˜ë°± ê¸°ê°€ë°”ì´íŠ¸ ~ ìˆ˜ í…Œë¼ë°”ì´íŠ¸ ê·œëª¨.  \n",
      "- **í´ë¦¬ë‹**: ê°œì¸ ì‹ë³„ ì •ë³´(PII) ì œê±°, ì €ì‘ê¶Œ ë¬¸ì œ í•´ê²°, ì¤‘ë³µ ì œê±°, ì–¸ì–´ë³„ ê· í˜• ë§ì¶”ê¸° ë“±.  \n",
      "\n",
      "#### 3.3 í•™ìŠµ ê³¼ì •\n",
      "1. **ë°°ì¹˜ êµ¬ì„±**: ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì¼ì • ê¸¸ì´(ì˜ˆ: 2048 í† í°)ë¡œ ì˜ë¼ì„œ ë°°ì¹˜ì— ë„£ìŠµë‹ˆë‹¤.  \n",
      "2. **ë§ˆìŠ¤í‚¹**: causal LMì—ì„œëŠ” í˜„ì¬ í† í° ì´í›„ë¥¼ ë§ˆìŠ¤í¬(mask) ì²˜ë¦¬í•´ ë¯¸ë˜ ì •ë³´ë¥¼ ë³´ì§€ ëª»í•˜ê²Œ í•©ë‹ˆë‹¤.  \n",
      "3. **í¬ì›Œë“œ íŒ¨ìŠ¤**: í† í° ì„ë² ë”© â†’ í¬ì§€ì…˜ ì„ë² ë”© â†’ ì—¬ëŸ¬ Transformer ë ˆì´ì–´ â†’ ì¶œë ¥ ë¡œì§“.  \n",
      "4. **ì†ì‹¤ ê³„ì‚°**: ì‹¤ì œ ë‹¤ìŒ í† í°ê³¼ ë¡œì§“ ì‚¬ì´ì˜ crossâ€‘entropy.  \n",
      "5. **ë°±ì›Œë“œ íŒ¨ìŠ¤**: AdamW ì˜µí‹°ë§ˆì´ì €ë¡œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸.  \n",
      "6. **ìŠ¤ì¼€ì¤„ë§**:  \n",
      "   - **Learning Rate Warmâ€‘up** â†’ **Cosine Decay** ë“±ìœ¼ë¡œ í•™ìŠµë¥ ì„ ì¡°ì ˆ.  \n",
      "   - **Gradient Clipping**: í­ë°œì ì¸ ê·¸ë˜ë””ì–¸íŠ¸ ë°©ì§€.  \n",
      "\n",
      "#### 3.4 ê·œëª¨ì™€ íš¨ìœ¨ì„±\n",
      "- **íŒŒë¼ë¯¸í„° ìˆ˜**: ChatGPTâ€‘3.5ëŠ” 6~175â€¯B(ì–µ) íŒŒë¼ë¯¸í„°, ìµœì‹  ëª¨ë¸ì€ ìˆ˜ì²œì–µê¹Œì§€.  \n",
      "- **ì—°ì‚°ëŸ‰**: FLOPs(ë¶€ë™ì†Œìˆ˜ì  ì—°ì‚°)ì™€ ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ì´ ë°©ëŒ€í•´ GPU/TPU í´ëŸ¬ìŠ¤í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.  \n",
      "- **ìŠ¤ì¼€ì¼ë§ ë²•ì¹™**: ë°ì´í„° ì–‘, íŒŒë¼ë¯¸í„° ìˆ˜, ì—°ì‚°ëŸ‰ì„ ë™ì‹œì— ëŠ˜ë¦¬ë©´ ì„±ëŠ¥ì´ ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¹„ìœ¨ë¡œ í–¥ìƒë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. ì§€ë„ í•™ìŠµ (Supervised Fineâ€‘tuning)\n",
      "ì‚¬ì „ í•™ìŠµë§Œìœ¼ë¡œëŠ” **íŠ¹ì • íƒœìŠ¤í¬**(ì˜ˆ: ì§ˆë¬¸â€‘ë‹µë³€, ë²ˆì—­, ì½”ë“œ ìƒì„±)ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ë‚´ê¸° ì–´ë µìŠµë‹ˆë‹¤.  \n",
      "- **ë°ì´í„°**: ì¸ê°„ì´ ë§Œë“  â€˜ì…ë ¥â€‘ì¶œë ¥â€™ ìŒ(í”„ë¡¬í”„íŠ¸ì™€ ê¸°ëŒ€ ë‹µë³€)ìœ¼ë¡œ êµ¬ì„±ëœ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹.  \n",
      "- **ëª©í‘œ**: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ë‘ê³ , ìƒˆë¡œìš´ ë°ì´í„°ì— ë§ê²Œ **Crossâ€‘Entropy** ì†ì‹¤ì„ ë‹¤ì‹œ ìµœì†Œí™”í•©ë‹ˆë‹¤.  \n",
      "- **íš¨ê³¼**: ëª¨ë¸ì´ ë” ì¼ê´€ëœ í˜•ì‹Â·í†¤ì„ ìœ ì§€í•˜ê³ , íŠ¹ì • ë„ë©”ì¸(ì˜ˆ: ë²•ë¥ , ì˜ë£Œ)ì—ì„œ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. ê°•í™” í•™ìŠµì„ í†µí•œ ì¸ê°„ í”¼ë“œë°± (RLHF: Reinforcement Learning from Human Feedback)\n",
      "ChatGPTê°€ ì‹¤ì œ ì‚¬ìš©ìì™€ ëŒ€í™”í•  ë•Œ **ì•ˆì „í•˜ê³  ìœ ìš©í•œ** ì‘ë‹µì„ ë§Œë“¤ë„ë¡ í›ˆë ¨í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **Humanâ€‘labelled Preference Data**  \n",
      "   - ì—¬ëŸ¬ í›„ë³´ ë‹µë³€ì„ ìƒì„±í•˜ê³ , ì¸ê°„ ë¼ë²¨ëŸ¬ê°€ â€œì–´ë–¤ ë‹µë³€ì´ ë” ì¢‹ì€ê°€â€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.  \n",
      "   - ì´ ë°ì´í„°ë¥¼ **Reward Model (ë³´ìƒ ëª¨ë¸)** í•™ìŠµì— ì‚¬ìš©í•©ë‹ˆë‹¤. ë³´ìƒ ëª¨ë¸ì€ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ ë‹µë³€ì„ ë°›ì•„ â€œì¢‹ìŒâ€ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. **Proximal Policy Optimization (PPO)**  \n",
      "   - ë³´ìƒ ëª¨ë¸ì„ ì´ìš©í•´ **Policy**(ì¦‰, ì–¸ì–´ ëª¨ë¸)ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.  \n",
      "   - ëª©í‘œëŠ” ë³´ìƒ ì ìˆ˜ê°€ ë†’ì€ ë‹µë³€ì„ ë” ë§ì´ ìƒì„±í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ë©°, PPOëŠ” ê¸‰ê²©í•œ íŒŒë¼ë¯¸í„° ë³€í™”ë¥¼ ë°©ì§€í•´ ì•ˆì •ì ì¸ í•™ìŠµì„ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **Safety & Alignment**  \n",
      "   - ë¶€ì ì ˆ, ìœ„í—˜, í¸í–¥ëœ ë‚´ìš©ì— ëŒ€í•œ **ê·œì¹™**(ì˜ˆ: â€œí­ë ¥ ì„ ë™ ê¸ˆì§€â€)ì„ ë³´ìƒ í•¨ìˆ˜ì— í¬í•¨í•˜ê±°ë‚˜, ë³„ë„ **í•„í„°ë§** ëª¨ë¸ì„ ì ìš©í•©ë‹ˆë‹¤.  \n",
      "   - ì§€ì†ì ì¸ **Humanâ€‘inâ€‘theâ€‘Loop** ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ì´ ìµœì‹  ì‚¬íšŒì Â·ìœ¤ë¦¬ì  ê¸°ì¤€ì— ë¶€í•©í•˜ë„ë¡ ìœ ì§€í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 6. ë°°í¬ì™€ ì¶”ë¡  (Inference)\n",
      "- **Quantization / Distillation**: ëª¨ë¸ì„ 8â€‘bit, 4â€‘bit ë“±ìœ¼ë¡œ ì••ì¶•í•˜ê±°ë‚˜, ì‘ì€ â€œí•™ìƒâ€ ëª¨ë¸ì— ì§€ì‹ì„ ì „ì´ì‹œì¼œ ë¹„ìš©ì„ ì ˆê°í•©ë‹ˆë‹¤.  \n",
      "- **ì—”ì§„**: GPU/TPU ê¸°ë°˜ ì„œë²„ì—ì„œ **ë‹¤ì¤‘â€‘GPU íŒŒì´í”„ë¼ì¸** í˜¹ì€ **TensorRT/ONNX Runtime** ê°™ì€ ê³ ì„±ëŠ¥ ëŸ°íƒ€ì„ì„ ì‚¬ìš©í•´ ë¹ ë¥¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.  \n",
      "- **ìƒ˜í”Œë§ ì „ëµ**:  \n",
      "  - **Greedy** (ìµœëŒ€ í™•ë¥  ì„ íƒ) â†’ ê°€ì¥ ë³´ìˆ˜ì .  \n",
      "  - **Topâ€‘k**, **Topâ€‘p (nucleus)** â†’ ë‹¤ì–‘ì„± í™•ë³´.  \n",
      "  - **Temperature** ì¡°ì ˆ â†’ ë‹µë³€ì˜ â€œì°½ì˜ì„±â€ ì •ë„ ì¡°ì ˆ.  \n",
      "\n",
      "---\n",
      "\n",
      "### 7. ì£¼ìš” í¬ì¸íŠ¸ ìš”ì•½\n",
      "| ë‹¨ê³„ | ëª©ì  | í•µì‹¬ ê¸°ìˆ  |\n",
      "|------|------|-----------|\n",
      "| **í† í°í™”** | í…ìŠ¤íŠ¸ â†’ ì •ìˆ˜ ì‹œí€€ìŠ¤ | BPE / SentencePiece |\n",
      "| **ì‚¬ì „ í•™ìŠµ** | ì–¸ì–´ êµ¬ì¡°ì™€ ì¼ë°˜ ì§€ì‹ ìŠµë“ | Causal LM, ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸, Transformer |\n",
      "| **ì§€ë„ íŒŒì¸íŠœë‹** | íŠ¹ì • ì‘ì—…Â·ë„ë©”ì¸ì— ë§ì¶¤ | ì¸ê°„ ë¼ë²¨ë§ëœ ì…ë ¥â€‘ì¶œë ¥ ìŒ |\n",
      "| **RLHF** | ì•ˆì „Â·ìœ ìš©ì„±Â·ì¸ê°„ ì„ í˜¸ ë°˜ì˜ | ë³´ìƒ ëª¨ë¸ + PPO |\n",
      "| **ë°°í¬/ì¶”ë¡ ** | ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ ì œê³µ | ì–‘ìí™”, ìƒ˜í”Œë§, ê³ ì„±ëŠ¥ ì—”ì§„ |\n",
      "\n",
      "---\n",
      "\n",
      "## ê²°ë¡ \n",
      "ChatGPTëŠ” **ëŒ€ê·œëª¨ Transformer**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ìê¸°ì§€ë„ í•™ìŠµ**ì„ í†µí•´ ì¼ë°˜ ì–¸ì–´ ëŠ¥ë ¥ì„ íšë“í•˜ê³ , **ì§€ë„ í•™ìŠµ**ê³¼ **ì¸ê°„ í”¼ë“œë°±ì„ í™œìš©í•œ ê°•í™” í•™ìŠµ(RLHF)**ì„ ê±°ì³ ì‹¤ì œ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ì—ì„œ **ì•ˆì „í•˜ê³  ìœ ìš©í•œ** ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ìµœì í™”ë©ë‹ˆë‹¤. ì´ ì „ì²´ íŒŒì´í”„ë¼ì¸ì€ ë°ì´í„° ìˆ˜ì§‘Â·ì „ì²˜ë¦¬, ëª¨ë¸ ì„¤ê³„Â·í•™ìŠµ, ì •êµí•œ í”¼ë“œë°± ë£¨í”„, ê·¸ë¦¬ê³  íš¨ìœ¨ì ì¸ ë°°í¬ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ë” ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ì„ ìƒì„±í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate í´ë˜ìŠ¤ ì‚¬ìš©\n",
    "* ê°ì²´ ì§€í–¥ì  ì ‘ê·¼ - Message ê°ì²´ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥\n",
    "* ì—¬ëŸ¬ ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„ íƒ\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ìƒì„¸ ë¶„ì„: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Deep Learning â€“ A Comprehensive Overview\n",
      "\n",
      "### 1. Whatâ€¯isâ€¯Deep Learning?\n",
      "Deep learning (DL) is a subâ€‘field of **machine learning** (ML) that models highâ€‘level abstractions in data by using **artificial neural networks** (ANNs) with many layersâ€”hence the term *deep*. While traditional ML often relies on handcrafted features and relatively shallow models, deep learning lets the system **learn hierarchical representations directly from raw data** (images, text, audio, sensor streams, etc.).\n",
      "\n",
      "> **In a nutshell:** Deep learning = neural networks with multiple hidden layers that automatically discover useful features from raw inputs, enabling stateâ€‘ofâ€‘theâ€‘art performance on many perceptionâ€‘heavy tasks.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Historical Milestones\n",
      "\n",
      "| Year | Milestone | Why It Matters |\n",
      "|------|-----------|----------------|\n",
      "| **1943** | **McCullochâ€‘Pitts neuron** | First mathematical model of a binary neuron. |\n",
      "| **1958** | **Perceptron (Rosenblatt)** | Early singleâ€‘layer network; showed limits (XOR problem). |\n",
      "| **1986** | **Backâ€‘propagation (Rumelhart, Hinton, Williams)** | Efficient gradientâ€‘based training for multiâ€‘layer nets. |\n",
      "| **1998** | **LeNetâ€‘5 (LeCun)** | First convolutional network that solved handwritten digit recognition. |\n",
      "| **2006** | **Deep Belief Networks (Hinton)** | Popularized â€œdeepâ€ preâ€‘training, reigniting interest. |\n",
      "| **2012** | **AlexNet (Krizhevsky etâ€¯al.)** | Won ImageNet competition with a huge margin; demonstrated the power of GPUs + large data. |\n",
      "| **2014â€‘2015** | **GANs (Goodfellow), ResNets (He), Transformers (Vaswani)** | Opened new research directions (generative models, very deep nets, sequence modeling). |\n",
      "| **2020â€‘2024** | **Large Language Models (GPTâ€‘3/4, PaLM, LLaMA, etc.)** | Showed scaling laws: bigger models + more data â†’ emergent abilities. |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Core Building Blocks\n",
      "\n",
      "| Component | Description | Typical Variants |\n",
      "|-----------|-------------|------------------|\n",
      "| **Neuron (or unit)** | Computes a weighted sum of its inputs, adds a bias, then applies a nonâ€‘linear *activation* function. | ReLU, Leaky ReLU, Sigmoid, Tanh, GELU, Swish |\n",
      "| **Layer** | A collection of neurons that operate in parallel on the same input. | Fullyâ€‘connected (dense), Convolutional, Recurrent, Selfâ€‘attention |\n",
      "| **Loss (objective) function** | Quantifies how far the networkâ€™s predictions are from the ground truth. | Crossâ€‘entropy, MSE, Huber, KLâ€‘divergence |\n",
      "| **Optimizer** | Updates weights using gradients of the loss. | SGD, Adam, AdamW, RMSprop, LAMB |\n",
      "| **Regularization** | Prevents overâ€‘fitting. | Dropout, weight decay, batch norm, data augmentation |\n",
      "| **Training loop** | Repeatedly forwardâ€‘propagate inputs, compute loss, backâ€‘propagate gradients, and update parameters. | Miniâ€‘batch training, epochs, learningâ€‘rate schedules |\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Major Architectures\n",
      "\n",
      "| Architecture | Primary Useâ€‘Case | Key Idea |\n",
      "|--------------|------------------|----------|\n",
      "| **Fullyâ€‘Connected (MLP)** | Tabular data, simple classification/regression | Stacks of dense layers; universal approximator. |\n",
      "| **Convolutional Neural Networks (CNNs)** | Vision, audio spectrograms, spatial data | Local receptive fields + weight sharing â†’ translation invariance. |\n",
      "| **Recurrent Neural Networks (RNNs) & LSTMs/GRUs** | Sequential data (speech, time series) | Hidden state carries information across time steps. |\n",
      "| **Transformers** | Language, vision (ViT), multimodal | Selfâ€‘attention replaces recurrence; parallelizable; scales well. |\n",
      "| **Generative Adversarial Networks (GANs)** | Image synthesis, style transfer | Two networks (generator vs. discriminator) in a minimax game. |\n",
      "| **Variational Autoencoders (VAEs)** | Probabilistic generative modeling | Encoder learns latent distribution; decoder reconstructs data. |\n",
      "| **Diffusion Models** | Highâ€‘fidelity image generation (e.g., Stable Diffusion) | Iteratively denoise random noise to produce data. |\n",
      "| **Graph Neural Networks (GNNs)** | Graphâ€‘structured data (social networks, molecules) | Message passing between nodes respects graph topology. |\n",
      "\n",
      "---\n",
      "\n",
      "### 5. How Training Works (Mathematical Sketch)\n",
      "\n",
      "1. **Forward Pass**  \n",
      "   For each layer \\(l\\):\n",
      "   \\[\n",
      "   \\mathbf{z}^{(l)} = \\mathbf{W}^{(l)}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)}\\quad\n",
      "   \\mathbf{a}^{(l)} = \\sigma\\big(\\mathbf{z}^{(l)}\\big)\n",
      "   \\]\n",
      "   where \\(\\sigma\\) is the activation function.\n",
      "\n",
      "2. **Loss Computation**  \n",
      "   Example: crossâ€‘entropy for classification with logits \\(\\mathbf{z}^{(L)}\\):\n",
      "   \\[\n",
      "   \\mathcal{L} = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c} y_{i,c}\\log\\frac{e^{z_{i,c}}}{\\sum_{k}e^{z_{i,k}}}\n",
      "   \\]\n",
      "\n",
      "3. **Backward Pass (Backâ€‘propagation)**  \n",
      "   Compute gradients \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}^{(l)}}\\) and \\(\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{b}^{(l)}}\\) using the chain rule, starting from the output layer back to the first hidden layer.\n",
      "\n",
      "4. **Parameter Update** (e.g., Adam optimizer)  \n",
      "   \\[\n",
      "   \\theta_{t+1} = \\theta_t - \\alpha \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
      "   \\]\n",
      "   where \\(\\theta\\) denotes all weights & biases, \\(\\alpha\\) is the learning rate, and \\(\\hat{m}_t, \\hat{v}_t\\) are biasâ€‘corrected first/second moment estimates.\n",
      "\n",
      "5. **Iterate** over many miniâ€‘batches and epochs until convergence (or early stopping).\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Why Deep Learning Works So Well\n",
      "\n",
      "| Factor | Explanation |\n",
      "|--------|-------------|\n",
      "| **Representation Learning** | Deep nets automatically discover hierarchical features (edges â†’ motifs â†’ objects) instead of relying on manual engineering. |\n",
      "| **Largeâ€‘Scale Data** | Modern datasets (ImageNet, Common Crawl, etc.) provide the diversity needed to train highâ€‘capacity models. |\n",
      "| **Compute Power** | GPUs, TPUs, and specialized ASICs enable massive parallel matrix multiplications. |\n",
      "| **Optimization Advances** | Adaptive optimizers, better initialization (He, Xavier), batch normalization, and learningâ€‘rate schedules improve convergence. |\n",
      "| **Architectural Innovation** | Attention mechanisms, residual connections, and normalization layers mitigate vanishing gradients and enable very deep models. |\n",
      "| **Scaling Laws** | Empirical studies show that performance improves predictably with model size, data size, and computeâ€”leading to â€œbigger is betterâ€ trends. |\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Common Applications\n",
      "\n",
      "| Domain | Example Tasks | Representative Models |\n",
      "|--------|----------------|------------------------|\n",
      "| **Computer Vision** | Image classification, object detection, segmentation, video analysis | ResNet, EfficientNet, YOLO, Mask Râ€‘CNN, Vision Transformers (ViT) |\n",
      "| **Natural Language Processing** | Machine translation, summarization, sentiment analysis, question answering | BERT, GPTâ€‘4, T5, RoBERTa, LLaMA |\n",
      "| **Speech & Audio** | Speech recognition, textâ€‘toâ€‘speech, music generation | DeepSpeech, wav2vec 2.0, Tacotron, DiffWave |\n",
      "| **Generative AI** | Image synthesis, style transfer, deepfakes, code generation | Stable Diffusion, DALLÂ·E, StyleGAN, Codex |\n",
      "| **Reinforcement Learning** | Game playing, robotics, autonomous driving | Deep Qâ€‘Network (DQN), AlphaGo/AlphaZero, PPO, MuZero |\n",
      "| **Healthcare** | Medical imaging diagnosis, drug discovery, patient risk modeling | 3D CNNs, Graph Neural Nets for molecules, Clinical BERT |\n",
      "| **Finance** | Fraud detection, algorithmic trading, risk assessment | Temporal CNNs, LSTMs, Transformerâ€‘based timeâ€‘series models |\n",
      "| **Scientific Computing** | Protein folding, climate modeling, particle physics simulation | AlphaFold, Graph Nets for molecules, Physicsâ€‘informed Neural Nets |\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Practical Tips for Getting Started\n",
      "\n",
      "| Step | Action | Reason |\n",
      "|------|--------|--------|\n",
      "| **1. Choose a framework** | PyTorch, TensorFlow/Keras, JAX | Mature ecosystems, automatic differentiation, GPU support. |\n",
      "| **2. Pick a baseline model** | For images â†’ ResNetâ€‘50; for text â†’ BERTâ€‘base | Proven performance; easy to fineâ€‘tune. |\n",
      "| **3. Prepare data** | Clean, augment, split into train/val/test | Quality data is more important than model size. |\n",
      "| **4. Define loss & metrics** | Crossâ€‘entropy + accuracy for classification; BLEU for translation | Aligns training objective with evaluation. |\n",
      "| **5. Train with proper hyperâ€‘parameters** | Learning rate â‰ˆ 1eâ€‘3 (Adam), batch size 32â€‘256, weight decay 1eâ€‘4 | Good starting point; use learningâ€‘rate schedulers. |\n",
      "| **6. Monitor** | TensorBoard, Weights & Biases, or MLflow | Detect divergence, overâ€‘fitting early. |\n",
      "| **7. Fineâ€‘tune / Transfer learn** | Freeze early layers, train last few on your domain | Saves compute and often yields better results on limited data. |\n",
      "| **8. Deploy** | Export to ONNX/TorchScript, use TensorRT or TorchServe | Enables lowâ€‘latency inference on edge or cloud. |\n",
      "\n",
      "---\n",
      "\n",
      "### 9. Current Challenges & Research Frontiers\n",
      "\n",
      "| Challenge | Why It Matters | Emerging Solutions |\n",
      "|-----------|----------------|--------------------|\n",
      "| **Data Efficiency** | Collecting labeled data is expensive. | Selfâ€‘supervised learning, fewâ€‘shot prompting, active learning. |\n",
      "| **Model Size & Energy** | Large models consume huge electricity and hardware. | Model pruning, quantization, distillation, efficient architectures (e.g., MobileNet, TinyBERT). |\n",
      "| **Interpretability** | Blackâ€‘box nature hinders trust in safetyâ€‘critical domains. | Saliency maps, concept activation vectors, mechanistic interpretability. |\n",
      "| **Robustness & Safety** | Vulnerable to adversarial attacks, distribution shift. | Adversarial training, certified defenses, outâ€‘ofâ€‘distribution detection. |\n",
      "| **Bias & Fairness** | Training data reflects societal biases. | Debiasing objectives, dataset curation, fairness metrics. |\n",
      "| **Continual / Lifelong Learning** | Realâ€‘world systems must adapt without catastrophic forgetting. | Elastic weight consolidation, replay buffers, modular architectures. |\n",
      "| **Multimodal Understanding** | Humans integrate vision, language, audio, and more. | Multimodal Transformers (e.g., CLIP, Flamingo), diffusionâ€‘based video generation. |\n",
      "\n",
      "---\n",
      "\n",
      "### 10. Quick Glossary\n",
      "\n",
      "| Term | Definition |\n",
      "|------|------------|\n",
      "| **Neuron / Unit** | Basic computational element performing a weighted sum + nonâ€‘linearity. |\n",
      "| **Activation Function** | Introduces nonâ€‘linearity; common choices: ReLU, Sigmoid, Tanh. |\n",
      "| **Backâ€‘propagation** | Algorithm to compute gradients of loss w.r.t. every parameter. |\n",
      "| **Epoch** | One full pass through the entire training dataset. |\n",
      "| **Batch / Miniâ€‘batch** | Subset of data processed together for efficiency and gradient stability. |\n",
      "| **Overfitting** | Model memorizes training data, performing poorly on unseen data. |\n",
      "| **Generalization** | Ability of a model to perform well on new, unseen inputs. |\n",
      "| **Transfer Learning** | Reusing a preâ€‘trained model (or its parts) on a new task. |\n",
      "| **Selfâ€‘Attention** | Mechanism that lets each element of a sequence weigh all others; core of Transformers. |\n",
      "| **Residual Connection** | Shortcut that adds input to output of a block; eases training of very deep nets. |\n",
      "\n",
      "---\n",
      "\n",
      "## TL;DR (Oneâ€‘Paragraph Summary)\n",
      "\n",
      "Deep learning is a branch of machine learning that uses multiâ€‘layer neural networks to automatically learn hierarchical representations from raw data. By stacking layers of simple computational units (neurons) and training them with gradientâ€‘based optimization on massive datasets, deep nets achieve humanâ€‘level performance on tasks like image recognition, naturalâ€‘language understanding, speech synthesis, and game playing. Key innovationsâ€”convolutional layers for vision, attention mechanisms for language, and massive scaling on GPUs/TPUsâ€”have turned deep learning into the dominant AI paradigm today, while ongoing research tackles efficiency, interpretability, and robustness challenges.\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate í™œìš©\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplateëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë©”ì‹œì§€(ì‹œìŠ¤í…œ, ì¸ê°„, AI)ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* SystemMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ AI ëª¨ë¸ì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê±°ë‚˜ ì „ë°˜ì ì¸ ê·œì¹™ì„ ì„¤ì •í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ìœ„ì˜ ì˜ˆì‹œì—ì„œëŠ” \"ë²ˆì—­ì„ ë„ì™€ì£¼ëŠ” ìœ ìš©í•œ ë„ìš°ë¯¸\"ë¼ëŠ” ì—­í• ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "* HumanMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ë‹´ëŠ” ì¸ê°„ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œëŠ” ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.\n",
    "* ChatPromptTemplate.from_messages: ì´ í´ë˜ìŠ¤ ë©”ì„œë“œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€, ì¸ê°„ ë©”ì‹œì§€ ë“± ì—¬ëŸ¬ ì¢…ë¥˜ì˜ MessagePromptTemplate ê°ì²´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ í•˜ë‚˜ì˜ ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "* format_messages: ì´ ë©”ì„œë“œëŠ” ì •ì˜ëœ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ì–´ [SystemMessage, HumanMessage] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë¦¬ìŠ¤íŠ¸ëŠ” ì±„íŒ… ëª¨ë¸(Chat Model) ì— ë°”ë¡œ ì „ë‹¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "í”„ë¡œê·¸ë˜ë°ì„ ì‚¬ë‘í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate ìƒì„±\n",
    "# SystemMessagePromptTemplateëŠ” ëª¨ë¸ì˜ í˜ë¥´ì†Œë‚˜ ë˜ëŠ” ê¸°ë³¸ ì§€ì¹¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplateëŠ” ì‚¬ìš©ìë¡œë¶€í„° ë°›ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate ìƒì„±\n",
    "# ìœ„ì—ì„œ ë§Œë“  ë‘ í…œí”Œë¦¿ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ ChatPromptTemplateì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
    "# chat_prompt_template.format_messages()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ì´ í•¨ìˆ˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. ê²°ê³¼ ì¶œë ¥\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplateì€ ëª¨ë¸ì´ íŠ¹ì • í˜•ì‹ì„ ë”°ë¥´ê²Œ í•˜ê±°ë‚˜, ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* ë„ë©”ì¸ ì§€ì‹ì´ í•„ìš”í•˜ê±°ë‚˜, AIê°€ ì˜¤ë‹µì„ ì¤„ì´ê³  ë” ì‹ ë¢°í•  ë§Œí•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ í•´ì•¼ í•  ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "**íƒœì–‘ê³„ í–‰ì„± 8ê°œ ìš”ì•½**\n",
      "\n",
      "| ìˆœì„œ | í–‰ì„± | í‰ê·  ê±°ë¦¬(íƒœì–‘ìœ¼ë¡œë¶€í„°) | ì§€ë¦„(â‰ˆ) | íŠ¹ì§• |\n",
      "|------|------|----------------------|--------|------|\n",
      "| 1 | **ìˆ˜ì„± (Mercury)** | 0.39â€¯AU (ì•½ 58â€¯ë°±ë§Œâ€¯km) | 4,880â€¯km | ê°€ì¥ ì‘ì€ í–‰ì„±, ëŒ€ê¸° ê±°ì˜ ì—†ìŒ, ê·¹ì‹¬í•œ ì˜¨ë„ ì°¨(âˆ’173â€¯â„ƒ ~ +427â€¯â„ƒ) |\n",
      "| 2 | **ê¸ˆì„± (Venus)** | 0.72â€¯AU (â‰ˆ 108â€¯ë°±ë§Œâ€¯km) | 12,104â€¯km | ì§€êµ¬ì™€ ë¹„ìŠ·í•œ í¬ê¸°Â·ì§ˆëŸ‰, ë‘êº¼ìš´ ì´ì‚°í™”íƒ„ì†Œ ëŒ€ê¸°ì™€ í™©ì‚° êµ¬ë¦„, ì˜¨ì‹¤íš¨ê³¼ë¡œ í‘œë©´ ì˜¨ë„ â‰ˆâ€¯465â€¯â„ƒ |\n",
      "| 3 | **ì§€êµ¬ (Earth)** | 1â€¯AU (â‰ˆ 150â€¯ë°±ë§Œâ€¯km) | 12,742â€¯km | ë¬¼ì´ ì•¡ì²´ ìƒíƒœë¡œ ì¡´ì¬í•˜ëŠ” ìœ ì¼í•œ í–‰ì„±, í’ë¶€í•œ ì‚°ì†Œ ëŒ€ê¸°, í•˜ë‚˜ì˜ ìœ„ì„±(ë‹¬) |\n",
      "| 4 | **í™”ì„± (Mars)** | 1.52â€¯AU (â‰ˆ 228â€¯ë°±ë§Œâ€¯km) | 6,779â€¯km | ë¶‰ì€ìƒ‰ í‘œë©´(ì‚°í™”ì² ), ì–‡ì€ COâ‚‚ ëŒ€ê¸°, ê³¼ê±° ë¬¼ì´ íë¥¸ í”ì , ë‘ ê°œì˜ ì‘ì€ ìœ„ì„±(í¬ë³´ìŠ¤Â·ë°ì´ëª¨ìŠ¤) |\n",
      "| 5 | **ëª©ì„± (Jupiter)** | 5.20â€¯AU (â‰ˆ 778â€¯ë°±ë§Œâ€¯km) | 139,822â€¯km | ê°€ì¥ í° í–‰ì„±, ì£¼ëœ ì„±ë¶„ì€ ìˆ˜ì†ŒÂ·í—¬ë¥¨, ê±°ëŒ€í•œ í­í’ â€œëŒ€ì ì â€, 79ê°œì˜ ìœ„ì„±(ê°€ë‹ˆë©”ë°Â·ì´ì˜¤Â·ìœ ë¡œíŒŒÂ·ì¹¸ì†Œ ë“±) |\n",
      "| 6 | **í† ì„± (Saturn)** | 9.58â€¯AU (â‰ˆ 1.43â€¯ì–µâ€¯km) | 116,464â€¯km | ëˆˆì— ë„ëŠ” ê³ ë¦¬ ì‹œìŠ¤í…œ(ì–¼ìŒÂ·ì•”ì„ ì…ì), ê°€ìŠ¤ í–‰ì„±, 83ê°œì˜ ìœ„ì„±(í‹°íƒ„Â·ë ˆì•„ ë“±) |\n",
      "| 7 | **ì²œì™•ì„± (Uranus)** | 19.2â€¯AU (â‰ˆ 2.87â€¯ì–µâ€¯km) | 50,724â€¯km | ì²­ë¡ìƒ‰(ë©”íƒ„ ê°€ìŠ¤), ìì „ì¶•ì´ ê±°ì˜ 98Â° ê¸°ìš¸ì–´ì ¸ ìˆì–´ â€œì˜†ìœ¼ë¡œ ëˆ„ìš´â€ í–‰ì„±, 27ê°œì˜ ìœ„ì„±(í‹°íƒ€ë‹ˆì•„Â·ì˜¤ë² ë¡  ë“±) |\n",
      "| 8 | **í•´ì™•ì„± (Neptune)** | 30.1â€¯AU (â‰ˆ 4.50â€¯ì–µâ€¯km) | 49,244â€¯km | ê°€ì¥ ë°”ëŒì´ ê°•í•œ í–‰ì„±(ìµœëŒ€ 2,100â€¯km/h), í‘¸ë¥¸ìƒ‰(ë©”íƒ„), 14ê°œì˜ ìœ„ì„±(íŠ¸ë¦¬í†¤Â·ë„¤ë ˆì´ë“œ ë“±) |\n",
      "\n",
      "### ê°„ë‹¨ ì •ë¦¬\n",
      "- **ë‚´í–‰ì„±(rocky planets)**: ìˆ˜ì„±Â·ê¸ˆì„±Â·ì§€êµ¬Â·í™”ì„± â€“ ê³ ì²´ í‘œë©´, ì‘ì€ í¬ê¸°, ìƒëŒ€ì ìœ¼ë¡œ ë°€ë„ê°€ ë†’ìŒ.  \n",
      "- **ê°€ìŠ¤Â·ì–¼ìŒ í–‰ì„±(gas/ice giants)**: ëª©ì„±Â·í† ì„±Â·ì²œì™•ì„±Â·í•´ì™•ì„± â€“ ì£¼ë¡œ ìˆ˜ì†ŒÂ·í—¬ë¥¨(ëª©ì„±Â·í† ì„±) ë˜ëŠ” ë¬¼Â·ì•”ëª¨ë‹ˆì•„Â·ë©”íƒ„(ì²œì™•ì„±Â·í•´ì™•ì„±)ìœ¼ë¡œ êµ¬ì„±, í¬ê¸°ê°€ í¬ê³  ë§ì€ ìœ„ì„±ì„ ê°€ì§.  \n",
      "- **íŠ¹ì§•ì ì¸ ì°¨ì´**: ìˆ˜ì„±ì€ ê°€ì¥ ëœ¨ê²ê³  ì°¨ê°€ìš´ ê·¹ë‹¨ì ì¸ ì˜¨ë„, ê¸ˆì„±ì€ ê°•ë ¥í•œ ì˜¨ì‹¤íš¨ê³¼, ì§€êµ¬ëŠ” ìƒëª…ì²´ ì¡´ì¬, í™”ì„±ì€ ê³¼ê±° ë¬¼ í”ì , ëª©ì„±Â·í† ì„±ì€ ê±°ëŒ€í•œ ê³ ë¦¬ì™€ ìœ„ì„±, ì²œì™•ì„±Â·í•´ì™•ì„±ì€ ê·¹ë‹¨ì ì¸ ìì „ì¶•Â·ë°”ëŒÂ·ì²­ìƒ‰ ëŒ€ê¸°.  \n",
      "\n",
      "ì´ ì •ë„ë©´ íƒœì–‘ê³„ í–‰ì„±ë“¤ì˜ í•µì‹¬ì ì¸ íŠ¹ì§•ì„ í•œëˆˆì— íŒŒì•…í•˜ì‹¤ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain ì‹¤í–‰\n",
    "result = llm.invoke(\"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.', 'output': '### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\\n1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\\n2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\\n3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.'}, {'input': 'ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.', 'output': '### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\\n- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\\n- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\\n- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\\n- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A8569CD0D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A8569DDD50>, root_client=<openai.OpenAI object at 0x000001A853826890>, root_async_client=<openai.AsyncOpenAI object at 0x000001A8569DD890>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "## ì–‘ì ì»´í“¨í„°ê°€ ë­ì—ìš”?  \n",
      "(ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•´ë³¼ê²Œìš”)\n",
      "\n",
      "---\n",
      "\n",
      "### 1ï¸âƒ£ ê¸°ì¡´ ì»´í“¨í„°ì™€ â€˜ë¹„íŠ¸â€™\n",
      "* **ë¹„íŠ¸** = 0 ë˜ëŠ” 1 ë‘ ê°€ì§€ ìƒíƒœë§Œ ê°€ì§ˆ ìˆ˜ ìˆì–´ìš”.  \n",
      "* ì»´í“¨í„° ì•ˆì—ì„œëŠ” ìˆ˜ë§ì€ ë¹„íŠ¸ê°€ ëª¨ì—¬ì„œ **ì—°ì‚°**ì„ í•´ìš”.  \n",
      "* ì˜ˆë¥¼ ë“¤ì–´, ì „êµ¬ë¥¼ ì¼œë©´ 1, ë„ë©´ 0ì´ë¼ê³  ìƒê°í•˜ë©´ ë¼ìš”.\n",
      "\n",
      "### 2ï¸âƒ£ ì–‘ì ì»´í“¨í„°ëŠ” â€˜íë¹„íŠ¸â€™\n",
      "* **íë¹„íŠ¸** = ì–‘ì ë¹„íŠ¸.  \n",
      "* íë¹„íŠ¸ëŠ” **0**ê³¼ **1**ì„ ë™ì‹œì— ê°€ì§ˆ ìˆ˜ ìˆì–´ìš”. â†’ â€œ0ê³¼ 1ì´ ë™ì‹œì— ì¼œì ¸ ìˆëŠ” ìƒíƒœâ€ë¼ê³  ìƒê°í•˜ë©´ ë¼ìš”. (ìˆ˜í•™ì ìœ¼ë¡œëŠ” **ì¤‘ì²©**ì´ë¼ê³  ë¶ˆëŸ¬ìš”)  \n",
      "* ë˜, ì—¬ëŸ¬ íë¹„íŠ¸ê°€ ì„œë¡œ **ì–½í˜€(Entanglement)** ìˆìœ¼ë©´, í•œ íë¹„íŠ¸ê°€ ë°”ë€” ë•Œ ë‹¤ë¥¸ íë¹„íŠ¸ë„ ì¦‰ì‹œ ì˜í–¥ì„ ë°›ì•„ìš”. ë§ˆì¹˜ ìŒë‘¥ì´ê°€ ëˆˆì„ ë§ì¶”ê³  ê°™ì€ í–‰ë™ì„ í•˜ëŠ” ê²ƒê³¼ ë¹„ìŠ·í•´ìš”.\n",
      "\n",
      "### 3ï¸âƒ£ ì™œ ë” ë¹ ë¥¼ê¹Œ?\n",
      "* **ì¤‘ì²©** ë•ë¶„ì— í•œ ë²ˆì— ë§ì€ ê²½ìš°ì˜ ìˆ˜ë¥¼ ë™ì‹œì— ê³„ì‚°í•  ìˆ˜ ìˆì–´ìš”.  \n",
      "* **ì–½í˜** ë•ë¶„ì— íë¹„íŠ¸ë“¤ ì‚¬ì´ì— ì •ë³´ë¥¼ ì•„ì£¼ ë¹ ë¥´ê²Œ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆì–´ìš”.  \n",
      "* ê·¸ë˜ì„œ ì–´ë–¤ íŠ¹ì •í•œ ë¬¸ì œ(ì˜ˆ: í° ì†Œìˆ˜ ì°¾ê¸°, ë³µì¡í•œ í™”í•™ ë°˜ì‘ ì‹œë®¬ë ˆì´ì…˜ ë“±)ëŠ” ê¸°ì¡´ ì»´í“¨í„°ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê²Œ í’€ ìˆ˜ ìˆì–´ìš”.\n",
      "\n",
      "### 4ï¸âƒ£ ì•„ì§ ì–´ë ¤ìš´ ì \n",
      "| ë¬¸ì œ | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ì˜¤ë¥˜** | íë¹„íŠ¸ê°€ ì•„ì£¼ ì‘ì€ ì™¸ë¶€ ë°©í•´(ì˜¨ë„, ë¹›, ì§„ë™ ë“±)ì—ë„ ì‰½ê²Œ ë³€í•´ë²„ë ¤ì„œ ì •í™•íˆ ê³„ì‚°í•˜ê¸° ì–´ë ¤ì›Œìš”. |\n",
      "| **ëƒ‰ê°** | ëŒ€ë¶€ë¶„ì˜ ì–‘ì ì»´í“¨í„°ëŠ” **ê·¹ì €ì˜¨(â€“273Â°Cì— ê°€ê¹Œìš´ ì˜¨ë„)** ì—ì„œë§Œ ë™ì‘í•´ìš”. |\n",
      "| **ê·œëª¨** | í˜„ì¬ëŠ” ìˆ˜ì‹­ ê°œ ì •ë„ì˜ íë¹„íŠ¸ë§Œ ì•ˆì •ì ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”. ë” í° ê·œëª¨ê°€ ë˜ë©´ ì œì–´ê°€ í›¨ì”¬ ì–´ë ¤ì›Œì ¸ìš”. |\n",
      "\n",
      "### 5ï¸âƒ£ ì–´ë””ì— ì“°ì¼ê¹Œ?\n",
      "| ë¶„ì•¼ | ì˜ˆì‹œ |\n",
      "|------|------|\n",
      "| **ì•”í˜¸ í•´ë…** | í˜„ì¬ ì“°ëŠ” ì•”í˜¸ë¥¼ ë¹ ë¥´ê²Œ ê¹¨ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ ê°€ëŠ¥í•´ìš”. (í•˜ì§€ë§Œ ë™ì‹œì— ìƒˆë¡œìš´ ì•ˆì „í•œ ì•”í˜¸ë„ ì—°êµ¬ ì¤‘) |\n",
      "| **ì‹ ì•½ ê°œë°œ** | ë³µì¡í•œ ë¶„ì êµ¬ì¡°ë¥¼ ì •í™•íˆ ì‹œë®¬ë ˆì´ì…˜í•´ì„œ ìƒˆë¡œìš´ ì•½ì„ ì°¾ëŠ” ë° ë„ì›€ì„ ì¤˜ìš”. |\n",
      "| **ì¬ë£Œ ê³¼í•™** | ìƒˆë¡œìš´ ë¬¼ì§ˆ(ì˜ˆ: ì´ˆì „ë„ì²´) ì„¤ê³„ì— í•„ìš”í•œ ê³„ì‚°ì„ ë¹ ë¥´ê²Œ í•  ìˆ˜ ìˆì–´ìš”. |\n",
      "| **ì¸ê³µì§€ëŠ¥** | íŠ¹ì • ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”. |\n",
      "\n",
      "### 6ï¸âƒ£ ì‰½ê²Œ ìƒê°í•´ ë³´ëŠ” ë¹„ìœ \n",
      "* **ì „í†µ ì»´í“¨í„°** : í•œ ì¤„ë¡œ ì„œì„œ ì°¨ë¡€ëŒ€ë¡œ ë¬¸ì œë¥¼ í‘¸ëŠ” ì‚¬ëŒë“¤.  \n",
      "* **ì–‘ì ì»´í“¨í„°** : ë™ì‹œì— ì—¬ëŸ¬ ì¤„ë¡œ ì„œì„œ ê°™ì€ ë¬¸ì œë¥¼ ì—¬ëŸ¬ ê²½ìš°ì˜ ìˆ˜ë¡œ í•œ ë²ˆì— í’€ì–´ë³´ëŠ” ì‚¬ëŒë“¤. (í•˜ì§€ë§Œ ì•„ì§ì€ ì¤„ì´ ë§ì´ ê¼¬ì—¬ì„œ ì œëŒ€ë¡œ ì›€ì§ì´ê²Œ í•˜ê¸°ê°€ ì–´ë ¤ì›Œìš”.)\n",
      "\n",
      "---\n",
      "\n",
      "#### ì •ë¦¬\n",
      "- **ë¹„íŠ¸ â†’ 0 ë˜ëŠ” 1** (ì „í†µ ì»´í“¨í„°)  \n",
      "- **íë¹„íŠ¸ â†’ 0ê³¼ 1ì„ ë™ì‹œì—** (ì–‘ì ì»´í“¨í„°)  \n",
      "- **ì¤‘ì²© + ì–½í˜** ë•ë¶„ì— **ë§ì€ ê²½ìš°ë¥¼ ë™ì‹œì—** ê³„ì‚°í•  ìˆ˜ ìˆìŒ.  \n",
      "- ì•„ì§ **ì˜¤ë¥˜ì™€ ëƒ‰ê°** ê°™ì€ ê¸°ìˆ ì  ì–´ë ¤ì›€ì´ ìˆì§€ë§Œ, **ì•”í˜¸, ì‹ ì•½, ì¬ë£Œ** ë“± ì¤‘ìš”í•œ ë¶„ì•¼ì— í° ë³€í™”ë¥¼ ì¤„ ì ì¬ë ¥ì´ ìˆì–´ìš”.\n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ ì£¼ì„¸ìš”! ğŸŒŸ\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"ì–‘ìì»´í“¨í„° ì •ë¦¬í•´ ì£¼ì„¸ìš”.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* í”„ë¡¬í”„íŠ¸ë¥¼ ë” ë™ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, AI ì‘ë‹µì„ ë” ì¼ê´€ì„± ìˆê²Œ ì¡°ì • ê°€ëŠ¥í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: ê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ íƒœí’ ë°œìƒì´ ë§ë‚˜ìš”? ê°€ì„ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\n",
      " ëª¨ë¸ ì‘ë‹µ: ê°€ì„(9â€‘11ì›”)ì—ëŠ” **ì—¬ë¦„**ì— ë¹„í•´ ê¸°ì˜¨ì´ ì„œì„œíˆ ë‚®ì•„ì§€ë©´ì„œ ëŒ€ê¸°ì˜ ëŒ€ê·œëª¨ íë¦„ì´ ë°”ë€Œê³ , ê·¸ì— ë”°ë¼ ì§€êµ¬ê³¼í•™ì ì¸ í˜„ìƒë“¤ì´ ëª‡ ê°€ì§€ ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.  \n",
      "ì•„ë˜ëŠ” **ê°€ì„ì— ì£¼ë¡œ ê´€ì¸¡ë˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€**ì™€ ê·¸ íŠ¹ì§•ì„ ê°„ë‹¨íˆ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
      "\n",
      "| # | í˜„ìƒ | ì£¼ìš” íŠ¹ì§• ë° ë°œìƒ ë©”ì»¤ë‹ˆì¦˜ | ê°€ì„ì— ë‘ë“œëŸ¬ì§€ëŠ” ì´ìœ  |\n",
      "|---|------|---------------------------|------------------------|\n",
      "| 1 | **íƒœí’(ì—´ëŒ€ ì €ê¸°ì••) ë°œìƒÂ·ì ‘ê·¼** | â€¢ ì„œìª½ íƒœí‰ì–‘ì—ì„œ í˜•ì„±ëœ íƒœí’ì´ ë¶ìª½ìœ¼ë¡œ ì´ë™í•˜ë©´ì„œ í•œë°˜ë„Â·ë™ì•„ì‹œì•„ì— ì˜í–¥ì„ ë¯¸ì¹¨.<br>â€¢ ë°”ë‹¤ í‘œë©´ ì˜¨ë„ê°€â€¯â‰ˆâ€¯26â€¯â„ƒ ì´ìƒì´ì–´ì•¼ ë°œë‹¬ ê°€ëŠ¥í•˜ì§€ë§Œ, ê°€ì„ ì´ˆì…(9â€‘10ì›”)ê¹Œì§€ëŠ” ì•„ì§ ì¶©ë¶„íˆ ë”°ëœ»í•¨.<br>â€¢ íƒœí’ì€ ê°•í’Â·í­ìš°Â· í•´ì¼(Storm Surge)ì„ ë™ë°˜í•´ ê°•ìš°ëŸ‰Â·í™ìˆ˜Â·ì‚°ì‚¬íƒœ ìœ„í—˜ì„ í¬ê²Œ ë†’ì„. | â€¢ ì—¬ë¦„ ë§ê¹Œì§€ ë‚¨ì•„ ìˆëŠ” ë†’ì€ í•´ìˆ˜ ì˜¨ë„ì™€ ë‚¨ìª½ì—ì„œ ë¶ìƒí•˜ëŠ” **ì¤‘ìœ„ë„ ì €ê¸°ì••**(í¸ì„œí’ ê¸‰ë¥˜) ì‚¬ì´ì˜ ìƒí˜¸ì‘ìš©ì´ ê°•í•´ì§€ë©´ì„œ íƒœí’ì´ ë¶ìª½ìœ¼ë¡œ ì´ë™Â·ì „í™˜í•˜ê¸° ì‰¬ì›Œì§.<br>â€¢ ê°€ì„ ì´ˆë°˜ì€ â€œíƒœí’ ì‹œì¦Œâ€ì˜ ë§ˆì§€ë§‰ ê³ ì ì´ë©°, 9ì›”â€¯~â€¯10ì›”ì— ê°€ì¥ ë§ì€ ìƒë¥™Â·ì ‘ê·¼ ì‚¬ë¡€ê°€ ë³´ê³ ë¨. |\n",
      "| 2 | **ì¤‘ìœ„ë„ ì €ê¸°ì••Â·ì „ì„  í™œë™ ê°•í™”** | â€¢ ê°€ì„ì—ëŠ” **ê·¹ì§€ ê³ ê¸°ì••**ì´ ë‚¨ìª½ìœ¼ë¡œ í›„í‡´í•˜ê³ , **ê·¹ì§€ ì €ê¸°ì••**ì´ ë¶ìª½ìœ¼ë¡œ ì´ë™í•˜ë©´ì„œ ì „í˜•ì ì¸ ì¤‘ìœ„ë„ ì €ê¸°ì••(ì €ê¸°ì•• ì „ì„ ) ì‹œìŠ¤í…œì´ í™œë°œí•´ì§.<br>â€¢ ê¸‰ê²©í•œ ì˜¨ë„Â·ìŠµë„ ì°¨ì´ë¡œ ì¸í•´ **ì „ì„ **ì´ í˜•ì„±ë˜ê³ , ì´ë¡œ ì¸í•´ **ì†Œë‚˜ê¸°Â·ë‡Œìš°Â·ê°•ìˆ˜**ê°€ ë¹ˆë²ˆíˆ ë°œìƒ.<br>â€¢ ì „ì„ ì´ ì§€ë‚˜ê°€ë©´ ì˜¨ë„ ê¸‰ë³€, ë°”ëŒ ì „í™˜, ëŒ€ê¸°ì•• ê¸‰ë½ ë“± ì¼êµì°¨ê°€ í¬ê²Œ ëŠ˜ì–´ë‚¨. | â€¢ ì—¬ë¦„ì˜ **ê³„ì ˆí’(ë‚¨ì„œÂ·ë‚¨ë™í’)**ì´ ì•½í•´ì§€ê³ , ê°€ì„ì— ë“¤ì–´ì„œë©´ì„œ **í¸ì„œí’**ì´ ì ì°¨ ê°•í™”ë¼ ì¤‘ìœ„ë„ ì €ê¸°ì••ì´ í•œë°˜ë„ ë‚¨ìª½Â·ë™ìª½ì„ ìì£¼ í†µê³¼í•¨.<br>â€¢ ëŒ€ê¸° ì¤‘ ìˆ˜ì¦ê¸° ê³µê¸‰ì´ ì•„ì§ ì¶©ë¶„í•˜ë¯€ë¡œ ì „ì„ ì— ì˜í•´ ë°œìƒí•˜ëŠ” ê°•ìˆ˜ëŸ‰ì´ ì—¬ì „íˆ í¬ê²Œ ë‚˜íƒ€ë‚¨. |\n",
      "| 3 | **ëŒ€ê¸° ì •ì²´Â·ê³ ê¸°ì•• ê°•í™”ì— ë”°ë¥¸ ì•ˆê°œÂ·ì—°ë¬´Â·ëŒ€ê¸°ì§ˆ ì•…í™”** | â€¢ ê°€ì„ì—ëŠ” **ë™ì•„ì‹œì•„ ê³ ê¸°ì••**(ë¶íƒœí‰ì–‘ ê³ ê¸°ì••Â·ì‹œë² ë¦¬ì•„ ê³ ê¸°ì••)ì´ ê°•í•´ì§€ë©´ì„œ **ëŒ€ê¸° ì •ì²´** í˜„ìƒì´ ìì£¼ ë°œìƒ.<br>â€¢ ë°”ëŒì´ ê±°ì˜ ë©ˆì¶”ê³ , ìŠµë„ê°€ ë†’ì€ ì €ì¸µ ëŒ€ê¸°ê°€ ì–‡ì€ ì¸µìœ¼ë¡œ ì–½íˆë©´ì„œ **ì•ˆê°œÂ·ì—°ë¬´**ê°€ ìì£¼ ë‚˜íƒ€ë‚¨.<br>â€¢ ì •ì²´ëœ ëŒ€ê¸°ì—ì„œëŠ” ì˜¤ì—¼ë¬¼ì§ˆ(ë¯¸ì„¸ë¨¼ì§€Â·í™©ì‚¬Â·ì‚°ë¶ˆ ì—°ê¸° ë“±)ì´ ì‰½ê²Œ í™•ì‚°ë˜ì§€ ì•Šì•„ **ëŒ€ê¸°ì§ˆ(PMâ€¯2.5, Oâ‚ƒ) ì•…í™”**ê°€ ì¼ì–´ë‚  ìˆ˜ ìˆìŒ. | â€¢ ê°€ì„ì€ **ì¼êµì°¨**ê°€ ì»¤ì ¸ ë°¤ì— ì°¨ê°€ìš´ ê³µê¸°ê°€ ì €ì¸µì— ë¨¸ë¬´ë¥´ê³ , ë‚®ì— ë”°ëœ»í•œ ê³µê¸°ê°€ ìœ„ë¡œ ì˜¬ë¼ê°€ëŠ” **ì—­ì „ì¸µ**ì´ í˜•ì„±ë˜ê¸° ì‰¬ì›€.<br>â€¢ ê°•ìˆ˜ëŸ‰ì´ ê°ì†Œí•˜ë©´ì„œ ëŒ€ê¸° ì¤‘ ìˆ˜ë¶„ì´ ìƒëŒ€ì ìœ¼ë¡œ ì ì–´ì§€ì§€ë§Œ, ìŠµë„ê°€ ë†’ì€ ì§€ì—­(ê°•ì›ë„Â·ì¶©ì²­ë„ ë“±)ì—ì„œëŠ” ì•ˆê°œê°€ ìì£¼ ë°œìƒí•¨.<br>â€¢ ë†ì—…Â·ì‚°ì—… í™œë™ì´ ê°ì†Œí•˜ë©´ì„œ ë°°ì¶œëŸ‰ì´ ì¤„ì–´ë“¤ì§€ë§Œ, ì •ì²´ëœ ëŒ€ê¸° ë•Œë¬¸ì— ê¸°ì¡´ ì˜¤ì—¼ë¬¼ì§ˆì´ â€˜ìŒ“ì´ëŠ”â€™ íš¨ê³¼ê°€ ì»¤ì§. |\n",
      "\n",
      "---\n",
      "\n",
      "## ì¶”ê°€ ì„¤ëª… â€“ â€œê°€ì„ì— íƒœí’ì´ ëŒ€í‘œì ì¸ê°€?â€  \n",
      "\n",
      "- **ë§ìŠµë‹ˆë‹¤.** ê°€ì„ ì´ˆì…(íŠ¹íˆ 9ì›”)ì€ íƒœí’ ì‹œì¦Œì˜ **í”¼í¬**ì— í•´ë‹¹í•©ë‹ˆë‹¤. ë”°ë¼ì„œ â€œê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒâ€ìœ¼ë¡œ **íƒœí’**ì„ ê¼½ëŠ” ê²ƒì€ íƒ€ë‹¹í•©ë‹ˆë‹¤.  \n",
      "- ë‹¤ë§Œ, ê°€ì„ì€ **íƒœí’** ì™¸ì—ë„ **ì¤‘ìœ„ë„ ì €ê¸°ì••Â·ì „ì„  í™œë™**ê³¼ **ëŒ€ê¸° ì •ì²´Â·ê³ ê¸°ì••**ì— ì˜í•´ ë‚˜íƒ€ë‚˜ëŠ” í˜„ìƒë“¤ì´ ë™ì‹œì— ê°•í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì‹œê¸°ì´ë¯€ë¡œ, ìœ„ 3ê°€ì§€ í˜„ìƒì„ í•¨ê»˜ ì´í•´í•˜ë©´ ê°€ì„ ê¸°í›„Â·ì¬í•´ ìœ„í—˜ì„ ë³´ë‹¤ ì¢…í•©ì ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ê°€ì„ ê¸°í›„Â·ì¬í•´ ëŒ€ë¹„ íŒ (ê°„ë‹¨íˆ)\n",
      "\n",
      "| í˜„ìƒ | ìœ„í—˜ ìš”ì†Œ | ëŒ€ë¹„ ë°©ë²• |\n",
      "|------|-----------|-----------|\n",
      "| íƒœí’ | ê°•í’Â·í­ìš°Â·í•´ì¼, ì‚°ì‚¬íƒœÂ·í™ìˆ˜ | â€¢ ì‚¬ì „ì— íƒœí’ ê²½ë¡œÂ·ê°•ë„ í™•ì¸<br>â€¢ ë°°ìˆ˜ë¡œÂ·í•˜ì²œ ì •ë¹„Â·ë¹„ìƒìš©í’ˆ ì¤€ë¹„ |\n",
      "| ì¤‘ìœ„ë„ ì €ê¸°ì••Â·ì „ì„  | ê¸‰ê²©í•œ ê°•ìˆ˜Â·ë‡Œìš°Â·ë‚™ë¢° | â€¢ ê¸°ìƒì˜ˆë³´Â·íŠ¹ë³´ì— ì£¼ì˜<br>â€¢ ì•¼ì™¸ í™œë™ ì‹œ í”¼ë¢°ì¹¨Â·ìš°ì‚°Â·ë°©ìˆ˜ ì¥ë¹„ ì¤€ë¹„ |\n",
      "| ëŒ€ê¸° ì •ì²´Â·ê³ ê¸°ì•• | ì•ˆê°œÂ·ì—°ë¬´Â·ëŒ€ê¸°ì§ˆ ì•…í™” | â€¢ êµí†µ ì‹œ ì €ì‹œì •Â·ì•ˆê°œ ì£¼ì˜<br>â€¢ ëŒ€ê¸°ì§ˆ ê²½ë³´ ì‹œ ì™¸ì¶œ ìì œÂ·ë§ˆìŠ¤í¬ ì°©ìš© |\n",
      "\n",
      "---\n",
      "\n",
      "### ì°¸ê³  ë¬¸í—ŒÂ·ë°ì´í„° (2020â€‘2024ë…„ ê¸°ì¤€)\n",
      "\n",
      "1. **KMA (ê¸°ìƒì²­) â€œê°€ì„ì²  ê¸°ìƒíŠ¹ì§• ë³´ê³ ì„œâ€** â€“ 2022ë…„, 2023ë…„ ë°œí‘œ ìë£Œ.  \n",
      "2. **JMA (ì¼ë³¸ ê¸°ìƒì²­) â€œTyphoon Season Statisticsâ€** â€“ 2021â€‘2023ë…„ í‰ê·  íƒœí’ ë°œìƒ ì‹œê¸°.  \n",
      "3. **IPCC AR6 Chapter 2 â€œAtmospheric Dynamicsâ€** â€“ ì¤‘ìœ„ë„ ì €ê¸°ì••Â·ì „ì„  ë³€í™”ì™€ ê³„ì ˆë³„ íŠ¹ì§•.  \n",
      "4. **Air Korea (ëŒ€ê¸°í™˜ê²½ì •ë³´) â€œê°€ì„ì²  ëŒ€ê¸°ì •ì²´Â·ë¯¸ì„¸ë¨¼ì§€ í˜„í™©â€** â€“ 2020â€‘2024ë…„ ë°ì´í„°.  \n",
      "\n",
      "í•„ìš”í•˜ì‹œë©´ ê° ìë£Œì˜ êµ¬ì²´ì ì¸ ë§í¬ë‚˜ ê·¸ë˜í”„ë„ ì œê³µí•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–¸ì œë“  ì¶”ê°€ ì§ˆë¬¸ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì´ ë§ë‚˜ìš”? {season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "    input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "    partial_variables={\"season\": get_current_season()}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "query = prompt.format(phenomenon=\"íƒœí’ ë°œìƒ\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\" í”„ë¡¬í”„íŠ¸: {query}\")\n",
    "print(f\" ëª¨ë¸ ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê³„ì ˆ: ë´„\n",
      "\n",
      " ë´„ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\n",
      "ë´„ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **ì¶˜ë¶„(ì¶˜ë¶„ì )**: ì¶˜ë¶„ì€ ì§€êµ¬ì˜ ì¶˜ë¶„ì ìœ¼ë¡œ ë¶ë°˜êµ¬ì—ì„œ ë´„ì´ ì‹œì‘ë˜ëŠ” ë‚ ì…ë‹ˆë‹¤. íƒœì–‘ì´ ë‚¨ì¶˜ë¶„ì (ì ë„ ë‚¨ìª½)ì—ì„œ ë¶ì¶˜ë¶„ì (ì ë„ ë¶ìª½)ìœ¼ë¡œ ì´ë™í•  ë•Œ ë°œìƒí•˜ë©°, ë‚®ê³¼ ë°¤ì˜ ê¸¸ì´ê°€ ê±°ì˜ ê°™ìŠµë‹ˆë‹¤.\n",
      "2.  **ë¹™í•˜ ìœµí•´**: ë¹™í•˜ ìœµí•´ëŠ” ë¹™í•˜ì˜ ì˜¨ë„ê°€ ìƒìŠ¹í•˜ë©´ì„œ ë¹™í•˜ì˜ í‘œë©´ì´ë‚˜ ë‚´ë¶€ì—ì„œ ëˆˆì´ë‚˜ ì–¼ìŒì´ ë…¹ëŠ” í˜„ìƒì…ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë°”ë‹¤ ìˆ˜ìœ„ê°€ ìƒìŠ¹í•˜ê³ , ìƒíƒœê³„ì˜ ë³€í™”ê°€ ì¼ì–´ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3.  **í™©ì‚¬ í˜„ìƒ**: í™©ì‚¬ í˜„ìƒì€ ì¤‘êµ­ì´ë‚˜ ëª½ê³¨ì˜ ì‚¬ë§‰ ì§€ì—­ì—ì„œ ê°•í•œ ë°”ëŒì´ ë¶ˆì–´ì˜¤ëŠ” ë•Œ ë°œìƒí•©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë¯¸ì„¸ë¨¼ì§€ê°€ ë§ì´ ë°œìƒí•˜ì—¬ ê±´ê°•ì— í•´ë¥¼ ë¼ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜„ìƒì€ íŠ¹íˆ ë´„ì² ì— ë”ìš± ì‹¬í•´ì§€ë©°, ì•„ì‹œì•„ ì§€ì—­ ì „ë°˜ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# Step 1: í˜„ì¬ ê³„ì ˆ ê²°ì •\n",
    "season = get_current_season(\"south\")  # ê³„ì ˆ ê°’ ì–»ê¸°\n",
    "print(f\"í˜„ì¬ ê³„ì ˆ: {season}\")\n",
    "\n",
    "# Step 2: í•´ë‹¹ ê³„ì ˆì˜ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# ì²´ì¸ 2: ìì—° í˜„ìƒ ì¶”ì²œ (ì…ë ¥: ê³„ì ˆ â†’ ì¶œë ¥: ìì—° í˜„ìƒ ëª©ë¡)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season}  # chain1ì˜ ì¶œë ¥ì„ season ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰: í˜„ì¬ ê³„ì ˆì— ë”°ë¥¸ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API í˜¸ì¶œ ë°ì´í„°, ì‹œê°„ ì •ë³´, ì‚¬ìš©ì ì •ë³´ ë“±ì„ ë°˜ì˜í•  ë•Œ ë§¤ìš° ìœ ìš©í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1377.98ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      " ëª¨ë¸ ì‘ë‹µ: ## 2024ë…„ 4ì›” 5ì¼ í™˜ìœ¨ ë¶„ì„: 1ë‹¬ëŸ¬ = 1377.98ì›\n",
      "\n",
      "### 1. í˜„ì¬ í™˜ìœ¨ ìƒíƒœ\n",
      "\n",
      "2024ë…„ 4ì›” 5ì¼, 1ë‹¬ëŸ¬ëŠ” 1377.98ì›ìœ¼ë¡œ ê±°ë˜ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” í•œêµ­ ì›í™”ì˜ ê°€ì¹˜ê°€ ë¯¸êµ­ ë‹¬ëŸ¬í™” ëŒ€ë¹„ ì•½ì„¸ì„ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. \n",
      "\n",
      "### 2. ìµœê·¼ í™˜ìœ¨ ë³€ë™ ì¶”ì„¸\n",
      "\n",
      "ìµœê·¼ì˜ ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©ê³¼ í†µí™” ì •ì±…ì€ í™˜ìœ¨ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ë¯¸êµ­ì˜ ê¸ˆë¦¬ ì •ì±…ê³¼ í•œêµ­ì˜ ê²½ì œ ì„±ì¥ë¥ , ë¬´ì—­ ìˆ˜ì§€ ë“±ì´ í™˜ìœ¨ ë³€ë™ì— ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤.\n",
      "\n",
      "### 3. ì›í™” ì•½ì„¸ ì›ì¸\n",
      "\n",
      "1. **ê¸€ë¡œë²Œ ê²½ì œ ë¶ˆí™•ì‹¤ì„±**: ê¸€ë¡œë²Œ ê²½ì œì˜ ë¶ˆí™•ì‹¤ì„±ì´ ì¦ê°€í•  ë•Œ, íˆ¬ììë“¤ì€ ì•ˆì „ ìì‚°ìœ¼ë¡œ ì—¬ê²¨ì§€ëŠ” ë‹¬ëŸ¬í™”ë¡œ ìê¸ˆì„ ì´ë™ì‹œí‚¤ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¬ëŸ¬í™”ì˜ ìˆ˜ìš”ë¥¼ ì¦ê°€ì‹œí‚¤ê³ , ì›í™”ì˜ ê°€ì¹˜ë¥¼ í•˜ë½ì‹œí‚¤ëŠ” ìš”ì¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "2. **ë¯¸êµ­ ì—°ë°©ì¤€ë¹„ì œë„(Fed)ì˜ ê¸ˆë¦¬ ì •ì±…**: ë¯¸êµ­ Fedì˜ ê¸ˆë¦¬ ì¸ìƒì´ë‚˜ ì¸í•˜ ì—¬ë¶€ëŠ” ë‹¬ëŸ¬í™” ê°€ì¹˜ì— í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ìµœê·¼ ë¯¸êµ­ ê²½ì œ ì§€í‘œì™€ Fedì˜ ì •ì±… ë°œí‘œì— ë”°ë¼ ë‹¬ëŸ¬í™”ì˜ ê°€ì¹˜ê°€ ë³€ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **í•œêµ­ì˜ ê²½ì œ ìƒí™©**: í•œêµ­ì˜ ìˆ˜ì¶œì… ì‹¤ì , ë¬´ì—­ ìˆ˜ì§€, ê²½ì œ ì„±ì¥ë¥  ë“±ë„ ì›í™” ê°€ì¹˜ì— ì˜í–¥ì„ ì£¼ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. íŠ¹íˆ, ë°˜ë„ì²´ì™€ ê°™ì€ ì£¼ìš” ìˆ˜ì¶œ í’ˆëª©ì˜ ìˆ˜ìš” ë³€ë™ì€ í•œêµ­ì˜ ê²½ì œ ìƒí™©ê³¼ ì›í™” ê°€ì¹˜ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "### 4. í–¥í›„ í™˜ìœ¨ ì „ë§\n",
      "\n",
      "í–¥í›„ í™˜ìœ¨ì€ ë‹¤ì–‘í•œ ê²½ì œì  ìš”ì¸ì— ì˜í•´ ë³€ë™í•  ê²ƒì…ë‹ˆë‹¤. \n",
      "\n",
      "1. **ê²½ì œ ì§€í‘œ ë°œí‘œ**: ë¯¸êµ­ê³¼ í•œêµ­ì˜ ê²½ì œ ì§€í‘œ ë°œí‘œëŠ” í–¥í›„ í™˜ìœ¨ ë³€ë™ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹  ê²ƒì…ë‹ˆë‹¤. íŠ¹íˆ, ê³ ìš©ë¥ , ë¬¼ê°€ ìƒìŠ¹ë¥ , ì œì¡°ì—… í™œë™ ë“± ì£¼ìš” ê²½ì œ ì§€í‘œì— ì£¼ëª©í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¤‘ì•™ì€í–‰ì˜ í†µí™” ì •ì±…**: ë¯¸êµ­ Fedì™€ í•œêµ­ì€í–‰ì˜ í†µí™” ì •ì±… ê²°ì •ë„ í™˜ìœ¨ì— í° ì˜í–¥ì„ ë¯¸ì¹  ê²ƒì…ë‹ˆë‹¤. ê¸ˆë¦¬ ì¸ìƒì´ë‚˜ ì¸í•˜, ì–‘ì  ê¸´ì¶• ë˜ëŠ” ì™„í™” ì •ì±… ë“±ì€ ë‹¬ëŸ¬í™”ì™€ ì›í™”ì˜ ìƒëŒ€ì  ê°€ì¹˜ì— ì˜í–¥ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "3. **ê¸€ë¡œë²Œ ê²½ì œ ìƒí™©**: ê¸€ë¡œë²Œ ê²½ì œì˜ ë¶ˆí™•ì‹¤ì„±ì´ ì¦ê°€í•˜ê±°ë‚˜ ê°ì†Œí•  ê²½ìš°, ì•ˆì „ ìì‚°ì— ëŒ€í•œ ì„ í˜¸ë„ê°€ ë³€ë™í•˜ë©´ì„œ í™˜ìœ¨ì— ì˜í–¥ì„ ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "### 5. ê°œì¸ ë° ê¸°ì—…ì˜ ëŒ€ì‘ ì „ëµ\n",
      "\n",
      "1. **í™˜í—¤ì§€**: ìˆ˜ì¶œì… ê¸°ì—…ì€ í™˜ìœ¨ ë³€ë™ì— ë”°ë¥¸ ìœ„í—˜ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ í™˜í—¤ì§€ ìƒí’ˆì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ì™¸í™˜ ìì‚° ê´€ë¦¬**: ê°œì¸ê³¼ ê¸°ì—…ì€ ì™¸í™˜ ìì‚°ì˜ í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ë‹¤ë³€í™”í•˜ì—¬ í™˜ìœ¨ ë³€ë™ì— ë”°ë¥¸ ìœ„í—˜ì„ ë¶„ì‚°ì‹œí‚¤ëŠ” ì „ëµì„ ê³ ë ¤í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ê²½ì œ ì§€í‘œ ë° ì •ì±… ë™í–¥ ëª¨ë‹ˆí„°ë§**: ê²½ì œ ì§€í‘œì™€ ì •ì±… ë™í–¥ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ í™˜ìœ¨ ë³€ë™ì˜ ì¶”ì„¸ë¥¼ ì˜ˆì¸¡í•˜ê³  ëŒ€ì‘í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ, í˜„ì¬ì˜ í™˜ìœ¨ ìƒíƒœëŠ” ë‹¤ì–‘í•œ ê²½ì œì  ìš”ì¸ì˜ ì˜í–¥ì„ ë°›ê³  ìˆìœ¼ë©°, í–¥í›„ì—ë„ ì´ëŸ¬í•œ ìš”ì¸ë“¤ì´ í™˜ìœ¨ì„ ë³€ë™ì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤. ê°œì¸ê³¼ ê¸°ì—…ì€ ì´ëŸ¬í•œ ë³€ë™ì„±ì„ ì´í•´í•˜ê³ , ì ì ˆí•œ ì „ëµì„ ìˆ˜ë¦½í•˜ì—¬ ì¬ë¬´ ìœ„í—˜ì„ ê´€ë¦¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# Partial Prompt í™œìš©\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì •\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\" í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\" ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-CGunLKE6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
